# å®ä½“å…³ç³»æå–è´¨é‡è¯„ä¼°æŒ‡å—

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»å¦‚ä½•è¯„ä¼° LightRAG ä¸­å®ä½“å’Œå…³ç³»æå–çš„è´¨é‡ï¼Œç‰¹åˆ«æ˜¯åœ¨è€ƒè™‘ä½¿ç”¨æ··åˆæ¶æ„ï¼ˆGLiNER + LLMï¼‰æ—¶å¦‚ä½•ç¡®ä¿è´¨é‡ä¸ä¸‹é™ã€‚

---

## ä¸ºä»€ä¹ˆéœ€è¦è¯„ä¼°ï¼Ÿ

åœ¨ä½¿ç”¨æ··åˆæ¶æ„ï¼ˆGLiNER æå–å®ä½“ + LLM æå–å…³ç³»ï¼‰ä¹‹å‰ï¼Œå¿…é¡»å›ç­”ï¼š

1. **GLiNER æå–çš„å®ä½“è´¨é‡æ˜¯å¦è¶³å¤Ÿå¥½ï¼Ÿ**
   - å‡†ç¡®ç‡ï¼ˆPrecisionï¼‰ï¼šæå–çš„å®ä½“æœ‰å¤šå°‘æ˜¯æ­£ç¡®çš„ï¼Ÿ
   - å¬å›ç‡ï¼ˆRecallï¼‰ï¼šæœ‰å¤šå°‘çœŸå®å®ä½“è¢«æå–å‡ºæ¥äº†ï¼Ÿ

2. **æ··åˆæ¶æ„å¯¹æœ€ç»ˆ RAG æ•ˆæœçš„å½±å“ï¼Ÿ**
   - å³ä½¿å®ä½“æå–æœ‰è½»å¾®æŸå¤±ï¼Œæœ€ç»ˆæŸ¥è¯¢æ•ˆæœæ˜¯å¦å¯æ¥å—ï¼Ÿ

3. **é€Ÿåº¦æå‡å€¼å¾—è´¨é‡æŸå¤±å—ï¼Ÿ**
   - å¦‚æœæé€Ÿ 2 å€ï¼Œä½†è´¨é‡ä¸‹é™ 5%ï¼Œæ˜¯å¦å¯æ¥å—ï¼Ÿ

---

## è¯„ä¼°æ–¹æ³•è®º

### ä¸‰å±‚è¯„ä¼°é‡‘å­—å¡”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å±‚çº§ 3: ç«¯åˆ°ç«¯ RAG è´¨é‡              â”‚  â† æœ€é‡è¦ï¼ˆç”¨æˆ·æœ€ç»ˆä½“éªŒï¼‰
â”‚  (RAGAS: Faithfulness, Relevance)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†‘ å—å½±å“äº
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å±‚çº§ 2: å…³ç³»æå–è´¨é‡                 â”‚
â”‚  (Relation Precision, Recall, F1)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†‘ å—å½±å“äº
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å±‚çº§ 1: å®ä½“æå–è´¨é‡                 â”‚  â† æœ€åº•å±‚ï¼ˆæœ€å®¹æ˜“æµ‹é‡ï¼‰
â”‚  (Entity Precision, Recall, F1)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**è¯„ä¼°ç­–ç•¥**ï¼š
- **å¿«é€ŸéªŒè¯**ï¼šä»å±‚çº§ 1 å¼€å§‹ï¼ˆå®ä½“è´¨é‡ï¼‰â†’ å¦‚æœå¤ªå·®ï¼Œç›´æ¥æ”¾å¼ƒ
- **æ·±å…¥éªŒè¯**ï¼šå±‚çº§ 2ï¼ˆå…³ç³»è´¨é‡ï¼‰â†’ ç¡®è®¤å…³ç³»æå–ä¸å—å½±å“
- **æœ€ç»ˆéªŒè¯**ï¼šå±‚çº§ 3ï¼ˆç«¯åˆ°ç«¯ RAGï¼‰â†’ ç¡®è®¤ç”¨æˆ·ä½“éªŒå¯æ¥å—

---

## å±‚çº§ 1: å®ä½“æå–è´¨é‡è¯„ä¼°

### 1.1 åˆ›å»ºé»„é‡‘æ ‡å‡†æ•°æ®é›†

**æ–¹æ³• 1: äººå·¥æ ‡æ³¨**ï¼ˆæœ€å‡†ç¡®ï¼Œä½†è€—æ—¶ï¼‰

```bash
# æ­¥éª¤ 1: ä»ä½ çš„è¯­æ–™åº“ä¸­éšæœºæŠ½å– 50-100 ä¸ª chunk
# æ­¥éª¤ 2: ä½¿ç”¨å½“å‰ LLM æ–¹æ³•æå–å®ä½“
python scripts/extract_entities_baseline.py --input samples.txt --output baseline_entities.json

# æ­¥éª¤ 3: äººå·¥å®¡æ ¸å’Œä¿®æ­£ï¼Œåˆ›å»ºé»„é‡‘æ ‡å‡†
# ä½¿ç”¨å·¥å…·å¦‚ Label Studio æˆ–æ‰‹åŠ¨ç¼–è¾‘ JSON
```

**é»„é‡‘æ ‡å‡†æ ¼å¼**ï¼š
```json
{
  "chunks": [
    {
      "chunk_id": "chunk_001",
      "text": "Apple Inc. was founded by Steve Jobs in Cupertino, California.",
      "ground_truth_entities": [
        {"text": "Apple Inc.", "type": "ORGANIZATION"},
        {"text": "Steve Jobs", "type": "PERSON"},
        {"text": "Cupertino", "type": "LOCATION"},
        {"text": "California", "type": "LOCATION"}
      ]
    }
  ]
}
```

**æ–¹æ³• 2: ä½¿ç”¨é«˜è´¨é‡ LLM ä½œä¸ºä¼ªæ ‡æ³¨**ï¼ˆå¿«é€Ÿï¼Œè´¨é‡è¾ƒé«˜ï¼‰

```python
# ä½¿ç”¨ GPT-4o æˆ– Claude 3.5 Sonnet ä½œä¸º"é»„é‡‘æ ‡å‡†"
# ç„¶åæµ‹è¯• GLiNER å’Œå…¶ä»–æ–¹æ³•ä¸ä¹‹çš„ä¸€è‡´æ€§

import asyncio
from openai import AsyncOpenAI

async def create_pseudo_gold_standard(chunks, model="gpt-4o"):
    """ä½¿ç”¨é«˜è´¨é‡ LLM åˆ›å»ºä¼ªé»„é‡‘æ ‡å‡†"""
    client = AsyncOpenAI()

    gold_standard = []
    for chunk in chunks:
        response = await client.chat.completions.create(
            model=model,
            messages=[{
                "role": "user",
                "content": f"""Extract ALL entities from this text. Return JSON array.

Text: {chunk['text']}

Format:
[
  {{"text": "entity name", "type": "PERSON|ORG|LOCATION|CONCEPT|etc"}},
  ...
]"""
            }],
            response_format={"type": "json_object"}
        )

        entities = response.choices[0].message.content
        gold_standard.append({
            "chunk_id": chunk['id'],
            "text": chunk['text'],
            "ground_truth_entities": entities
        })

    return gold_standard
```

### 1.2 è¯„ä¼°æŒ‡æ ‡è®¡ç®—

**æ ¸å¿ƒæŒ‡æ ‡**ï¼š
- **Precisionï¼ˆå‡†ç¡®ç‡ï¼‰**ï¼šæå–çš„å®ä½“ä¸­ï¼Œæœ‰å¤šå°‘æ˜¯æ­£ç¡®çš„
  ```
  Precision = æ­£ç¡®æå–çš„å®ä½“æ•° / æ€»æå–çš„å®ä½“æ•°
  ```

- **Recallï¼ˆå¬å›ç‡ï¼‰**ï¼šçœŸå®å®ä½“ä¸­ï¼Œæœ‰å¤šå°‘è¢«æå–å‡ºæ¥äº†
  ```
  Recall = æ­£ç¡®æå–çš„å®ä½“æ•° / é»„é‡‘æ ‡å‡†ä¸­çš„å®ä½“æ€»æ•°
  ```

- **F1 Scoreï¼ˆè°ƒå’Œå¹³å‡ï¼‰**ï¼šç»¼åˆè¯„ä»·
  ```
  F1 = 2 * (Precision * Recall) / (Precision + Recall)
  ```

**å®ç°ä»£ç **ï¼š

```python
# scripts/evaluate_entity_extraction.py

from typing import List, Dict, Set
import json

def normalize_entity(entity: str) -> str:
    """æ ‡å‡†åŒ–å®ä½“åç§°ï¼ˆå»é™¤ç©ºæ ¼ã€ç»Ÿä¸€å¤§å°å†™ç­‰ï¼‰"""
    return entity.strip().lower()

def calculate_entity_metrics(
    predicted_entities: List[Dict[str, str]],
    ground_truth_entities: List[Dict[str, str]],
    match_type: bool = False  # æ˜¯å¦è¦æ±‚ç±»å‹ä¹ŸåŒ¹é…
) -> Dict[str, float]:
    """
    è®¡ç®—å®ä½“æå–çš„ Precision, Recall, F1

    Args:
        predicted_entities: é¢„æµ‹çš„å®ä½“åˆ—è¡¨ [{"text": "...", "type": "..."}]
        ground_truth_entities: é»„é‡‘æ ‡å‡†å®ä½“åˆ—è¡¨
        match_type: True = å®ä½“åå’Œç±»å‹éƒ½è¦åŒ¹é…ï¼ŒFalse = åªåŒ¹é…å®ä½“å

    Returns:
        {"precision": 0.85, "recall": 0.90, "f1": 0.87}
    """
    if match_type:
        # å®ä½“å + ç±»å‹ä¸€èµ·åŒ¹é…ï¼ˆä¸¥æ ¼æ¨¡å¼ï¼‰
        pred_set = {
            (normalize_entity(e["text"]), e["type"])
            for e in predicted_entities
        }
        gold_set = {
            (normalize_entity(e["text"]), e["type"])
            for e in ground_truth_entities
        }
    else:
        # åªåŒ¹é…å®ä½“åï¼ˆå®½æ¾æ¨¡å¼ï¼‰
        pred_set = {normalize_entity(e["text"]) for e in predicted_entities}
        gold_set = {normalize_entity(e["text"]) for e in ground_truth_entities}

    # è®¡ç®—äº¤é›†ï¼ˆæ­£ç¡®æå–çš„å®ä½“ï¼‰
    true_positives = len(pred_set & gold_set)

    # è®¡ç®— Precision å’Œ Recall
    precision = true_positives / len(pred_set) if pred_set else 0
    recall = true_positives / len(gold_set) if gold_set else 0

    # è®¡ç®— F1
    f1 = (
        2 * (precision * recall) / (precision + recall)
        if (precision + recall) > 0
        else 0
    )

    return {
        "precision": round(precision, 4),
        "recall": round(recall, 4),
        "f1": round(f1, 4),
        "true_positives": true_positives,
        "false_positives": len(pred_set) - true_positives,
        "false_negatives": len(gold_set) - true_positives,
    }


def evaluate_on_dataset(
    predictions_file: str,
    gold_standard_file: str,
    match_type: bool = False
) -> Dict[str, any]:
    """
    åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°

    Returns:
        {
            "overall_metrics": {"precision": 0.85, "recall": 0.90, "f1": 0.87},
            "per_chunk_metrics": [...],
            "summary": {...}
        }
    """
    with open(predictions_file) as f:
        predictions = json.load(f)

    with open(gold_standard_file) as f:
        gold_standard = json.load(f)

    # æŒ‰ chunk è®¡ç®—æŒ‡æ ‡
    per_chunk_metrics = []
    total_tp, total_fp, total_fn = 0, 0, 0

    for pred_chunk, gold_chunk in zip(predictions["chunks"], gold_standard["chunks"]):
        assert pred_chunk["chunk_id"] == gold_chunk["chunk_id"]

        metrics = calculate_entity_metrics(
            pred_chunk["entities"],
            gold_chunk["ground_truth_entities"],
            match_type=match_type
        )

        per_chunk_metrics.append({
            "chunk_id": pred_chunk["chunk_id"],
            **metrics
        })

        total_tp += metrics["true_positives"]
        total_fp += metrics["false_positives"]
        total_fn += metrics["false_negatives"]

    # è®¡ç®—æ•´ä½“æŒ‡æ ‡ï¼ˆmicro-averageï¼‰
    overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0
    overall_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0
    overall_f1 = (
        2 * (overall_precision * overall_recall) / (overall_precision + overall_recall)
        if (overall_precision + overall_recall) > 0
        else 0
    )

    return {
        "overall_metrics": {
            "precision": round(overall_precision, 4),
            "recall": round(overall_recall, 4),
            "f1": round(overall_f1, 4),
        },
        "per_chunk_metrics": per_chunk_metrics,
        "summary": {
            "total_chunks": len(per_chunk_metrics),
            "total_true_positives": total_tp,
            "total_false_positives": total_fp,
            "total_false_negatives": total_fn,
        }
    }


if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šè¯„ä¼° GLiNER ä¸ LLM çš„å¯¹æ¯”

    # 1. è¯„ä¼°åŸºçº¿ LLM
    llm_results = evaluate_on_dataset(
        predictions_file="results/llm_predictions.json",
        gold_standard_file="data/gold_standard.json",
        match_type=False  # åªåŒ¹é…å®ä½“åï¼Œä¸è¦æ±‚ç±»å‹å®Œå…¨ä¸€è‡´
    )

    print("=== LLM å®ä½“æå–è´¨é‡ ===")
    print(f"Precision: {llm_results['overall_metrics']['precision']:.2%}")
    print(f"Recall:    {llm_results['overall_metrics']['recall']:.2%}")
    print(f"F1 Score:  {llm_results['overall_metrics']['f1']:.2%}")

    # 2. è¯„ä¼° GLiNER
    gliner_results = evaluate_on_dataset(
        predictions_file="results/gliner_predictions.json",
        gold_standard_file="data/gold_standard.json",
        match_type=False
    )

    print("\n=== GLiNER å®ä½“æå–è´¨é‡ ===")
    print(f"Precision: {gliner_results['overall_metrics']['precision']:.2%}")
    print(f"Recall:    {gliner_results['overall_metrics']['recall']:.2%}")
    print(f"F1 Score:  {gliner_results['overall_metrics']['f1']:.2%}")

    # 3. å¯¹æ¯”
    f1_diff = gliner_results['overall_metrics']['f1'] - llm_results['overall_metrics']['f1']
    print(f"\n=== è´¨é‡å·®å¼‚ ===")
    print(f"F1 å·®å¼‚: {f1_diff:+.2%}")

    if abs(f1_diff) < 0.05:
        print("âœ… è´¨é‡å·®å¼‚ < 5%ï¼Œå¯ä»¥æ¥å—")
    elif f1_diff < 0:
        print(f"âš ï¸  GLiNER è´¨é‡ä¸‹é™ {abs(f1_diff):.1%}ï¼Œéœ€è¦æƒè¡¡é€Ÿåº¦æ”¶ç›Š")
    else:
        print(f"ğŸ‰ GLiNER è´¨é‡æå‡ {f1_diff:.1%}ï¼")
```

### 1.3 è¿è¡Œè¯„ä¼°

**å®Œæ•´æµç¨‹**ï¼š

```bash
# æ­¥éª¤ 1: åˆ›å»ºæµ‹è¯•æ•°æ®é›†ï¼ˆéšæœºæŠ½å– 100 ä¸ª chunksï¼‰
python scripts/create_test_dataset.py \
    --input_dir ./your_documents \
    --output data/test_chunks.json \
    --num_samples 100

# æ­¥éª¤ 2: ä½¿ç”¨å½“å‰ LLM æ–¹æ³•åˆ›å»ºé»„é‡‘æ ‡å‡†
python scripts/create_gold_standard.py \
    --input data/test_chunks.json \
    --output data/gold_standard.json \
    --model gpt-4o  # ä½¿ç”¨é«˜è´¨é‡æ¨¡å‹

# æ­¥éª¤ 3: ä½¿ç”¨ GLiNER æå–å®ä½“
python scripts/extract_with_gliner.py \
    --input data/test_chunks.json \
    --output results/gliner_predictions.json

# æ­¥éª¤ 4: è¯„ä¼°è´¨é‡
python scripts/evaluate_entity_extraction.py \
    --predictions results/gliner_predictions.json \
    --gold_standard data/gold_standard.json
```

**é¢„æœŸè¾“å‡º**ï¼š

```
=== GLiNER å®ä½“æå–è´¨é‡ ===
Precision: 87.50%  â† æå–çš„å®ä½“ä¸­æœ‰ 87.5% æ˜¯æ­£ç¡®çš„
Recall:    82.30%  â† çœŸå®å®ä½“ä¸­æœ‰ 82.3% è¢«æå–å‡ºæ¥
F1 Score:  84.82%  â† ç»¼åˆè¯„åˆ†

ä¸ LLM åŸºçº¿å¯¹æ¯”:
F1 å·®å¼‚: -3.2%    â† GLiNER æ¯” LLM è´¨é‡ä¸‹é™ 3.2%

è¯¦ç»†åˆ†æ:
- True Positives:  164 ä¸ªæ­£ç¡®æå–
- False Positives: 23 ä¸ªé”™è¯¯æå–ï¼ˆå¹»è§‰ï¼‰
- False Negatives: 35 ä¸ªé—æ¼å®ä½“

é€Ÿåº¦æå‡: 15x faster (150ms vs 10ms per chunk)

ç»“è®º: å¯æ¥å— - è´¨é‡è½»å¾®ä¸‹é™ä½†é€Ÿåº¦å¤§å¹…æå‡
```

---

## å±‚çº§ 2: å…³ç³»æå–è´¨é‡è¯„ä¼°

### 2.1 ä¸ºä»€ä¹ˆå…³ç³»æå–æ›´é‡è¦ï¼Ÿ

åœ¨ RAG ç³»ç»Ÿä¸­ï¼Œ**å…³ç³»è´¨é‡ > å®ä½“è´¨é‡**ï¼Œå› ä¸ºï¼š

1. **çŸ¥è¯†å›¾è°±çš„æ ¸å¿ƒæ˜¯å…³ç³»**ï¼šå®ä½“åªæ˜¯èŠ‚ç‚¹ï¼Œå…³ç³»æ‰æ˜¯è¿æ¥
2. **æŸ¥è¯¢ä¾èµ–å…³ç³»**ï¼šLightRAG çš„ `mix` æ¨¡å¼éœ€è¦éå†å…³ç³»å›¾
3. **å…³ç³»é”™è¯¯å½±å“æ›´å¤§**ï¼šé”™è¯¯çš„å…³ç³»ä¼šå¯¼è‡´å®Œå…¨é”™è¯¯çš„æ¨ç†è·¯å¾„

### 2.2 å…³ç³»æå–è¯„ä¼°æŒ‡æ ‡

**åŒæ ·ä½¿ç”¨ Precision, Recall, F1**ï¼Œä½†åŒ¹é…è§„åˆ™æ›´å¤æ‚ï¼š

```python
def calculate_relation_metrics(
    predicted_relations: List[Dict],
    ground_truth_relations: List[Dict],
    match_mode: str = "strict"  # "strict", "relaxed", "directional"
) -> Dict[str, float]:
    """
    è®¡ç®—å…³ç³»æå–çš„ Precision, Recall, F1

    Args:
        predicted_relations: [{"source": "A", "target": "B", "type": "FOUNDED"}]
        ground_truth_relations: é»„é‡‘æ ‡å‡†å…³ç³»
        match_mode:
            - "strict": è¦æ±‚ source, target, type å®Œå…¨åŒ¹é…
            - "relaxed": åªè¦æ±‚ source, target åŒ¹é…ï¼Œå¿½ç•¥ type
            - "directional": å¿½ç•¥æ–¹å‘ï¼Œ(A->B) == (B->A)

    Returns:
        {"precision": 0.80, "recall": 0.75, "f1": 0.77}
    """
    def normalize_relation(rel: Dict) -> tuple:
        source = normalize_entity(rel["source"])
        target = normalize_entity(rel["target"])
        rel_type = rel.get("type", "RELATED")

        if match_mode == "strict":
            return (source, target, rel_type)
        elif match_mode == "relaxed":
            return (source, target)
        elif match_mode == "directional":
            # æ— å‘å…³ç³»ï¼š(A, B) == (B, A)
            return tuple(sorted([source, target]))

    pred_set = {normalize_relation(r) for r in predicted_relations}
    gold_set = {normalize_relation(r) for r in ground_truth_relations}

    true_positives = len(pred_set & gold_set)

    precision = true_positives / len(pred_set) if pred_set else 0
    recall = true_positives / len(gold_set) if gold_set else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    return {
        "precision": round(precision, 4),
        "recall": round(recall, 4),
        "f1": round(f1, 4),
        "true_positives": true_positives,
        "false_positives": len(pred_set) - true_positives,
        "false_negatives": len(gold_set) - true_positives,
    }
```

### 2.3 æ··åˆæ¶æ„çš„å…³ç³»è¯„ä¼°

**å…³é”®é—®é¢˜**ï¼šå¦‚æœç”¨ GLiNER æå–å®ä½“ï¼Œå†ç”¨ LLM æå–å…³ç³»ï¼Œè´¨é‡ä¼šä¸‹é™å—ï¼Ÿ

**æµ‹è¯•æ–¹æ³•**ï¼š

```bash
# æµ‹è¯• 1: LLM å®ä½“ + LLM å…³ç³»ï¼ˆåŸºçº¿ï¼‰
python scripts/extract_relations.py \
    --entity_method llm \
    --relation_method llm \
    --output results/baseline_relations.json

# æµ‹è¯• 2: GLiNER å®ä½“ + LLM å…³ç³»ï¼ˆæ··åˆï¼‰
python scripts/extract_relations.py \
    --entity_method gliner \
    --relation_method llm \
    --output results/hybrid_relations.json

# å¯¹æ¯”è´¨é‡
python scripts/evaluate_relation_extraction.py \
    --predictions results/hybrid_relations.json \
    --baseline results/baseline_relations.json \
    --gold_standard data/gold_standard_relations.json
```

**å¯èƒ½çš„ç»“æœ**ï¼š

```
=== å…³ç³»æå–è´¨é‡å¯¹æ¯” ===

åŸºçº¿ (LLM + LLM):
  Precision: 85.2%
  Recall:    81.5%
  F1:        83.3%

æ··åˆ (GLiNER + LLM):
  Precision: 84.1%  â† è½»å¾®ä¸‹é™
  Recall:    80.2%  â† è½»å¾®ä¸‹é™
  F1:        82.1%  â† ä¸‹é™ 1.2%

é€Ÿåº¦å¯¹æ¯”:
  åŸºçº¿: 250ms per chunk
  æ··åˆ: 120ms per chunk  â† æé€Ÿ 2.1x

ç»“è®º:
âœ… å¯æ¥å— - è´¨é‡ä¸‹é™ <2%ï¼Œä½†é€Ÿåº¦æå‡ 2x
```

---

## å±‚çº§ 3: ç«¯åˆ°ç«¯ RAG è´¨é‡è¯„ä¼°

### 3.1 ä½¿ç”¨ LightRAG å†…ç½®çš„ RAGAS è¯„ä¼°

LightRAG å·²ç»å†…ç½®äº† RAGAS è¯„ä¼°æ¡†æ¶ï¼ˆ`lightrag/evaluation/eval_rag_quality.py`ï¼‰ã€‚

**è¿è¡Œæµç¨‹**ï¼š

```bash
# æ­¥éª¤ 1: å‡†å¤‡æµ‹è¯•é—®é¢˜é›†
cat > lightrag/evaluation/my_test.json << 'EOF'
{
  "test_cases": [
    {
      "question": "What is the relationship between Apple and Steve Jobs?",
      "ground_truth": "Steve Jobs co-founded Apple Inc. in 1976 and served as CEO.",
      "project": "tech_companies"
    },
    {
      "question": "Where is Apple headquartered?",
      "ground_truth": "Apple is headquartered in Cupertino, California.",
      "project": "tech_companies"
    }
  ]
}
EOF

# æ­¥éª¤ 2: è¿è¡Œ LightRAG æœåŠ¡å™¨ï¼ˆä½¿ç”¨åŸºçº¿æ–¹æ³•ï¼‰
python -m lightrag.api.lightrag_server

# æ­¥éª¤ 3: è¯„ä¼°åŸºçº¿
python lightrag/evaluation/eval_rag_quality.py \
    --dataset lightrag/evaluation/my_test.json \
    --ragendpoint http://localhost:9621

# æ­¥éª¤ 4: åˆ‡æ¢åˆ°æ··åˆæ–¹æ³•
# ä¿®æ”¹ä»£ç ä½¿ç”¨ GLiNER + LLM
# é‡å¯æœåŠ¡å™¨

# æ­¥éª¤ 5: è¯„ä¼°æ··åˆæ–¹æ³•
python lightrag/evaluation/eval_rag_quality.py \
    --dataset lightrag/evaluation/my_test.json \
    --ragendpoint http://localhost:9621
```

### 3.2 RAGAS æŒ‡æ ‡è§£è¯»

RAGAS æä¾› 4 ä¸ªæ ¸å¿ƒæŒ‡æ ‡ï¼š

1. **Faithfulnessï¼ˆå¿ å®åº¦ï¼‰**ï¼šç­”æ¡ˆæ˜¯å¦åŸºäºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ï¼Ÿ
   - æµ‹é‡ï¼šLLM æ˜¯å¦åœ¨æ²¡æœ‰è¯æ®çš„æƒ…å†µä¸‹"å¹»è§‰"
   - æœŸæœ›å€¼ï¼š> 0.8

2. **Answer Relevanceï¼ˆç­”æ¡ˆç›¸å…³æ€§ï¼‰**ï¼šç­”æ¡ˆæ˜¯å¦å›ç­”äº†é—®é¢˜ï¼Ÿ
   - æµ‹é‡ï¼šç­”æ¡ˆä¸é—®é¢˜çš„è¯­ä¹‰ç›¸ä¼¼åº¦
   - æœŸæœ›å€¼ï¼š> 0.85

3. **Context Recallï¼ˆä¸Šä¸‹æ–‡å¬å›ï¼‰**ï¼šæ˜¯å¦æ£€ç´¢åˆ°æ‰€æœ‰ç›¸å…³ä¿¡æ¯ï¼Ÿ
   - æµ‹é‡ï¼šé»„é‡‘æ ‡å‡†ç­”æ¡ˆä¸­çš„ä¿¡æ¯æœ‰å¤šå°‘å‡ºç°åœ¨æ£€ç´¢çš„ä¸Šä¸‹æ–‡ä¸­
   - æœŸæœ›å€¼ï¼š> 0.75

4. **Context Precisionï¼ˆä¸Šä¸‹æ–‡å‡†ç¡®æ€§ï¼‰**ï¼šæ£€ç´¢çš„ä¸Šä¸‹æ–‡æ˜¯å¦å¹²å‡€æ— å™ªéŸ³ï¼Ÿ
   - æµ‹é‡ï¼šæ£€ç´¢çš„ä¸Šä¸‹æ–‡ä¸­æœ‰å¤šå°‘æ˜¯çœŸæ­£ç›¸å…³çš„
   - æœŸæœ›å€¼ï¼š> 0.70

### 3.3 å¯¹æ¯”åˆ†æ

**ç¤ºä¾‹å¯¹æ¯”è¡¨æ ¼**ï¼š

| æ–¹æ³• | Faithfulness | Answer Relevance | Context Recall | Context Precision | RAGAS Score | é€Ÿåº¦ (s/query) |
|------|-------------|------------------|----------------|-------------------|-------------|----------------|
| LLM + LLMï¼ˆåŸºçº¿ï¼‰| 0.87 | 0.91 | 0.82 | 0.75 | **0.84** | 3.2 |
| GLiNER + LLMï¼ˆæ··åˆï¼‰| 0.85 | 0.89 | 0.79 | 0.73 | **0.82** | 1.5 |
| å·®å¼‚ | -0.02 | -0.02 | -0.03 | -0.02 | **-0.02** | **-53%** |

**ç»“è®º**ï¼š
- âœ… RAGAS Score ä¸‹é™ 2%ï¼Œåœ¨å¯æ¥å—èŒƒå›´å†…
- âœ… æŸ¥è¯¢é€Ÿåº¦æå‡ 53%
- âœ… æ¨èä½¿ç”¨æ··åˆæ–¹æ³•

---

## å®é™…è¯„ä¼°æ¡ˆä¾‹

### æ¡ˆä¾‹ç ”ç©¶ï¼šæŠ€æœ¯æ–‡æ¡£ RAG ç³»ç»Ÿ

**èƒŒæ™¯**ï¼š
- è¯­æ–™åº“ï¼š5000 ä¸ªæŠ€æœ¯æ–‡æ¡£ï¼ˆAPI æ–‡æ¡£ã€æ•™ç¨‹ç­‰ï¼‰
- å½“å‰æ–¹æ³•ï¼šQwen3-4Bï¼ˆMLXï¼Œ150 tokens/sï¼‰
- ç›®æ ‡ï¼šæé€Ÿä½†ä¿æŒè´¨é‡

**è¯„ä¼°æµç¨‹**ï¼š

#### é˜¶æ®µ 1: å®ä½“æå–è´¨é‡

```bash
# 1. åˆ›å»º 100 ä¸ªæ ·æœ¬çš„é»„é‡‘æ ‡å‡†
python scripts/create_gold_standard.py \
    --input_dir docs/ \
    --num_samples 100 \
    --model gpt-4o \
    --output data/tech_docs_gold.json

# 2. æµ‹è¯• GLiNER
python scripts/test_gliner.py \
    --gold_standard data/tech_docs_gold.json \
    --output results/gliner_tech.json

# 3. è¯„ä¼°
python scripts/evaluate_entity_extraction.py \
    --predictions results/gliner_tech.json \
    --gold_standard data/tech_docs_gold.json
```

**ç»“æœ**ï¼š

```
GLiNER vs Qwen3-4B (å®ä½“æå–):

Precision: 83.2% vs 88.5%  (-5.3%)
Recall:    78.9% vs 85.1%  (-6.2%)
F1:        81.0% vs 86.7%  (-5.7%)

é€Ÿåº¦: 12ms vs 180ms per chunk (15x faster)

åˆ†æ:
- GLiNER åœ¨"æŠ€æœ¯æ¦‚å¿µ"å®ä½“ä¸Šè¡¨ç°è¾ƒå·®ï¼ˆå¦‚ "API endpoint", "callback function"ï¼‰
- GLiNER åœ¨æ ‡å‡†å®ä½“ï¼ˆäººåã€å…¬å¸åï¼‰ä¸Šè¡¨ç°æ¥è¿‘
```

**å†³ç­–ç‚¹ 1**ï¼šF1 ä¸‹é™ 5.7%ï¼Œæ˜¯å¦ç»§ç»­ï¼Ÿ
- âœ… ç»§ç»­ - é€Ÿåº¦æå‡æ˜¾è‘—ï¼Œä¸”å¯ä»¥ä¼˜åŒ–

#### é˜¶æ®µ 2: å…³ç³»æå–è´¨é‡

```bash
# æµ‹è¯•æ··åˆæ–¹æ³•çš„å…³ç³»æå–
python scripts/test_hybrid_relations.py \
    --entity_method gliner \
    --relation_method qwen \
    --gold_standard data/tech_docs_gold.json \
    --output results/hybrid_relations.json
```

**ç»“æœ**ï¼š

```
å…³ç³»æå–è´¨é‡:

åŸºçº¿ (Qwen + Qwen):  F1 = 79.2%
æ··åˆ (GLiNER + Qwen): F1 = 76.8%  (-2.4%)

å…³é”®å‘ç°:
- å®ä½“é”™è¯¯ä¼ æ’­åˆ°å…³ç³»æå–
- é”™è¯¯ä¸»è¦åœ¨æŠ€æœ¯æ¦‚å¿µä¹‹é—´çš„å…³ç³»ï¼ˆå¦‚ "uses", "implements"ï¼‰
```

**å†³ç­–ç‚¹ 2**ï¼šå…³ç³» F1 ä¸‹é™ 2.4%ï¼Œæ˜¯å¦å¯æ¥å—ï¼Ÿ
- âš ï¸ éœ€è¦æµ‹è¯•ç«¯åˆ°ç«¯æ•ˆæœ

#### é˜¶æ®µ 3: ç«¯åˆ°ç«¯ RAG è¯„ä¼°

```bash
# å‡†å¤‡ 20 ä¸ªçœŸå®ç”¨æˆ·é—®é¢˜
python scripts/create_rag_test_cases.py \
    --output lightrag/evaluation/tech_docs_test.json

# æµ‹è¯•åŸºçº¿
python lightrag/evaluation/eval_rag_quality.py \
    --dataset lightrag/evaluation/tech_docs_test.json

# åˆ‡æ¢åˆ°æ··åˆæ–¹æ³•åé‡æ–°æµ‹è¯•
# ï¼ˆä¿®æ”¹ LightRAG ä½¿ç”¨ GLiNERï¼‰
python lightrag/evaluation/eval_rag_quality.py \
    --dataset lightrag/evaluation/tech_docs_test.json
```

**ç»“æœ**ï¼š

```
RAGAS è¯„ä¼°ç»“æœ:

                    Faithfulness  Answer Rel  Context Rec  Context Prec  Overall
åŸºçº¿ (Qwen + Qwen)    0.89          0.92        0.85         0.78         0.86
æ··åˆ (GLiNER + Qwen)  0.87          0.90        0.82         0.76         0.84

å·®å¼‚                  -2.2%         -2.2%       -3.5%        -2.6%        -2.3%

ç”¨æˆ·ä½“éªŒæµ‹è¯•ï¼ˆç›²æµ‹ 10 ä¸ªé—®é¢˜ï¼‰:
- ç­”æ¡ˆè´¨é‡ç›¸å½“ï¼š8/10 æ— æ˜æ˜¾å·®å¼‚
- æ··åˆæ–¹æ³•ç•¥å·®ï¼š2/10 æ¼æ‰å…³é”®æŠ€æœ¯æ¦‚å¿µ

é€Ÿåº¦å¯¹æ¯”:
- ç´¢å¼•æ—¶é—´ï¼š5.2h â†’ 2.1h  (60% faster)
- æŸ¥è¯¢æ—¶é—´ï¼š3.2s â†’ 1.8s  (44% faster)
```

**æœ€ç»ˆå†³ç­–**ï¼š
- âœ… **é‡‡ç”¨æ··åˆæ–¹æ³•**
- ç†ç”±ï¼š
  1. RAGAS ä¸‹é™ 2.3%ï¼ˆå¯æ¥å—èŒƒå›´å†…ï¼‰
  2. ç´¢å¼•é€Ÿåº¦æå‡ 60%ï¼ˆèŠ‚çœå¤§é‡æ—¶é—´ï¼‰
  3. æŸ¥è¯¢é€Ÿåº¦æå‡ 44%ï¼ˆç”¨æˆ·ä½“éªŒæ”¹å–„ï¼‰
  4. ç›²æµ‹ä¸­ 80% é—®é¢˜æ— å·®å¼‚

**ä¼˜åŒ–æªæ–½**ï¼š
- ä¸ºæŠ€æœ¯æ¦‚å¿µåˆ›å»ºè‡ªå®šä¹‰å®ä½“ç±»å‹åˆ—è¡¨
- ä½¿ç”¨ GLiNER fine-tuning åœ¨æŠ€æœ¯æ–‡æ¡£ä¸Š
- ä¿ç•™ LLM ä½œä¸º fallbackï¼ˆå¯¹ä¸ç¡®å®šçš„ chunk ä½¿ç”¨ LLMï¼‰

---

## è´¨é‡é˜ˆå€¼å»ºè®®

### ä½•æ—¶å¯ä»¥ä½¿ç”¨æ··åˆæ–¹æ³•ï¼Ÿ

| æŒ‡æ ‡ | æœ€ä½é˜ˆå€¼ | æ¨èé˜ˆå€¼ | è¯´æ˜ |
|------|---------|---------|------|
| å®ä½“ F1 å·®å¼‚ | < 10% | < 5% | ç›¸æ¯”åŸºçº¿çš„ä¸‹é™å¹…åº¦ |
| å…³ç³» F1 å·®å¼‚ | < 8% | < 3% | å…³ç³»æ¯”å®ä½“æ›´é‡è¦ |
| RAGAS Score å·®å¼‚ | < 5% | < 2% | ç«¯åˆ°ç«¯è´¨é‡ |
| Context Recall å·®å¼‚ | < 10% | < 5% | ä¸èƒ½æ¼æ‰å¤ªå¤šä¿¡æ¯ |

### å†³ç­–çŸ©é˜µ

```
è´¨é‡ä¸‹é™ vs é€Ÿåº¦æå‡çš„æƒè¡¡:

            é€Ÿåº¦æå‡
            1-2x    2-5x    5-10x   >10x
è´¨é‡  0-2%   âœ…      âœ…      âœ…      âœ…
ä¸‹é™  2-5%   âš ï¸      âœ…      âœ…      âœ…
      5-10%  âŒ      âš ï¸      âœ…      âœ…
      >10%   âŒ      âŒ      âš ï¸      âœ…

âœ… = æ¨èä½¿ç”¨
âš ï¸ = éœ€è¦è¯¦ç»†è¯„ä¼°
âŒ = ä¸æ¨è
```

---

## å·¥å…·å’Œä»£ç æ¨¡æ¿

### å®Œæ•´è¯„ä¼°è„šæœ¬

LightRAG é¡¹ç›®ä¸­å¯ä»¥æ·»åŠ è¿™äº›è„šæœ¬ï¼š

```bash
# åˆ›å»ºè¯„ä¼°å·¥å…·ç›®å½•
mkdir -p scripts/evaluation

# 1. åˆ›å»ºé»„é‡‘æ ‡å‡†
scripts/evaluation/create_gold_standard.py

# 2. è¯„ä¼°å®ä½“æå–
scripts/evaluation/evaluate_entities.py

# 3. è¯„ä¼°å…³ç³»æå–
scripts/evaluation/evaluate_relations.py

# 4. ç«¯åˆ°ç«¯ RAG è¯„ä¼°ï¼ˆå·²æœ‰ï¼‰
lightrag/evaluation/eval_rag_quality.py

# 5. ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
scripts/evaluation/generate_comparison_report.py
```

### ä¸€é”®è¯„ä¼°å‘½ä»¤

```bash
# è¿è¡Œå®Œæ•´è¯„ä¼°æµç¨‹
./scripts/run_quality_benchmark.sh \
    --baseline llm \
    --candidate gliner \
    --num_samples 100 \
    --output reports/gliner_vs_llm.html
```

è¿™ä¼šè‡ªåŠ¨ï¼š
1. åˆ›å»ºæµ‹è¯•æ•°æ®é›†
2. è¿è¡ŒåŸºçº¿å’Œå€™é€‰æ–¹æ³•
3. è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
4. ç”Ÿæˆ HTML æŠ¥å‘Š

---

## æ€»ç»“

### è¯„ä¼°æµç¨‹æ€»ç»“

```mermaid
graph TD
    A[å¼€å§‹è¯„ä¼°] --> B[åˆ›å»ºé»„é‡‘æ ‡å‡†æ•°æ®é›†]
    B --> C{è¯„ä¼°å®ä½“æå–}
    C -->|F1 < 80%| D[âŒ æ”¾å¼ƒæ··åˆæ–¹æ³•]
    C -->|F1 â‰¥ 80%| E{è¯„ä¼°å…³ç³»æå–}
    E -->|F1 < 75%| D
    E -->|F1 â‰¥ 75%| F{è¯„ä¼°ç«¯åˆ°ç«¯ RAG}
    F -->|RAGAS < 0.75| D
    F -->|RAGAS â‰¥ 0.75| G{è´¨é‡vsé€Ÿåº¦æƒè¡¡}
    G -->|å€¼å¾—| H[âœ… é‡‡ç”¨æ··åˆæ–¹æ³•]
    G -->|ä¸å€¼å¾—| D
```

### å…³é”®è¦ç‚¹

1. **åˆ†å±‚è¯„ä¼°**ï¼š
   - å…ˆè¯„ä¼°å®ä½“ï¼ˆæœ€å®¹æ˜“ï¼‰
   - å†è¯„ä¼°å…³ç³»ï¼ˆä¸­ç­‰éš¾åº¦ï¼‰
   - æœ€åè¯„ä¼°ç«¯åˆ°ç«¯ï¼ˆæœ€é‡è¦ï¼‰

2. **è´¨é‡é˜ˆå€¼**ï¼š
   - å®ä½“ F1 > 80%
   - å…³ç³» F1 > 75%
   - RAGAS Score > 0.75
   - ç›¸æ¯”åŸºçº¿ä¸‹é™ < 5%

3. **é€Ÿåº¦æ”¶ç›Š**ï¼š
   - å¦‚æœé€Ÿåº¦æå‡ > 2xï¼Œè´¨é‡ä¸‹é™ 2-5% å¯æ¥å—
   - å¦‚æœé€Ÿåº¦æå‡ > 5xï¼Œè´¨é‡ä¸‹é™ 5-8% å¯æ¥å—

4. **å®é™…æµ‹è¯•**ï¼š
   - åœ¨çœŸå®æ•°æ®ä¸Šæµ‹è¯•ï¼ˆä¸è¦åªç”¨å…¬å¼€æ•°æ®é›†ï¼‰
   - åŒ…å«é¢†åŸŸç‰¹å®šå®ä½“ï¼ˆå¦‚æŠ€æœ¯æœ¯è¯­ï¼‰
   - è¿›è¡Œç›²æµ‹éªŒè¯

5. **æŒç»­ç›‘æ§**ï¼š
   - éƒ¨ç½²åæŒç»­ç›‘æ§ RAGAS æŒ‡æ ‡
   - æ”¶é›†ç”¨æˆ·åé¦ˆ
   - å®šæœŸé‡æ–°è¯„ä¼°

---

## ä¸‹ä¸€æ­¥

ä½ ç°åœ¨å¯ä»¥ï¼š

1. **å¿«é€ŸéªŒè¯**ï¼šä½¿ç”¨ 50 ä¸ªæ ·æœ¬æµ‹è¯• GLiNER vs LLM
2. **è¯¦ç»†è¯„ä¼°**ï¼šè¿è¡Œå®Œæ•´çš„ä¸‰å±‚è¯„ä¼°
3. **éƒ¨ç½²å†³ç­–**ï¼šæ ¹æ®è¯„ä¼°ç»“æœå†³å®šæ˜¯å¦é‡‡ç”¨æ··åˆæ–¹æ³•

éœ€è¦æˆ‘å¸®ä½ ï¼š
- åˆ›å»ºè¯„ä¼°è„šæœ¬ï¼Ÿ
- è®¾è®¡æµ‹è¯•æ•°æ®é›†ï¼Ÿ
- è¿è¡Œå®é™…è¯„ä¼°ï¼Ÿ
