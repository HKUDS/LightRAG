### This is sample file of .env

### Server Configuration
# HOST=0.0.0.0
# PORT=9621
# WORKERS=1
# NAMESPACE_PREFIX=lightrag  # separating data from difference Lightrag instances
# MAX_GRAPH_NODES=1000       # Max nodes return from grap retrieval
# CORS_ORIGINS=http://localhost:3000,http://localhost:8080

### Optional SSL Configuration
# SSL=true
# SSL_CERTFILE=/path/to/cert.pem
# SSL_KEYFILE=/path/to/key.pem

### Security (empty for no api-key is needed)
# LIGHTRAG_API_KEY=your-secure-api-key-here

### Directory Configuration
# WORKING_DIR=<absolute_path_for_working_dir>
# INPUT_DIR=<absolute_path_for_doc_input_dir>

### Ollama Emulating Model Tag
# OLLAMA_EMULATING_MODEL_TAG=latest

### Logging level
# LOG_LEVEL=INFO
# VERBOSE=False
# LOG_DIR=/path/to/log/directory  # Log file directory path, defaults to current working directory
# LOG_MAX_BYTES=10485760          # Log file max size in bytes, defaults to 10MB
# LOG_BACKUP_COUNT=5              # Number of backup files to keep, defaults to 5

### Settings for RAG query
# HISTORY_TURNS=3
# COSINE_THRESHOLD=0.2
# TOP_K=60
# MAX_TOKEN_TEXT_CHUNK=4000
# MAX_TOKEN_RELATION_DESC=4000
# MAX_TOKEN_ENTITY_DESC=4000

### Settings for document indexing
# SUMMARY_LANGUAGE=English
# CHUNK_SIZE=1200
# CHUNK_OVERLAP_SIZE=100
# MAX_TOKEN_SUMMARY=500                # Max tokens for entity or relations summary
# MAX_PARALLEL_INSERT=2                # Number of parallel processing documents in one patch
# MAX_ASYNC=4                          # Max concurrency requests of LLM
# ENABLE_LLM_CACHE_FOR_EXTRACT=true    # Enable LLM cache for entity extraction

# EMBEDDING_BATCH_NUM=32               # num of chunks send to Embedding in one request
# EMBEDDING_FUNC_MAX_ASYNC=16          # Max concurrency requests for Embedding
# MAX_EMBED_TOKENS=8192

### LLM Configuration (Use valid host. For local services installed with docker, you can use host.docker.internal)
# MAX_TOKENS=32768             # Max tokens send to LLM (less than context size of the model)
# TIMEOUT=150                  # Time out in seconds for LLM, None for infinite timeout
LLM_BINDING=ollama
LLM_MODEL=mistral-nemo:latest
LLM_BINDING_API_KEY=your_api_key
### Ollama example
LLM_BINDING_HOST=http://localhost:11434
### OpenAI alike example
# LLM_BINDING=openai
# LLM_MODEL=gpt-4o
# LLM_BINDING_HOST=https://api.openai.com/v1
# LLM_BINDING_API_KEY=your_api_key
### lollms example
# LLM_BINDING=lollms
# LLM_MODEL=mistral-nemo:latest
# LLM_BINDING_HOST=http://localhost:9600
# LLM_BINDING_API_KEY=your_api_key

### Embedding Configuration (Use valid host. For local services installed with docker, you can use host.docker.internal)
EMBEDDING_MODEL=bge-m3:latest
EMBEDDING_DIM=1024
# EMBEDDING_BINDING_API_KEY=your_api_key
### ollama example
EMBEDDING_BINDING=ollama
EMBEDDING_BINDING_HOST=http://localhost:11434
### OpenAI alike example
# EMBEDDING_BINDING=openai
# LLM_BINDING_HOST=https://api.openai.com/v1
### Lollms example
# EMBEDDING_BINDING=lollms
# EMBEDDING_BINDING_HOST=http://localhost:9600

### Optional for Azure (LLM_BINDING_HOST, LLM_BINDING_API_KEY take priority)
# AZURE_OPENAI_API_VERSION=2024-08-01-preview
# AZURE_OPENAI_DEPLOYMENT=gpt-4o
# AZURE_OPENAI_API_KEY=your_api_key
# AZURE_OPENAI_ENDPOINT=https://myendpoint.openai.azure.com

# AZURE_EMBEDDING_DEPLOYMENT=text-embedding-3-large
# AZURE_EMBEDDING_API_VERSION=2023-05-15

### Data storage selection
LIGHTRAG_KV_STORAGE=JsonKVStorage
LIGHTRAG_VECTOR_STORAGE=NanoVectorDBStorage
LIGHTRAG_GRAPH_STORAGE=NetworkXStorage
LIGHTRAG_DOC_STATUS_STORAGE=JsonDocStatusStorage

### Oracle Database Configuration
ORACLE_DSN=localhost:1521/XEPDB1
ORACLE_USER=your_username
ORACLE_PASSWORD='your_password'
ORACLE_CONFIG_DIR=/path/to/oracle/config
#ORACLE_WALLET_LOCATION=/path/to/wallet  # optional
#ORACLE_WALLET_PASSWORD='your_password'  # optional
#ORACLE_WORKSPACE=default  # separating all data from difference Lightrag instances(deprecated, use NAMESPACE_PREFIX in future)

### TiDB Configuration
TIDB_HOST=localhost
TIDB_PORT=4000
TIDB_USER=your_username
TIDB_PASSWORD='your_password'
TIDB_DATABASE=your_database
#TIDB_WORKSPACE=default  # separating all data from difference Lightrag instances(deprecated, use NAMESPACE_PREFIX in future)

### PostgreSQL Configuration
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=your_username
POSTGRES_PASSWORD='your_password'
POSTGRES_DATABASE=your_database
#POSTGRES_WORKSPACE=default  # separating all data from difference Lightrag instances(deprecated, use NAMESPACE_PREFIX in future)

### Independent AGM Configuration(not for AMG embedded in PostreSQL)
AGE_POSTGRES_DB=
AGE_POSTGRES_USER=
AGE_POSTGRES_PASSWORD=
AGE_POSTGRES_HOST=
# AGE_POSTGRES_PORT=8529

# AGE Graph Name(apply to PostgreSQL and independent AGM)
# AGE_GRAPH_NAME=lightrag  # deprecated, use NAME_SPACE_PREFIX instead

### Neo4j Configuration
NEO4J_URI=neo4j+s://xxxxxxxx.databases.neo4j.io
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD='your_password'

### MongoDB Configuration
MONGODB_URI=mongodb://root:root@localhost:27017/
MONGODB_DATABASE=LightRAG
MONGODB_GRAPH=false # deprecated (keep for backward compatibility)

### Qdrant
QDRANT_URL=http://localhost:16333
# QDRANT_API_KEY=your-api-key

### Redis
REDIS_URI=redis://localhost:6379

### For JWT Auth
# AUTH_ACCOUNTS='admin:admin123,user1:pass456'     # username:password,username:password
# TOKEN_SECRET=Your-Key-For-LightRAG-API-Server    # JWT key
# TOKEN_EXPIRE_HOURS=4                             # expire duration
# WHITELIST_PATHS=                                 # white list
