import os
import asyncio
from lightrag import LightRAG
from lightrag.utils import EmbeddingFunc
from lightrag.llm.ollama import ollama_embed
from lightrag.llm.openai import azure_openai_complete 
from lightrag.base import DocStatus  # å¼•å…¥ DocStatus æšèˆ‰
from functools import partial
from dotenv import load_dotenv

load_dotenv()

# === è¨­å®š ===
WORKING_DIR = "./data/rag_storage"
OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://localhost:11434")
EMBEDDING_MODEL = "bge-m3"
EMBEDDING_DIM = 1024

# === ğŸ¯ å®šç¾©ä½ è¦åˆªé™¤çš„æ–‡ä»¶é—œéµå­— ===
# åªè¦æ–‡ä»¶è·¯å¾‘ (file_path) åŒ…å«é€™äº›å­—ï¼Œå°±æœƒè¢«åˆªé™¤
TARGET_FILES_TO_DELETE = [
    "0001_2024",
    "0775_2024",
    "1038_2024",
    "1366_2024",
    "Global Market Insights",
    "HSBC_Report_Source_A",
    "SFC",
    "Strategic Investment Partners",
    "HSBC_Report_Source_B",
    # "SFC_Report_2023.pdf",   # ä¾‹å­ï¼šå®Œæ•´æ–‡ä»¶å
    # "Draft_v1",              # ä¾‹å­ï¼šæ–‡ä»¶åçš„ä¸€éƒ¨åˆ†
    # "Old_Data_Folder"        # ä¾‹å­ï¼šæŸå€‹æ–‡ä»¶å¤¾ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
]

async def find_ids_by_filename(rag, targets):
    """
    éæ­·æ‰€æœ‰ç‹€æ…‹çš„æ–‡æª”ï¼Œå°‹æ‰¾åŒ¹é…æ–‡ä»¶åçš„ ID
    """
    print("ğŸ” æ­£åœ¨æƒææ•¸æ“šåº«ä¸­çš„æ–‡æª”...")
    
    found_ids = set()
    
    # æˆ‘å€‘éœ€è¦æª¢æŸ¥æ‰€æœ‰å¯èƒ½çš„ç‹€æ…‹
    statuses_to_check = [
        DocStatus.PROCESSED, 
        DocStatus.FAILED, 
        DocStatus.PENDING, 
        DocStatus.PROCESSING
    ]
    
    total_scanned = 0
    
    for status in statuses_to_check:
        # ç²å–è©²ç‹€æ…‹ä¸‹çš„æ‰€æœ‰æ–‡æª”
        docs_dict = await rag.doc_status.get_docs_by_status(status)
        
        for doc_id, doc_obj in docs_dict.items():
            total_scanned += 1
            # ç²å–æ–‡ä»¶è·¯å¾‘ (å…¼å®¹å­—å…¸æˆ–å°è±¡è¨ªå•)
            file_path = getattr(doc_obj, "file_path", "") or doc_obj.get("file_path", "")
            
            # æª¢æŸ¥æ˜¯å¦åŒ…å«æˆ‘å€‘è¦åˆªé™¤çš„é—œéµå­—
            for target in targets:
                if target in file_path:
                    print(f"   ğŸ¯ æ‰¾åˆ°ç›®æ¨™: {file_path} (ID: {doc_id}) [Status: {status}]")
                    found_ids.add(doc_id)
                    break # æ‰¾åˆ°ä¸€å€‹é—œéµå­—åŒ¹é…å°±å¤ äº†
                    
    print(f"ğŸ“Š æƒæå®Œæˆ: å…±æª¢æŸ¥ {total_scanned} å€‹æ–‡æª”ï¼Œæ‰¾åˆ° {len(found_ids)} å€‹å¾…åˆªé™¤ã€‚")
    return list(found_ids)

async def main():
    print(f"ğŸš€ åˆå§‹åŒ– LightRAG ä»¥é€²è¡Œæ¸…ç†...")
    
    rag = LightRAG(
        working_dir=WORKING_DIR,
        llm_model_func=azure_openai_complete, 
        embedding_func=EmbeddingFunc(
            embedding_dim=EMBEDDING_DIM,
            max_token_size=8192,
            func=partial(
                ollama_embed, 
                host=OLLAMA_HOST,
                embed_model=EMBEDDING_MODEL
            )
        )
    )

    print("âš™ï¸ æ­£åœ¨åˆå§‹åŒ– Storage...")
    await rag.initialize_storages()

    # 1. æ ¹æ“šæ–‡ä»¶åæŸ¥æ‰¾ ID
    if not TARGET_FILES_TO_DELETE:
        print("âš ï¸ æ²’æœ‰è¨­å®šè¦åˆªé™¤çš„æ–‡ä»¶å (TARGET_FILES_TO_DELETE ç‚ºç©º)ã€‚")
        return

    ids_to_delete = await find_ids_by_filename(rag, TARGET_FILES_TO_DELETE)

    if not ids_to_delete:
        print("âœ… æ²’æœ‰ç™¼ç¾éœ€è¦åˆªé™¤çš„æ–‡ä»¶ï¼Œç³»çµ±ä¹¾æ·¨ã€‚")
        return

    # 2. ç”¨æˆ¶ç¢ºèª (é˜²æ­¢èª¤åˆª)
    confirm = input(f"âš ï¸ å³å°‡åˆªé™¤ {len(ids_to_delete)} å€‹æ–‡æª” (åŒ…å«ç›¸é—œçš„ Chunks å’Œ Graph Nodes)ã€‚ç¢ºå®šå—? (y/n): ")
    if confirm.lower() != 'y':
        print("âŒ æ“ä½œå·²å–æ¶ˆã€‚")
        return

    # 3. åŸ·è¡Œåˆªé™¤
    print(f"ğŸ—‘ï¸ é–‹å§‹åˆªé™¤...")
    
    for i, doc_id in enumerate(ids_to_delete):
        try:
            print(f" [{i+1}/{len(ids_to_delete)}] æ­£åœ¨åˆªé™¤ ID: {doc_id} ...")
            
            # èª¿ç”¨ LightRAG çš„åˆªé™¤æ¥å£
            await rag.adelete_by_doc_id(doc_id)
            
            print(f"   âœ… åˆªé™¤æˆåŠŸ")
        except Exception as e:
            # å¿½ç•¥ "Not found" éŒ¯èª¤ï¼Œå› ç‚ºå¯èƒ½å·²ç¶“è¢«æ¸…ç†é
            if "not found" in str(e).lower():
                print(f"   âš ï¸ æ–‡æª”å·²ä¸å­˜åœ¨ (è¦–ç‚ºæˆåŠŸ)")
            else:
                print(f"   âŒ åˆªé™¤å¤±æ•—: {str(e)}")

    print("ğŸ æ‰€æœ‰æŒ‡å®šæ–‡ä»¶æ¸…ç†å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(main())