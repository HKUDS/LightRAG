import sys
import os
import subprocess
import json
import glob
import time
from loguru import logger

# === 1. è¨­å®š Logging (çµ±ä¸€é¢¨æ ¼) ===
LOG_DIR = "./logs"
if not os.path.exists(LOG_DIR):
    os.makedirs(LOG_DIR)

# è¨­å®š Log æª”æ¡ˆå
log_file = os.path.join(LOG_DIR, f"step1_run_{time.strftime('%Y%m%d_%H%M%S')}.log")

# é‡ç½® Logger è¨­å®š
logger.remove() 

# Handler 1: Console (è¢å¹•è¼¸å‡º - ç°¡æ½”)
logger.add(sys.stderr, format="<green>{time:HH:mm:ss}</green> | <level>{message}</level>", level="INFO")

# Handler 2: File (æª”æ¡ˆç´€éŒ„ - è©³ç´°)
logger.add(log_file, rotation="10 MB", level="DEBUG", encoding="utf-8")

logger.info(f"ğŸ“ Log æª”æ¡ˆå·²å»ºç«‹: {log_file}")
# ==========================================

def process_single_file(input_path, output_base_dir, step1_std_base_dir, config):
    filename = os.path.basename(input_path)
    file_stem = os.path.splitext(filename)[0]
    ext = os.path.splitext(filename)[1].lower()
    
    # å»ºç«‹å°ˆå±¬è³‡æ–™å¤¾
    current_file_std_dir = os.path.join(step1_std_base_dir, file_stem)
    
    if not os.path.exists(current_file_std_dir):
        os.makedirs(current_file_std_dir)
        logger.info(f"ğŸ“‚ å·²å»ºç«‹å°ˆå±¬ç›®éŒ„: {current_file_std_dir}")

    logger.info("="*60)
    logger.info(f"ğŸš€ [Start] æ­£åœ¨è™•ç†: {filename}")
    logger.info(f"ğŸ“ è·¯å¾‘: {input_path}")
    logger.info("="*60)

    start_time = time.time()

    # === [ç­–ç•¥ A] é‡å°ç´”æ–‡å­—æª” (.txt / .md) çš„ç‰¹æ®Šè™•ç† (Bypass Mineru) ===
    if ext in ['.txt', '.md']:
        logger.info(f"ğŸ“„ æª¢æ¸¬åˆ°ç´”æ–‡å­—æª” ({ext})ï¼Œè·³é Mineruï¼Œç›´æ¥è½‰æ›æ ¼å¼...")
        
        try:
            with open(input_path, "r", encoding="utf-8") as f:
                content = f.read()
            
            # æ§‹é€  Step 2 éœ€è¦çš„ JSON æ ¼å¼
            # Step 2 æœŸæœ›: [{"type": "text", "text": "...", "page_idx": 0}]
            mock_data = [{
                "type": "text",
                "text": content,
                "page_idx": 0,
                # è£œä¸Šå‡è³‡æ–™ä»¥é˜² Step 2 å ±éŒ¯
                "bbox": [0, 0, 0, 0], 
                "img_path": ""
            }]
            
            final_json_path = os.path.join(current_file_std_dir, "intermediate_result.json")
            
            with open(final_json_path, "w", encoding="utf-8") as f:
                json.dump(mock_data, f, ensure_ascii=False, indent=2)
                
            duration = time.time() - start_time
            logger.success(f"âœ… è½‰æ›æˆåŠŸï¼(Text Bypass Mode) è€—æ™‚: {duration:.2f} ç§’")
            logger.success(f"ğŸ’¾ æª”æ¡ˆå·²å„²å­˜: {final_json_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ è®€å–æ–‡å­—æª”å¤±æ•—: {e}")
            return False

    # === [ç­–ç•¥ B] é‡å° PDFï¼Œå‘¼å« Mineru ===
    # çµ„åˆæŒ‡ä»¤
    cmd = [
        "uv", "run", "mineru",
        "-p", input_path,
        "-o", output_base_dir,
        "-m", "auto",
        "-b", config["use_backend"],
        "-d", config["use_device"]
    ]

    logger.info(f"ğŸ”§ åŸ·è¡Œ Mineru æŒ‡ä»¤: {' '.join(cmd)}")

    try:
        # ä½¿ç”¨ Popen å³æ™‚æŠ“å– Mineru çš„è¼¸å‡º
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT, 
            text=True,
            encoding='utf-8',
            errors='replace'
        )

        for line in process.stdout:
            line = line.strip()
            if line:
                logger.info(f"   [Mineru] {line}")

        return_code = process.wait()

        if return_code != 0:
            logger.error(f"âŒ Mineru åŸ·è¡Œå¤±æ•—ï¼ŒReturn Code: {return_code}")
            # å¦‚æœä¸æ˜¯ PDFï¼ŒMineru å¤±æ•—æ˜¯æ­£å¸¸çš„ï¼Œä¸éœ€è¦å¤ªé©šæ…Œ
            return False 

        # --- å¾ŒçºŒ JSON è™•ç†é‚è¼¯ (Mineru æˆåŠŸå¾Œ) ---
        possible_paths = [
            os.path.join(output_base_dir, file_stem, config["use_backend"], f"{file_stem}_content_list.json"),
            os.path.join(output_base_dir, file_stem, f"{file_stem}_content_list.json"),
        ]
        
        target_json = None
        for p in possible_paths:
            if os.path.exists(p):
                target_json = p
                break
        
        if target_json:
            final_json_name = "intermediate_result.json"
            final_json_path = os.path.join(current_file_std_dir, final_json_name)
            
            try:
                with open(target_json, "r", encoding="utf-8") as f:
                    data = json.load(f)
                
                with open(final_json_path, "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                
                duration = time.time() - start_time
                logger.success(f"âœ… è§£ææˆåŠŸï¼è€—æ™‚: {duration:.2f} ç§’")
                logger.success(f"ğŸ’¾ ä¸­é–“æª”å·²å„²å­˜æ–¼: {final_json_path}")
                return True

            except Exception as json_err:
                logger.error(f"âš ï¸ JSON è®€å¯«éŒ¯èª¤: {json_err}")
                return False
        else:
            logger.error(f"âŒ Mineru é›–ç„¶è·‘å®Œ (Code 0)ï¼Œä½†æ‰¾ä¸åˆ°è¼¸å‡ºçš„ JSON æª”æ¡ˆã€‚")
            return False

    except Exception as e:
        logger.exception(f"âš ï¸ ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}") 
        return False

def main():
    # === è¨­å®šå€ ===
    input_dir = "./data/input/__enqueued__"
    output_dir = "./data/output/step1_vlm_output"
    
    # è¼¸å‡ºæ ¹ç›®éŒ„
    step1_std_base_dir = "./data/input/step1_output" 
    
    config = {
        "use_backend": "vlm-transformers",
        "use_device": "cpu"
    }
    
    FORCE_RERUN = False 
    
    # ğŸ›‘ æ’é™¤åå–® (å…¨éƒ¨è½‰å°å¯«æ¯”å°)
    EXCLUDE_FILES = ["sfc.pdf", "sfc_report.pdf"] 
    # ============

    if not os.path.exists(input_dir):
        logger.error(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥è³‡æ–™å¤¾: {input_dir}")
        return

    if not os.path.exists(step1_std_base_dir):
        os.makedirs(step1_std_base_dir)

    # ğŸŒŸ é—œéµä¿®æ”¹ï¼šæƒææ‰€æœ‰æª”æ¡ˆ (ä¸é™ PDF) ğŸŒŸ
    all_entries = glob.glob(os.path.join(input_dir, "*"))
    files = []
    
    logger.info(f"ğŸ” æ­£åœ¨æƒææ‰€æœ‰æª”æ¡ˆ...")
    
    for entry in all_entries:
        if os.path.isfile(entry):
            filename = os.path.basename(entry)
            # éæ¿¾éš±è—æª”
            if not filename.startswith("."):
                files.append(entry)

    if not files:
        logger.warning(f"ğŸ“‚ è³‡æ–™å¤¾ {input_dir} å…§æ‰¾ä¸åˆ°ä»»ä½•æª”æ¡ˆ")
        return

    logger.info(f"ğŸ“¦ ç™¼ç¾ {len(files)} å€‹æª”æ¡ˆï¼Œæº–å‚™é–‹å§‹æ‰¹æ¬¡è™•ç†...")
    
    success_count = 0
    fail_count = 0
    skipped_count = 0

    for i, file_path in enumerate(files):
        logger.info(f"\nâ³ [ç¸½é€²åº¦: {i+1}/{len(files)}]")
        
        filename = os.path.basename(file_path)
        file_stem = os.path.splitext(filename)[0]

        # === ğŸ›‘ æª¢æŸ¥æ˜¯å¦åœ¨æ’é™¤åå–® ===
        if filename.lower() in EXCLUDE_FILES:
            logger.info(f"ğŸ›‘ æª¢æ¸¬åˆ°æ’é™¤æª”æ¡ˆï¼Œæ˜ç¢ºè·³é: {filename}")
            skipped_count += 1
            continue
        
        # --- ğŸ”„ æª¢æŸ¥æ˜¯å¦å·²è™•ç† (Resume Logic) ---
        expected_output_path = os.path.join(step1_std_base_dir, file_stem, "intermediate_result.json")
        
        if not FORCE_RERUN and os.path.exists(expected_output_path):
            logger.info(f"â­ï¸  æª¢æ¸¬åˆ°æª”æ¡ˆå·²å­˜åœ¨ï¼Œè·³éè™•ç†: {filename}")
            skipped_count += 1
            success_count += 1 
            continue
        # ----------------------------------------
        
        # åŸ·è¡Œå–®å€‹æª”æ¡ˆè™•ç†
        if process_single_file(file_path, output_dir, step1_std_base_dir, config):
            success_count += 1
        else:
            fail_count += 1

    logger.info("\n" + "="*60)
    logger.info(f"ğŸ æ‰€æœ‰ä½œæ¥­å®Œæˆï¼")
    logger.info(f"ğŸ“Š çµ±è¨ˆ: ç¸½æ•¸ {len(files)} | âœ… å®Œæˆ/è·³é {success_count} | â­ï¸ è·³é {skipped_count} | âŒ å¤±æ•— {fail_count}")
    logger.info(f"ğŸ“ è©³ç´° Log è«‹æŸ¥çœ‹: {LOG_DIR}")

if __name__ == "__main__":
    main()