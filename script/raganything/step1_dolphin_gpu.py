import sys
import os
import json
import glob
import time
import math
import gc
import io
import torch
import pymupdf  # ğŸ”¥ å®˜æ–¹ä½¿ç”¨çš„ PDF å¼•æ“ (ç„¡éœ€ Poppler)
from PIL import Image
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig
from qwen_vl_utils import process_vision_info
from loguru import logger

# ==========================================
# ğŸ”¥ [ä½¿ç”¨è€…è¨­å®šå€]
# ==========================================

# 1. è·¯å¾‘è¨­å®š
INPUT_DIR = "./data/input/__enqueued__"
OUTPUT_DIR_BASE = "./data/input/step1_output"

# 2. æ¨¡å‹è¨­å®š
MODEL_ID = "ByteDance/Dolphin-v2"

# 3. ç•«è³ªèˆ‡æ•ˆèƒ½è¨­å®š (RTX 4060 8GB å°ˆç”¨)
# è¨­å®šè®€å–æ™‚çš„ DPI (300 DPI = é«˜ç•«è³ªï¼ŒPyMuPDF é€Ÿåº¦å¾ˆå¿«ï¼Œé€™æ²’å•é¡Œ)
RENDER_DPI = 300 

# Token é™åˆ¶ (ä¿è­· VRAM ä¸çˆ†)
# 14000 tokens â‰ˆ 274è¬åƒç´  (è¶³å¤ çœ‹æ¸…çµ•å¤§å¤šæ•¸ A4 æ–‡ä»¶)
MAX_VISUAL_TOKENS = 14000 

# å­˜æª”é »ç‡ (æ¯å¹¾é å­˜ä¸€æ¬¡)
SAVE_INTERVAL = 5 

# ==========================================

# === 0. ç’°å¢ƒæº–å‚™ ===
# è¨­å®š Logging
LOG_DIR = "./logs"
if not os.path.exists(LOG_DIR): os.makedirs(LOG_DIR)
log_file = os.path.join(LOG_DIR, f"step1_official_gpu_{time.strftime('%Y%m%d_%H%M%S')}.log")

logger.remove()
logger.add(sys.stderr, format="<green>{time:HH:mm:ss}</green> | <level>{message}</level>", level="INFO")
logger.add(log_file, rotation="10 MB", level="DEBUG", encoding="utf-8")
logger.info(f"ğŸ“ Log æª”æ¡ˆå·²å»ºç«‹: {log_file}")

# === 1. æ ¸å¿ƒå‡½å¼ ===

def resize_to_token_limit(image, max_tokens=14000):
    """
    æ™ºæ…§ç¸®åœ–ï¼šç¢ºä¿åœ–ç‰‡ä¸æœƒç”¢ç”Ÿéå¤š Token å°è‡´ OOM
    """
    w, h = image.size
    total_pixels = w * h
    current_tokens = total_pixels / 196 # Qwen2.5-VL: 1 token â‰ˆ 14x14 pixels
    
    if current_tokens > max_tokens:
        scale = math.sqrt(max_tokens / current_tokens)
        new_w = int(w * scale)
        new_h = int(h * scale)
        logger.debug(f"ğŸ“‰ åœ–ç‰‡å£“ç¸®: {w}x{h} -> {new_w}x{new_h} (Tokens: {int(current_tokens)} -> ~{max_tokens})")
        return image.resize((new_w, new_h), Image.Resampling.LANCZOS)
    
    return image

def render_pdf_page(doc, page_index, dpi=200):
    """
    ä½¿ç”¨ PyMuPDF æ¸²æŸ“å–®é  PDF ç‚º PIL Image
    """
    try:
        page = doc[page_index]
        # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹ (72 dpi æ˜¯ PDF æ¨™æº–è§£æåº¦)
        zoom = dpi / 72.0
        mat = pymupdf.Matrix(zoom, zoom)
        
        # ç²å–åƒç´ åœ–
        pix = page.get_pixmap(matrix=mat, alpha=False)
        
        # è½‰æ›ç‚º PIL Image
        img_data = pix.tobytes("png")
        return Image.open(io.BytesIO(img_data))
    except Exception as e:
        logger.error(f"âŒ PyMuPDF æ¸²æŸ“å¤±æ•— (Page {page_index}): {e}")
        return None

def load_model():
    """
    è¼‰å…¥æ¨¡å‹ (4-bit é‡åŒ– + GPU åŠ é€Ÿ)
    """
    logger.info("="*60)
    logger.info(f"ğŸ“¥ æ­£åœ¨è¼‰å…¥æ¨¡å‹: {MODEL_ID} (4-bit Official Mode)...")
    
    if not torch.cuda.is_available():
        logger.critical("âŒ æª¢æ¸¬ä¸åˆ° GPUï¼è«‹ç¢ºèª CUDA æ˜¯å¦å®‰è£æ­£ç¢ºã€‚")
        sys.exit(1)

    gpu_name = torch.cuda.get_device_name(0)
    logger.info(f"ğŸ® GPU åµæ¸¬: {gpu_name}")

    try:
        quantization_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_compute_dtype=torch.bfloat16,
            bnb_4bit_use_double_quant=True,
            bnb_4bit_quant_type="nf4"
        )
        
        processor = AutoProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)
        model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
            MODEL_ID,
            quantization_config=quantization_config,
            device_map="auto",
            trust_remote_code=True
        )
        
        logger.success("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆï¼")
        return model, processor
    except Exception as e:
        logger.critical(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        sys.exit(1)

def process_single_file(input_path, output_base, model, processor):
    filename = os.path.basename(input_path)
    file_stem = os.path.splitext(filename)[0]
    
    # å»ºç«‹è¼¸å‡ºç›®éŒ„
    current_out_dir = os.path.join(output_base, file_stem)
    if not os.path.exists(current_out_dir): os.makedirs(current_out_dir)
    final_json = os.path.join(current_out_dir, "intermediate_result.json")
    images_dir = os.path.join(current_out_dir, "images")
    if not os.path.exists(images_dir): os.makedirs(images_dir)

    logger.info("-" * 40)
    logger.info(f"ğŸš€ [Start] è™•ç†æª”æ¡ˆ: {filename}")
    start_time = time.time()

    # 1. é–‹å•Ÿ PDF (PyMuPDF)
    try:
        doc = pymupdf.open(input_path)
        total_pages = len(doc)
        logger.info(f"ğŸ“„ PDF ç¸½é æ•¸: {total_pages}")
    except Exception as e:
        logger.error(f"âŒ ç„¡æ³•é–‹å•Ÿ PDF: {e}")
        return False

    parsed_results = []
    
    # 2. é€é è™•ç†
    for i in range(total_pages):
        page_start = time.time()
        logger.info(f"   ğŸ”„ æ­£åœ¨è™•ç† Page {i+1}/{total_pages}...")

        try:
            # ğŸ”¥ æ¸²æŸ“ï¼šä½¿ç”¨å®˜æ–¹åº« PyMuPDF
            image = render_pdf_page(doc, i, dpi=RENDER_DPI)
            
            if image is None:
                logger.warning(f"âš ï¸ Page {i+1} æ¸²æŸ“å¤±æ•—ï¼Œè·³éã€‚")
                continue
            
            # å„²å­˜åŸåœ– (Debug ç”¨)
            img_filename = f"page_{i}.jpg"
            image.save(os.path.join(images_dir, img_filename))

            # æ™ºæ…§ç¸®æ”¾ (ä¿è­· VRAM)
            image = resize_to_token_limit(image, max_tokens=MAX_VISUAL_TOKENS)

            # å»ºæ§‹ Prompt
            messages = [{
                "role": "user",
                "content": [
                    {"type": "image", "image": image},
                    {"type": "text", "text": "Read the text in the image word by word and transcribe it into Markdown format. Represent tables using Markdown syntax."}
                ]
            }]

            # æº–å‚™è¼¸å…¥ Tensor
            text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
            image_inputs, video_inputs = process_vision_info(messages)
            
            inputs = processor(
                text=[text], 
                images=image_inputs, 
                videos=video_inputs, 
                padding=True, 
                return_tensors="pt"
            ).to(model.device)

            # æ¨ç† (GPU)
            with torch.no_grad():
                generated_ids = model.generate(
                    **inputs,
                    max_new_tokens=2048,
                    do_sample=False
                )

            # è§£ç¢¼
            gen_ids_trimmed = [out[len(inp):] for inp, out in zip(inputs.input_ids, generated_ids)]
            md_text = processor.batch_decode(gen_ids_trimmed, skip_special_tokens=True)[0]

            # æ”¶é›†çµæœ
            parsed_results.append({
                "type": "text",
                "text": md_text,
                "page_idx": i,
                "img_path": f"images/{img_filename}",
                "bbox": [0, 0, image.width, image.height]
            })

            dur = time.time() - page_start
            vram_usage = torch.cuda.memory_allocated()/1e9
            logger.info(f"     âœ… å®Œæˆ ({dur:.2f}s) | VRAM: {vram_usage:.2f}GB")

            # ğŸ”¥ å®šæœŸå­˜æª”
            if (i + 1) % SAVE_INTERVAL == 0 or (i + 1) == total_pages:
                with open(final_json, "w", encoding="utf-8") as f:
                    json.dump(parsed_results, f, ensure_ascii=False, indent=2)
                logger.debug(f"ğŸ’¾ é€²åº¦å·²å„²å­˜ (Page {i+1})")

        except torch.cuda.OutOfMemoryError:
            logger.error(f"âŒ Page {i+1} OOM (é¡¯å­˜ä¸è¶³)ï¼è·³éæ­¤é ã€‚")
            torch.cuda.empty_cache()
        except Exception as e:
            logger.exception(f"âŒ Page {i+1} ç™¼ç”ŸéŒ¯èª¤: {e}")
        finally:
            # æ¸…ç†é¡¯å­˜
            if 'inputs' in locals(): del inputs
            if 'generated_ids' in locals(): del generated_ids
            if 'image' in locals(): del image
            torch.cuda.empty_cache()
            gc.collect()

    doc.close()
    logger.success(f"ğŸ‰ æª”æ¡ˆè™•ç†å®Œæˆï¼ç¸½è€—æ™‚: {time.time() - start_time:.2f}s")
    return True

def main():
    if not os.path.exists(INPUT_DIR):
        logger.error(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥ç›®éŒ„: {INPUT_DIR}")
        return
    if not os.path.exists(OUTPUT_DIR_BASE):
        os.makedirs(OUTPUT_DIR_BASE)

    # æª¢æŸ¥æ˜¯å¦å®‰è£äº† PyMuPDF
    try:
        import pymupdf
    except ImportError:
        logger.error("âŒ ç¼ºå°‘ PyMuPDFï¼è«‹åŸ·è¡Œ: `uv pip install pymupdf`")
        return

    # è¼‰å…¥æ¨¡å‹
    model, processor = load_model()

    # æƒææª”æ¡ˆ
    all_files = glob.glob(os.path.join(INPUT_DIR, "*"))
    files = [f for f in all_files if os.path.isfile(f) and not os.path.basename(f).startswith(".")]
    
    logger.info(f"ğŸ“¦ ç™¼ç¾ {len(files)} å€‹æª”æ¡ˆï¼Œæº–å‚™é–‹å§‹...")

    for idx, file_path in enumerate(files):
        logger.info(f"\n[{idx+1}/{len(files)}] ----------------------------------------")
        
        if not file_path.lower().endswith(".pdf"):
            logger.warning(f"â­ï¸ è·³éé PDF æª”æ¡ˆ: {file_path}")
            continue
            
        process_single_file(file_path, OUTPUT_DIR_BASE, model, processor)

    logger.success("\nğŸ æ‰€æœ‰ä»»å‹™åŸ·è¡Œå®Œç•¢ï¼")

if __name__ == "__main__":
    main()