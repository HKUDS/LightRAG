import sys
import os
import json
import glob
import time
import math
import io
import psutil
import torch
import pymupdf  # ğŸ”¥ å–ä»£ pdf2image (å®˜æ–¹ Dolphin ä½¿ç”¨é€™å€‹)
from PIL import Image
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
from qwen_vl_utils import process_vision_info
from loguru import logger

# ==========================================
# ğŸ”¥ [ä½¿ç”¨è€…è¨­å®šå€]
# ==========================================

# 1. è·¯å¾‘è¨­å®š
INPUT_DIR = "./data/input/__enqueued__"
OUTPUT_DIR_BASE = "./data/input/step1_output"

# 2. æ¨¡å‹è¨­å®š
MODEL_ID = "ByteDance/Dolphin-v2"

# 3. ç•«è³ªè¨­å®š (PyMuPDF Zoom Factor)
# æ¨™æº– PDF æ˜¯ 72 DPIã€‚è¨­å®š zoom=4.16 å¤§ç´„ç­‰æ–¼ 300 DPI (é«˜å“è³ªå°åˆ·æ¨™æº–)
# é€™æ¨£èƒ½ç¢ºä¿å°å­—é«”ä¹Ÿèƒ½è¢«ç²¾ç¢ºè­˜åˆ¥
PDF_ZOOM = 300 / 72  # ~4.166

# 4. Token é™åˆ¶ (ä¿è­· RAM)
# 25000 tokens â‰ˆ 490è¬åƒç´ ã€‚
# é…åˆ CPU æ¨¡å¼ï¼Œé€™å€‹è¨­å®šèƒ½åƒä¸‹ A4 å…¨é é«˜ç•«è³ªç´°ç¯€ã€‚
MAX_VISUAL_TOKENS = 25000 

# æ¯å¹¾é å­˜æª”ä¸€æ¬¡
SAVE_INTERVAL = 1

# ==========================================

# è¨­å®š Logging
LOG_DIR = "./logs"
if not os.path.exists(LOG_DIR): os.makedirs(LOG_DIR)
log_file = os.path.join(LOG_DIR, f"step1_dolphin_official_{time.strftime('%Y%m%d_%H%M%S')}.log")

logger.remove()
logger.add(sys.stderr, format="<green>{time:HH:mm:ss}</green> | <level>{message}</level>", level="INFO")
logger.add(log_file, rotation="10 MB", level="DEBUG", encoding="utf-8")
logger.info(f"ğŸ“ Log æª”æ¡ˆå·²å»ºç«‹: {log_file}")

# === è¼”åŠ©å‡½å¼ ===

def get_ram_usage():
    """å–å¾—ç›®å‰ç³»çµ± RAM ä½¿ç”¨é‡ (GB)"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / (1024 ** 3)

def resize_to_token_limit(image, max_tokens=25000):
    """
    æ™ºæ…§ç¸®åœ–ï¼šé˜²æ­¢è¶…å¤§åœ–ç‰‡å°è‡´æ¨ç†éæ…¢
    """
    w, h = image.size
    total_pixels = w * h
    current_tokens = total_pixels / 196  # Qwen2.5-VL patch size 14x14
    
    if current_tokens > max_tokens:
        scale = math.sqrt(max_tokens / current_tokens)
        new_w = int(w * scale)
        new_h = int(h * scale)
        logger.info(f"ğŸ“‰ [Resize] åœ–ç‰‡éå¤§: {w}x{h} -> {new_w}x{new_h} (Tokens: {int(current_tokens)} -> ~{max_tokens})")
        return image.resize((new_w, new_h), Image.Resampling.LANCZOS)
    
    return image

def load_model():
    """
    è¼‰å…¥æ¨¡å‹ (CPU High-Quality Mode)
    """
    logger.info("="*60)
    logger.info(f"ğŸ“¥ æ­£åœ¨è¼‰å…¥æ¨¡å‹: {MODEL_ID} (CPU + PyMuPDF)...")
    logger.info("âš ï¸ æ³¨æ„ï¼šCPU æ¨ç†é€Ÿåº¦è¼ƒæ…¢ï¼Œè«‹è€å¿ƒç­‰å¾…ã€‚")
    
    try:
        processor = AutoProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)
        # ä½¿ç”¨ float32 ç¢ºä¿ CPU ä¸Šçš„æœ€ä½³ç›¸å®¹æ€§èˆ‡ç•«è³ª
        model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
            MODEL_ID,
            torch_dtype=torch.float32, 
            device_map="cpu",          
            trust_remote_code=True
        )
        logger.success(f"âœ… æ¨¡å‹è¼‰å…¥å®Œæˆï¼ç›®å‰ RAM ä½¿ç”¨: {get_ram_usage():.2f} GB")
        return model, processor
    except Exception as e:
        logger.critical(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        sys.exit(1)

def process_single_file(input_path, output_base, model, processor):
    filename = os.path.basename(input_path)
    file_stem = os.path.splitext(filename)[0]
    
    # å»ºç«‹è¼¸å‡ºç›®éŒ„
    current_out_dir = os.path.join(output_base, file_stem)
    if not os.path.exists(current_out_dir): os.makedirs(current_out_dir)
    final_json = os.path.join(current_out_dir, "intermediate_result.json")
    images_dir = os.path.join(current_out_dir, "images")
    if not os.path.exists(images_dir): os.makedirs(images_dir)

    logger.info("-" * 40)
    logger.info(f"ğŸš€ [Start] è™•ç†æª”æ¡ˆ: {filename}")
    
    start_time = time.time()

    # === ğŸ”¥ [æ ¸å¿ƒä¿®æ”¹] ä½¿ç”¨ PyMuPDF è®€å– PDF ===
    try:
        doc = pymupdf.open(input_path)
        total_pages = len(doc)
        logger.info(f"ğŸ“„ PDF ç¸½é æ•¸: {total_pages} (Engine: PyMuPDF)")
    except Exception as e:
        logger.error(f"âŒ ç„¡æ³•è®€å– PDF: {e}")
        return False

    parsed_results = []
    
    # é€é è™•ç†
    for i in range(total_pages):
        # æ³¨æ„: PyMuPDF é ç¢¼å¾ 0 é–‹å§‹
        page_start = time.time()
        logger.info(f"   ğŸ”„ æ­£åœ¨è™•ç† Page {i+1}/{total_pages} ...")

        try:
            # 1. æ¸²æŸ“é é¢ (Render Page)
            page = doc[i]
            # è¨­å®šç¸®æ”¾çŸ©é™£ (æ§åˆ¶ DPI)
            mat = pymupdf.Matrix(PDF_ZOOM, PDF_ZOOM)
            pix = page.get_pixmap(matrix=mat, alpha=False) # alpha=False ç§»é™¤é€æ˜é€šé“ï¼Œè½‰ç‚º RGB
            
            # 2. è½‰æ›ç‚º PIL Image
            # æ–¹æ³•åƒè€ƒå®˜æ–¹ utils.py: ä½¿ç”¨ tobytes("png") å†ç”¨ PIL é–‹å•Ÿï¼Œæœ€ç©©å¥
            img_data = pix.tobytes("png")
            image = Image.open(io.BytesIO(img_data))
            
            # å„²å­˜åŸåœ–å‚™ä»½
            img_filename = f"page_{i}.jpg"
            image.save(os.path.join(images_dir, img_filename))

            # 3. æ™ºæ…§ç¸®æ”¾ (Token Limit)
            image = resize_to_token_limit(image, max_tokens=MAX_VISUAL_TOKENS)

            # 4. å»ºæ§‹ Prompt
            messages = [{
                "role": "user",
                "content": [
                    {"type": "image", "image": image},
                    {"type": "text", "text": "Read the text in the image word by word and transcribe it into Markdown format. Represent tables using Markdown syntax."}
                ]
            }]

            # 5. æ¨ç† (Inference)
            text_inputs = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
            image_inputs, video_inputs = process_vision_info(messages)
            
            inputs = processor(
                text=[text_inputs], 
                images=image_inputs, 
                videos=video_inputs, 
                padding=True, 
                return_tensors="pt"
            ).to("cpu")

            with torch.no_grad():
                generated_ids = model.generate(
                    **inputs,
                    max_new_tokens=4096, 
                    do_sample=False
                )

            gen_ids_trimmed = [out[len(inp):] for inp, out in zip(inputs.input_ids, generated_ids)]
            md_text = processor.batch_decode(gen_ids_trimmed, skip_special_tokens=True)[0]

            # 6. å„²å­˜çµæœ
            parsed_results.append({
                "type": "text",
                "text": md_text,
                "page_idx": i,
                "img_path": f"images/{img_filename}",
                "bbox": [0, 0, image.width, image.height]
            })

            dur = time.time() - page_start
            logger.info(f"     âœ… å®Œæˆ (è€—æ™‚: {dur:.2f}s) | RAM: {get_ram_usage():.2f} GB")

            # å®šæœŸå¯«å…¥ç¡¬ç¢Ÿ
            if (i + 1) % SAVE_INTERVAL == 0 or (i + 1) == total_pages:
                with open(final_json, "w", encoding="utf-8") as f:
                    json.dump(parsed_results, f, ensure_ascii=False, indent=2)

        except Exception as e:
            logger.exception(f"âŒ Page {i+1} ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        finally:
            # æ¸…ç†è¨˜æ†¶é«”
            if 'inputs' in locals(): del inputs
            if 'generated_ids' in locals(): del generated_ids
            if 'image' in locals(): del image
            if 'pix' in locals(): del pix  # æ¸…ç† PyMuPDF ç‰©ä»¶
            import gc; gc.collect()

    logger.success(f"ğŸ‰ æª”æ¡ˆè™•ç†å®Œæˆï¼ç¸½è€—æ™‚: {time.time() - start_time:.2f}s")
    doc.close()
    return True

def main():
    if not os.path.exists(INPUT_DIR):
        logger.error(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥ç›®éŒ„: {INPUT_DIR}")
        return
    if not os.path.exists(OUTPUT_DIR_BASE):
        os.makedirs(OUTPUT_DIR_BASE)

    # è¼‰å…¥æ¨¡å‹
    model, processor = load_model()

    # æƒææª”æ¡ˆ
    all_files = glob.glob(os.path.join(INPUT_DIR, "*"))
    files = [f for f in all_files if os.path.isfile(f) and not os.path.basename(f).startswith(".")]
    
    logger.info(f"ğŸ“¦ ç™¼ç¾ {len(files)} å€‹æª”æ¡ˆï¼Œæº–å‚™é–‹å§‹...")

    for idx, file_path in enumerate(files):
        logger.info(f"\n[{idx+1}/{len(files)}] ----------------------------------------")
        
        if not file_path.lower().endswith(".pdf"):
            logger.warning(f"â­ï¸ è·³éé PDF æª”æ¡ˆ: {file_path}")
            continue
            
        process_single_file(file_path, OUTPUT_DIR_BASE, model, processor)

    logger.success("\nğŸ æ‰€æœ‰ä»»å‹™åŸ·è¡Œå®Œç•¢ï¼")

if __name__ == "__main__":
    main()