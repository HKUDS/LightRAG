import os
import re
import time
import base64
import sys
import glob
import json
from loguru import logger
from dotenv import load_dotenv
from openai import AzureOpenAI

# å¼·åˆ¶è¼‰å…¥ .env
load_dotenv()

# === 1. è¨­å®šå€ (Configuration) ===
# Azure OpenAI è¨­å®š (å„ªå…ˆä½¿ç”¨ AZURE_ å‰ç¶´ï¼Œå¦å‰‡ä½¿ç”¨ LLM_BINDING_ å‰ç¶´)
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY") or os.getenv("LLM_BINDING_API_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT") or os.getenv("LLM_BINDING_HOST")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")
AZURE_DEPLOYMENT_NAME = os.getenv("AZURE_OPENAI_DEPLOYMENT") or os.getenv("LLM_MODEL", "gpt-4o") 

# è¼¸å…¥èˆ‡è¼¸å‡ºè·¯å¾‘
INPUT_BASE_DIR = "./data/output/step1_vlm_output"
OUTPUT_SUFFIX = "_enriched" # è™•ç†å¾Œçš„æª”æ¡ˆæœƒåŠ ä¸Šé€™å€‹å¾Œç¶´ï¼Œä¾‹å¦‚ doc_enriched.md

# ç›®æ¨™æª”æ¡ˆåˆ—è¡¨ (ç›´æ¥åœ¨é€™è£¡è¨­å®š)
TARGET_FILES = ["SFC/vlm/SFC.md"]  # ä¾‹å¦‚: ["data/output/step1_vlm_output/folder1/vlm/file1.md", "data/output/step1_vlm_output/folder2/vlm/file2.md"]

# Log è¨­å®š
LOG_DIR = "./logs"
if not os.path.exists(LOG_DIR): os.makedirs(LOG_DIR)
logger.remove()
logger.add(sys.stderr, level="INFO")
logger.add(os.path.join(LOG_DIR, f"markdown_enrich_{time.strftime('%Y%m%d_%H%M%S')}.log"), rotation="10 MB", encoding="utf-8")

# ============

HAS_AI = False
ai_client = None

try:
    logger.info(f"ğŸ” æª¢æŸ¥ Azure OpenAI è¨­å®š...")
    logger.info(f"   API Key: {'å·²è¨­å®š' if AZURE_OPENAI_API_KEY else 'æœªè¨­å®š'}")
    logger.info(f"   Endpoint: {AZURE_OPENAI_ENDPOINT if AZURE_OPENAI_ENDPOINT else 'æœªè¨­å®š'}")
    
    if AZURE_OPENAI_API_KEY and AZURE_OPENAI_ENDPOINT:
        ai_client = AzureOpenAI(
            api_key=AZURE_OPENAI_API_KEY,
            api_version=AZURE_OPENAI_API_VERSION,
            azure_endpoint=AZURE_OPENAI_ENDPOINT
        )
        HAS_AI = True
        logger.info(f"âœ… Azure OpenAI å·²å•Ÿç”¨ (Deployment: {AZURE_DEPLOYMENT_NAME})")
    else:
        logger.warning("âš ï¸ æœªè¨­å®š Azure API Key æˆ– Endpointï¼ŒAI åŠŸèƒ½å°‡è·³é")
except ImportError:
    logger.error("âš ï¸ ç¼ºå°‘ openai å¥—ä»¶ï¼Œè«‹åŸ·è¡Œ: pip install openai")
except Exception as e:
    logger.error(f"âŒ Azure OpenAI åˆå§‹åŒ–å¤±æ•—: {e}")

def encode_image(image_path):
    if not os.path.exists(image_path):
        return None
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def generate_image_description(img_path, context_text=""):
    """å‘¼å« Azure OpenAI ç”Ÿæˆåœ–ç‰‡æè¿°"""
    if not HAS_AI: return None
    
    base64_image = encode_image(img_path)
    if not base64_image: 
        logger.warning(f"   âš ï¸ æ‰¾ä¸åˆ°åœ–ç‰‡æˆ–ç„¡æ³•è®€å–: {img_path}")
        return None

    try:
        system_prompt = "You are a helpful assistant assisting in document digitization. Your task is to provide a concise but descriptive summary of the image provided."
        user_msg = "Describe this image in detail. If it is a chart, summarize the key trends. If it is a diagram, explain its components. Output plain text only."
        
        # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥åŠ å¼· Prompt
        if context_text:
            user_msg += f"\n\nContext surrounding this image:\n{context_text[:500]}"

        response = ai_client.chat.completions.create(
            model=AZURE_DEPLOYMENT_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": [
                    {"type": "text", "text": user_msg},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                ]}
            ],
            temperature=0.3, 
            max_tokens=1024
        )
        content = response.choices[0].message.content.strip()
        
        # æ¸…ç†å¯èƒ½å‡ºç¾çš„ markdown code block
        if content.startswith("```"):
            content = content.replace("```markdown", "").replace("```", "").strip()
            
        return content

    except Exception as e:
        logger.error(f"âŒ Azure API Error on {os.path.basename(img_path)}: {e}")
        return None

def process_single_markdown(md_file_path):
    """è™•ç†å–®å€‹ Markdown æª”æ¡ˆ"""
    if not os.path.exists(md_file_path):
        logger.error(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {md_file_path}")
        return
    
    file_dir = os.path.dirname(md_file_path)
    file_name = os.path.basename(md_file_path)
    file_stem = os.path.splitext(file_name)[0]
    
    # å®šç¾©è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
    output_path = os.path.join(file_dir, f"{file_stem}{OUTPUT_SUFFIX}.md")
    
    logger.info(f"ğŸ“– è®€å–æª”æ¡ˆ: {md_file_path}")
    
    with open(md_file_path, "r", encoding="utf-8") as f:
        content = f.read()

    # Regex å°‹æ‰¾ Markdown åœ–ç‰‡èªæ³•: ![alt text](image_path)
    # capture group 1: alt text
    # capture group 2: image path
    img_pattern = re.compile(r'!\[(.*?)\]\((.*?)\)')
    
    # æ‰¾å‡ºæ‰€æœ‰åœ–ç‰‡é€£çµ
    matches = list(img_pattern.finditer(content))
    
    if not matches:
        logger.info("   â„¹ï¸ æ­¤æ–‡ä»¶æ²’æœ‰ç™¼ç¾åœ–ç‰‡")
        return

    logger.info(f"   ğŸ” ç™¼ç¾ {len(matches)} å¼µåœ–ç‰‡ï¼Œé–‹å§‹ç”Ÿæˆæè¿°...")
    
    # æˆ‘å€‘ä½¿ç”¨ã€Œæ›¿æ›ã€çš„æ–¹å¼ï¼Œç‚ºäº†é¿å…æ›¿æ›å¾Œ offset è·‘æ‰ï¼Œæˆ‘å€‘å¾å¾Œé¢å¾€å‰è™•ç†ï¼Œæˆ–è€…é‡å»ºå­—ä¸²
    # é€™è£¡ä½¿ç”¨é‡å»ºå­—ä¸²çš„æ–¹å¼æ¯”è¼ƒå®‰å…¨
    
    new_content = content
    # çµ±è¨ˆç”¨
    processed_count = 0
    
    # ç‚ºäº†é¿å…å¤šæ¬¡æ›¿æ›å°è‡´æ··äº‚ï¼Œæˆ‘å€‘å»ºç«‹ä¸€å€‹æ›¿æ›æ¸…å–®
    replacements = {}

    for match in matches:
        alt_text = match.group(1)
        rel_img_path = match.group(2)
        full_match_str = match.group(0)
        
        # çµ„åˆåœ–ç‰‡çš„çµ•å°è·¯å¾‘ (Mineru çš„åœ–ç‰‡è·¯å¾‘é€šå¸¸æ˜¯ç›¸å°çš„)
        abs_img_path = os.path.join(file_dir, rel_img_path)
        
        # å–å¾—åœ–ç‰‡å‘¨åœçš„ä¸Šä¸‹æ–‡ (å‰å¾Œ 200 å­—)
        start_idx = match.start()
        context_text = content[max(0, start_idx-200) : min(len(content), start_idx+200)]

        # å‘¼å« AI ç”Ÿæˆæè¿°
        logger.info(f"   ğŸ–¼ï¸ æ­£åœ¨åˆ†æåœ–ç‰‡: {rel_img_path}")
        description = generate_image_description(abs_img_path, context_text)
        
        if description:
            # æ§‹å»ºæ–°çš„ Markdown å€å¡Š
            # æ ¼å¼:
            # ![alt](path)
            # > **AI Description:** ...
            new_block = f"{full_match_str}\n\n> **AI Image Description:** {description}\n"
            replacements[full_match_str] = new_block
            processed_count += 1
            
            # ä¼‘æ¯ä¸€ä¸‹é¿å… Rate Limit
            time.sleep(1) 
        else:
            replacements[full_match_str] = full_match_str # æ²’æè¿°å°±ä¿æŒåŸæ¨£

    # åŸ·è¡Œæ›¿æ› (ä¸€æ¬¡æ€§æ›¿æ›æ‰€æœ‰åœ–ç‰‡)
    # æ³¨æ„ï¼šå¦‚æœæœ‰å¤šå€‹ç›¸åŒçš„åœ–ç‰‡æ¨™ç±¤ï¼Œé€™è£¡æœƒå…¨éƒ¨æ›¿æ›
    for old_str, new_str in replacements.items():
        new_content = new_content.replace(old_str, new_str)

    # å¯«å…¥æ–°æª”æ¡ˆ
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(new_content)

    logger.success(f"âœ… å®Œæˆï¼å·²è™•ç† {processed_count}/{len(matches)} å¼µåœ–ç‰‡")
    logger.info(f"   ğŸ’¾ å„²å­˜è‡³: {output_path}")

def main():
    # ä½¿ç”¨ç›´æ¥è¨­å®šçš„ç›®æ¨™æª”æ¡ˆåˆ—è¡¨ï¼Œå¦‚æœæ˜¯ç›¸å°è·¯å¾‘å‰‡åœ¨ INPUT_BASE_DIR ä¸‹
    target_files = []
    for f in TARGET_FILES:
        if os.path.isabs(f):
            target_files.append(f)
        else:
            target_files.append(os.path.join(INPUT_BASE_DIR, f))

    if not target_files:
        logger.error("âŒ æ²’æœ‰è¨­å®šç›®æ¨™æª”æ¡ˆåˆ—è¡¨")
        return

    logger.info(f"ğŸ“¦ ç¸½å…±ç™¼ç¾ {len(target_files)} å€‹ Markdown æª”æ¡ˆå¾…è™•ç†")

    for i, md_path in enumerate(target_files):
        logger.info(f"\nğŸš€ [{i+1}/{len(target_files)}] è™•ç†æ–‡ä»¶: {md_path}")
        process_single_markdown(md_path)

    logger.success("\nğŸ‰ æ‰€æœ‰ Markdown æª”æ¡ˆè™•ç†å®Œç•¢ï¼")

if __name__ == "__main__":
    main()