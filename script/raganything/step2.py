import os
import json
import time
import base64
import sys
from loguru import logger
from dotenv import load_dotenv  

# å¼·åˆ¶è¼‰å…¥ .env æª”æ¡ˆ
load_dotenv()

# === 1. è¨­å®šå€ (Configuration) ===
# SiliconFlow API Key
SILICONFLOW_API_KEY = os.getenv("SILICONFLOW_API_KEY", "")
MODEL_NAME = "thudm/glm-4.1v-9b-thinking" 

# è¨­å®š Log ç›®éŒ„
LOG_DIR = "./logs"
if not os.path.exists(LOG_DIR):
    os.makedirs(LOG_DIR)

# è¨­å®š Loguru
log_file = os.path.join(LOG_DIR, f"step2_resume_{time.strftime('%Y%m%d_%H%M%S')}.log")
logger.remove() 
logger.add(sys.stderr, level="INFO") 
logger.add(log_file, rotation="10 MB", level="DEBUG", encoding="utf-8")
logger.info(f"ğŸ“ Log æª”æ¡ˆå·²å»ºç«‹: {log_file}")

# ============

HAS_AI = False
ai_client = None

# åˆå§‹åŒ– OpenAI Client
try:
    from openai import OpenAI
    if SILICONFLOW_API_KEY and "ä½ çš„_SILICONFLOW_KEY" not in SILICONFLOW_API_KEY:
        ai_client = OpenAI(
            api_key=SILICONFLOW_API_KEY,
            base_url="https://api.siliconflow.cn/v1"
        )
        HAS_AI = True
        logger.info(f"âœ… å·²å•Ÿç”¨ SiliconFlow AI ({MODEL_NAME})")
    else:
        logger.warning("âš ï¸ æœªå¡«å¯« SILICONFLOW_API_KEYï¼Œå°‡è·³é AI æè¿°åŠŸèƒ½")
except ImportError:
    logger.error("âš ï¸ ç¼ºå°‘ openai å¥—ä»¶ï¼Œè«‹åŸ·è¡Œ: pip install openai")

def encode_image(image_path):
    """å°‡åœ–ç‰‡è½‰ç‚º Base64"""
    if not os.path.exists(image_path): 
        logger.error(f"âŒ æ‰¾ä¸åˆ°åœ–ç‰‡: {image_path}")
        return None
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def call_vision_llm(img_path, mode="table", context_text=""):
    if not HAS_AI: return None
    
    base64_image = encode_image(img_path)
    if not base64_image: return None

    try:
        context_instruction = ""
        if context_text:
            context_instruction = f"""
            \n[Context Info]:
            The text surrounding this image/table is:
            " ... {context_text} ... "
            Instruction: Use this context to infer the title, subject, time period, or data units.
            """

        if mode == "table":
            system_prompt = "You are an expert OCR engine. Transcribe the table in the image into a clean Markdown table."
            user_msg = f"{context_instruction}\nTask: Output ONLY the markdown table content. Handle merged cells. No explanations."
        else: # Image / Chart
            system_prompt = "You are a helpful assistant describing images for a RAG system."
            user_msg = f"{context_instruction}\nTask: Provide a detailed description of this image. Extract key data points, trends, and the title."

        response = ai_client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": [
                    {"type": "text", "text": user_msg},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                ]}
            ],
            temperature=0.1, max_tokens=4096, stream=False
        )
        content = response.choices[0].message.content.strip()
        
        if "</think>" in content:
            content = content.split("</think>")[-1].strip()
            
        return content

    except Exception as e:
        logger.error(f"âŒ SiliconFlow API Error on {img_path}: {e}")
        return None

def main():
    # è·¯å¾‘è¨­å®š
    input_json = "./data/input/step1_output/intermediate_result.json"
    output_dir = "./data/output/step2_output_granular"
    output_path = os.path.join(output_dir, "granular_content.json")
    
    if not os.path.exists(input_json):
        input_json_fallback = "./data/input/step1_output/intermediate_result.json"
        if os.path.exists(input_json_fallback):
            input_json = input_json_fallback
            output_dir = "./data/output/step2_output_granular"
            output_path = os.path.join(output_dir, "granular_content.json")
        else:
            logger.critical(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥æª”æ¡ˆ: {input_json}")
            return

    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # === ğŸ”„ æ–·é»çºŒå‚³é‚è¼¯ (Resume Logic) ===
    processed_blocks = []
    processed_ids = set() # ç”¨ä¾†è¨˜éŒ„é‚Šå•²å·²ç¶“åšé

    if os.path.exists(output_path):
        logger.info(f"ğŸ“‚ ç™¼ç¾èˆŠæœ‰æª”æ¡ˆ: {output_path}ï¼Œå˜—è©¦è®€å–ä»¥é€²è¡ŒçºŒå‚³...")
        try:
            with open(output_path, "r", encoding="utf-8") as f:
                existing_data = json.load(f)
                if isinstance(existing_data, list):
                    processed_blocks = existing_data
                    # å»ºç«‹ ID Set (Page + Bbox String)
                    for block in processed_blocks:
                        pid = f"{block['page']}_{str(block['bbox'])}"
                        processed_ids.add(pid)
                    logger.success(f"âœ… æˆåŠŸè¼‰å…¥ {len(processed_blocks)} å€‹å·²è™•ç†å€å¡Šï¼Œå°‡æœƒè·³éé€™äº›ã€‚")
        except Exception as e:
            logger.warning(f"âš ï¸ è®€å–èˆŠæª”å¤±æ•— ({e})ï¼Œå°‡æœƒé‡æ–°é–‹å§‹ã€‚")
            processed_blocks = []

    logger.info(f"ğŸš€ [Step 2] å•Ÿå‹•è™•ç†... è®€å–: {input_json}")
    
    with open(input_json, "r", encoding="utf-8") as f:
        content_list = json.load(f)
    
    base_dir = os.path.dirname(input_json)
    stats = {"text": 0, "table": 0, "image": 0, "ai_processed": 0, "skipped": 0}

    for idx, item in enumerate(content_list):
        item_type = item.get('type')
        page_idx = item.get('page_idx', 0)
        
        # è™•ç† Bbox: è½‰ç‚º List [x, y, w, h] (ä½ åŸæœ¬çš„ä¿®æ­£)
        raw_bbox = item.get('bbox') or item.get('rect')
        bbox = [int(b) for b in raw_bbox] if raw_bbox else None
        
        # æ§‹é€ å”¯ä¸€ ID
        current_id = f"{page_idx + 1}_{str(bbox)}"

        # ğŸ›‘ æª¢æŸ¥æ˜¯å¦å·²è™•ç† (Skip Check)
        if current_id in processed_ids:
            stats["skipped"] += 1
            if idx % 100 == 0: logger.info(f"â­ï¸ è·³éå·²è™•ç†å€å¡Š (é€²åº¦: {idx}/{len(content_list)})")
            continue

        # === è™•ç†æ–°å€å¡Š ===
        rel_path = item.get('img_path', '')
        abs_img_path = os.path.join(base_dir, rel_path) if rel_path else None
        
        block_data = {
            "type": item_type,
            "page": page_idx + 1,
            "bbox": bbox,
            "content": "",
            "original_img": rel_path
        }

        # Context Logic
        context_text = ""
        if idx > 0 and content_list[idx-1].get('type') == 'text':
            prev_text = content_list[idx-1].get('text', '').strip()
            context_text += f"Preceding Text: {prev_text[-500:]}\n"
        if idx < len(content_list) - 1 and content_list[idx+1].get('type') == 'text':
            next_text = content_list[idx+1].get('text', '').strip()
            context_text += f"Following Text: {next_text[:200]}"

        # --- [A] Text ---
        if item_type == 'text':
            text = item.get('text', '').strip()
            if text:
                block_data["content"] = text
                processed_blocks.append(block_data)
                processed_ids.add(current_id)
                stats["text"] += 1

        # --- [B] Table ---
        elif item_type == 'table':
            logger.info(f"ğŸ” [Table] P{page_idx+1} è™•ç†ä¸­...")
            content = item.get('table_body', '')
            if HAS_AI and abs_img_path:
                ai_content = call_vision_llm(abs_img_path, mode="table", context_text=context_text)
                if ai_content:
                    content = ai_content
                    stats["ai_processed"] += 1
            
            caption = "".join(item.get('table_caption', []))
            if caption: content = f"**Table Caption:** {caption}\n\n{content}"
            block_data["content"] = content
            processed_blocks.append(block_data)
            processed_ids.add(current_id)
            stats["table"] += 1

        # --- [C] Image ---
        elif item_type == 'image':
            logger.info(f"ğŸ–¼ï¸ [Image] P{page_idx+1} è™•ç†ä¸­...")
            caption = "".join(item.get('image_caption', []))
            if HAS_AI and abs_img_path:
                ai_desc = call_vision_llm(abs_img_path, mode="caption", context_text=context_text)
                if ai_desc:
                    caption = f"{caption}\n**Image Description:** {ai_desc}".strip()
                    stats["ai_processed"] += 1
            
            block_data["content"] = caption
            processed_blocks.append(block_data)
            processed_ids.add(current_id)
            stats["image"] += 1
            
        # ğŸ’¾ è‡ªå‹•å­˜æª” (Auto-Save): æ¯ 5 å€‹æ–° Item å°±å„²å­˜ä¸€æ¬¡
        newly_processed = stats["text"] + stats["table"] + stats["image"]
        if newly_processed > 0 and newly_processed % 5 == 0:
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(processed_blocks, f, ensure_ascii=False, indent=2)

        if idx > 0 and idx % 50 == 0:
            logger.info(f"â³ é€²åº¦: {idx}/{len(content_list)} (New: {newly_processed}, Skipped: {stats['skipped']})...")

    # æœ€å¾Œå„²å­˜
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(processed_blocks, f, ensure_ascii=False, indent=2)

    logger.success("=" * 40)
    logger.success(f"ğŸ‰ è™•ç†å®Œæˆï¼ç¸½å€å¡Šæ•¸: {len(processed_blocks)}")
    logger.info(f"ğŸ“Š çµ±è¨ˆ: New AI Calls={stats['ai_processed']} | Skipped={stats['skipped']}")
    logger.success(f"ğŸ’¾ æª”æ¡ˆå·²å„²å­˜: {output_path}")
    logger.success("=" * 40)

if __name__ == "__main__":
    main()