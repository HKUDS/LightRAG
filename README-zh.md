<div align="center">

<div style="margin: 20px 0;">
  <img src="./assets/logo.png" width="120" height="120" alt="LightRAG Logo" style="border-radius: 20px; box-shadow: 0 8px 32px rgba(0, 217, 255, 0.3);">
</div>

# ğŸš€ LightRAG: Simple and Fast Retrieval-Augmented Generation

<div align="center">
    <a href="https://trendshift.io/repositories/13043" target="_blank"><img src="https://trendshift.io/api/badge/repositories/13043" alt="HKUDS%2FLightRAG | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>
</div>

<div align="center">
  <div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"></div>
</div>

<div align="center">
  <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 25px; text-align: center;">
    <p>
      <a href='https://github.com/HKUDS/LightRAG'><img src='https://img.shields.io/badge/ğŸ”¥é¡¹ç›®-ä¸»é¡µ-00d9ff?style=for-the-badge&logo=github&logoColor=white&labelColor=1a1a2e'></a>
      <a href='https://arxiv.org/abs/2410.05779'><img src='https://img.shields.io/badge/ğŸ“„arXiv-2410.05779-ff6b6b?style=for-the-badge&logo=arxiv&logoColor=white&labelColor=1a1a2e'></a>
      <a href="https://github.com/HKUDS/LightRAG/stargazers"><img src='https://img.shields.io/github/stars/HKUDS/LightRAG?color=00d9ff&style=for-the-badge&logo=star&logoColor=white&labelColor=1a1a2e' /></a>
    </p>
    <p>
      <img src="https://img.shields.io/badge/ğŸPython-3.10-4ecdc4?style=for-the-badge&logo=python&logoColor=white&labelColor=1a1a2e">
      <a href="https://pypi.org/project/lightrag-hku/"><img src="https://img.shields.io/pypi/v/lightrag-hku.svg?style=for-the-badge&logo=pypi&logoColor=white&labelColor=1a1a2e&color=ff6b6b"></a>
    </p>
    <p>
      <a href="https://discord.gg/yF2MmDJyGJ"><img src="https://img.shields.io/badge/ğŸ’¬Discord-ç¤¾åŒº-7289da?style=for-the-badge&logo=discord&logoColor=white&labelColor=1a1a2e"></a>
      <a href="https://github.com/HKUDS/LightRAG/issues/285"><img src="https://img.shields.io/badge/ğŸ’¬å¾®ä¿¡ç¾¤-äº¤æµ-07c160?style=for-the-badge&logo=wechat&logoColor=white&labelColor=1a1a2e"></a>
    </p>
    <p>
      <a href="README-zh.md"><img src="https://img.shields.io/badge/ğŸ‡¨ğŸ‡³ä¸­æ–‡ç‰ˆ-1a1a2e?style=for-the-badge"></a>
      <a href="README.md"><img src="https://img.shields.io/badge/ğŸ‡ºğŸ‡¸English-1a1a2e?style=for-the-badge"></a>
    </p>
    <p>
      <a href="https://pepy.tech/projects/lightrag-hku"><img src="https://static.pepy.tech/personalized-badge/lightrag-hku?period=total&units=INTERNATIONAL_SYSTEM&left_color=BLACK&right_color=GREEN&left_text=downloads"></a>
    </p>
  </div>
</div>

</div>

<div align="center" style="margin: 30px 0;">
  <img src="https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif" width="800">
</div>

<div align="center" style="margin: 30px 0;">
    <img src="./README.assets/b2aaf634151b4706892693ffb43d9093.png" width="800" alt="LightRAG Diagram">
</div>

---

## ğŸ‰ æ–°é—»

- [2025.11.05]ğŸ¯æ·»åŠ **åŸºäºRAGASçš„**è¯„ä¼°æ¡†æ¶å’Œ**Langfuse**å¯è§‚æµ‹æ€§æ”¯æŒï¼ˆAPIå¯éšæŸ¥è¯¢ç»“æœè¿”å›å¬å›ä¸Šä¸‹æ–‡ï¼‰ã€‚
- [2025.10.22]ğŸ¯æ¶ˆé™¤å¤„ç†**å¤§è§„æ¨¡æ•°æ®é›†**çš„æ€§èƒ½ç“¶é¢ˆã€‚
- [2025.09.15]ğŸ¯æ˜¾è‘—æå‡**å°å‹LLM**ï¼ˆå¦‚Qwen3-30B-A3Bï¼‰çš„çŸ¥è¯†å›¾è°±æå–å‡†ç¡®æ€§ã€‚
- [2025.08.29]ğŸ¯ç°å·²æ”¯æŒ**Reranker**ï¼Œæ˜¾è‘—æå‡æ··åˆæŸ¥è¯¢æ€§èƒ½(ç°å·²è®¾ä¸ºé»˜è®¤æŸ¥è¯¢æ¨¡å¼)ã€‚
- [2025.08.04]ğŸ¯æ”¯æŒ**æ–‡æ¡£åˆ é™¤**å¹¶é‡æ–°ç”ŸæˆçŸ¥è¯†å›¾è°±ä»¥ç¡®ä¿æŸ¥è¯¢æ€§èƒ½ã€‚
- [2025.06.16]ğŸ¯æˆ‘ä»¬çš„å›¢é˜Ÿå‘å¸ƒäº†[RAG-Anything](https://github.com/HKUDS/RAG-Anything)ï¼Œä¸€ä¸ªç”¨äºæ— ç¼å¤„ç†æ–‡æœ¬ã€å›¾åƒã€è¡¨æ ¼å’Œæ–¹ç¨‹å¼çš„å…¨åŠŸèƒ½å¤šæ¨¡æ€ RAG ç³»ç»Ÿã€‚
- [2025.06.05]ğŸ¯LightRAGç°å·²é›†æˆ[RAG-Anything](https://github.com/HKUDS/RAG-Anything)ï¼Œæ”¯æŒå…¨é¢çš„å¤šæ¨¡æ€æ–‡æ¡£è§£æä¸RAGèƒ½åŠ›ï¼ˆPDFã€å›¾ç‰‡ã€Officeæ–‡æ¡£ã€è¡¨æ ¼ã€å…¬å¼ç­‰ï¼‰ã€‚è¯¦è§ä¸‹æ–¹[å¤šæ¨¡æ€å¤„ç†æ¨¡å—](https://github.com/HKUDS/LightRAG?tab=readme-ov-file#å¤šæ¨¡æ€æ–‡æ¡£å¤„ç†rag-anythingé›†æˆ)ã€‚
- [2025.03.18]ğŸ¯LightRAGç°å·²æ”¯æŒå‚è€ƒæ–‡çŒ®åŠŸèƒ½ã€‚
- [2025.02.12]ğŸ¯ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨MongoDBä½œä¸ºä¸€ä½“åŒ–å­˜å‚¨è§£å†³æ–¹æ¡ˆã€‚
- [2025.02.05]ğŸ¯æˆ‘ä»¬å›¢é˜Ÿå‘å¸ƒäº†[VideoRAG](https://github.com/HKUDS/VideoRAG)ï¼Œç”¨äºç†è§£è¶…é•¿ä¸Šä¸‹æ–‡è§†é¢‘ã€‚
- [2025.01.13]ğŸ¯æˆ‘ä»¬å›¢é˜Ÿå‘å¸ƒäº†[MiniRAG](https://github.com/HKUDS/MiniRAG)ï¼Œä½¿ç”¨å°å‹æ¨¡å‹ç®€åŒ–RAGã€‚
- [2025.01.06]ğŸ¯ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨PostgreSQLä½œä¸ºä¸€ä½“åŒ–å­˜å‚¨è§£å†³æ–¹æ¡ˆã€‚
- [2024.11.19]ğŸ¯LightRAGçš„ç»¼åˆæŒ‡å—ç°å·²åœ¨[LearnOpenCV](https://learnopencv.com/lightrag)ä¸Šå‘å¸ƒã€‚éå¸¸æ„Ÿè°¢åšå®¢ä½œè€…ã€‚
- [2024.11.09]ğŸ¯æ¨å‡ºLightRAG Webuiï¼Œå…è®¸æ‚¨æ’å…¥ã€æŸ¥è¯¢ã€å¯è§†åŒ–LightRAGçŸ¥è¯†ã€‚
- [2024.11.04]ğŸ¯ç°åœ¨æ‚¨å¯ä»¥[ä½¿ç”¨Neo4Jè¿›è¡Œå­˜å‚¨](https://github.com/HKUDS/LightRAG?tab=readme-ov-file#using-neo4j-for-storage)ã€‚
- [2024.10.18]ğŸ¯æˆ‘ä»¬æ·»åŠ äº†[LightRAGä»‹ç»è§†é¢‘](https://youtu.be/oageL-1I0GE)çš„é“¾æ¥ã€‚æ„Ÿè°¢ä½œè€…ï¼
- [2024.10.17]ğŸ¯æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª[Discordé¢‘é“](https://discord.gg/yF2MmDJyGJ)ï¼æ¬¢è¿åŠ å…¥åˆ†äº«å’Œè®¨è®ºï¼ğŸ‰ğŸ‰
- [2024.10.16]ğŸ¯LightRAGç°åœ¨æ”¯æŒ[Ollamaæ¨¡å‹](https://github.com/HKUDS/LightRAG?tab=readme-ov-file#quick-start)ï¼

<details>
  <summary style="font-size: 1.4em; font-weight: bold; cursor: pointer; display: list-item;">
    ç®—æ³•æµç¨‹å›¾
  </summary>

![LightRAGç´¢å¼•æµç¨‹å›¾](https://learnopencv.com/wp-content/uploads/2024/11/LightRAG-VectorDB-Json-KV-Store-Indexing-Flowchart-scaled.jpg)
*å›¾1ï¼šLightRAGç´¢å¼•æµç¨‹å›¾ - å›¾ç‰‡æ¥æºï¼š[Source](https://learnopencv.com/lightrag/)*
![LightRAGæ£€ç´¢å’ŒæŸ¥è¯¢æµç¨‹å›¾](https://learnopencv.com/wp-content/uploads/2024/11/LightRAG-Querying-Flowchart-Dual-Level-Retrieval-Generation-Knowledge-Graphs-scaled.jpg)
*å›¾2ï¼šLightRAGæ£€ç´¢å’ŒæŸ¥è¯¢æµç¨‹å›¾ - å›¾ç‰‡æ¥æºï¼š[Source](https://learnopencv.com/lightrag/)*

</details>

## å®‰è£…

> **ğŸ’¡ ä½¿ç”¨ uv è¿›è¡ŒåŒ…ç®¡ç†**: æœ¬é¡¹ç›®ä½¿ç”¨ [uv](https://docs.astral.sh/uv/) è¿›è¡Œå¿«é€Ÿå¯é çš„ Python åŒ…ç®¡ç†ã€‚
> é¦–å…ˆå®‰è£… uv: `curl -LsSf https://astral.sh/uv/install.sh | sh` (Unix/macOS) æˆ– `powershell -c "irm https://astral.sh/uv/install.ps1 | iex"` (Windows)
>
> **æ³¨æ„**: å¦‚æœæ‚¨æ›´å–œæ¬¢ä½¿ç”¨ pip ä¹Ÿå¯ä»¥ï¼Œä½†æˆ‘ä»¬æ¨èä½¿ç”¨ uv ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½å’Œæ›´å¯é çš„ä¾èµ–ç®¡ç†ã€‚

### å®‰è£…LightRAGæœåŠ¡å™¨

LightRAGæœåŠ¡å™¨æ—¨åœ¨æä¾›Web UIå’ŒAPIæ”¯æŒã€‚Web UIä¾¿äºæ–‡æ¡£ç´¢å¼•ã€çŸ¥è¯†å›¾è°±æ¢ç´¢å’Œç®€å•çš„RAGæŸ¥è¯¢ç•Œé¢ã€‚LightRAGæœåŠ¡å™¨è¿˜æä¾›å…¼å®¹Ollamaçš„æ¥å£ï¼Œæ—¨åœ¨å°†LightRAGæ¨¡æ‹Ÿä¸ºOllamaèŠå¤©æ¨¡å‹ã€‚è¿™ä½¿å¾—AIèŠå¤©æœºå™¨äººï¼ˆå¦‚Open WebUIï¼‰å¯ä»¥è½»æ¾è®¿é—®LightRAGã€‚

* ä»PyPIå®‰è£…

```bash
# ä½¿ç”¨ uv (æ¨è)
uv pip install "lightrag-hku[api]"
# æˆ–ä½¿ç”¨ pip
# pip install "lightrag-hku[api]"

cp env.example .env  # ä½¿ç”¨ä½ çš„LLMå’ŒEmbeddingæ¨¡å‹è®¿é—®å‚æ•°æ›´æ–°.envæ–‡ä»¶

lightrag-server
```

* ä»æºä»£ç å®‰è£…

```bash
git clone https://github.com/HKUDS/LightRAG.git
cd LightRAG

# ä½¿ç”¨ uv (æ¨è)
# æ³¨æ„: uv sync ä¼šè‡ªåŠ¨åœ¨ .venv/ ç›®å½•åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
uv sync --extra api
source .venv/bin/activate  # æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ (Linux/macOS)
# Windows ç³»ç»Ÿ: .venv\Scripts\activate

# æˆ–ä½¿ç”¨ pip å’Œè™šæ‹Ÿç¯å¢ƒ
# python -m venv .venv
# source .venv/bin/activate  # Windows: .venv\Scripts\activate
# pip install -e ".[api]"

cp env.example .env  # ä½¿ç”¨ä½ çš„LLMå’ŒEmbeddingæ¨¡å‹è®¿é—®å‚æ•°æ›´æ–°.envæ–‡ä»¶

# æ„å»ºå‰ç«¯ä»£ç 
cd lightrag_webui
bun install --frozen-lockfile
bun run build
cd ..

lightrag-server
```

* ä½¿ç”¨ Docker Compose å¯åŠ¨ LightRAG æœåŠ¡å™¨

```bash
git clone https://github.com/HKUDS/LightRAG.git
cd LightRAG
cp env.example .env  # ä½¿ç”¨ä½ çš„LLMå’ŒEmbeddingæ¨¡å‹è®¿é—®å‚æ•°æ›´æ–°.envæ–‡ä»¶
# modify LLM and Embedding settings in .env
docker compose up
```

> åœ¨æ­¤è·å–LightRAG dockeré•œåƒå†å²ç‰ˆæœ¬: [LightRAG Docker Images]( https://github.com/HKUDS/LightRAG/pkgs/container/lightrag)

### å®‰è£…LightRAG Core

* ä»æºä»£ç å®‰è£…ï¼ˆæ¨èï¼‰

```bash
cd LightRAG
# æ³¨æ„: uv sync ä¼šè‡ªåŠ¨åœ¨ .venv/ ç›®å½•åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
uv sync
source .venv/bin/activate  # æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ (Linux/macOS)
# Windows ç³»ç»Ÿ: .venv\Scripts\activate

# æˆ–: pip install -e .
```

* ä»PyPIå®‰è£…

```bash
uv pip install lightrag-hku
# æˆ–: pip install lightrag-hku
```

## å¿«é€Ÿå¼€å§‹

### LightRAGçš„LLMåŠé…å¥—æŠ€æœ¯æ ˆè¦æ±‚

LightRAGå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èƒ½åŠ›è¦æ±‚è¿œé«˜äºä¼ ç»ŸRAGï¼Œå› ä¸ºå®ƒéœ€è¦LLMæ‰§è¡Œæ–‡æ¡£ä¸­çš„å®ä½“å…³ç³»æŠ½å–ä»»åŠ¡ã€‚é…ç½®åˆé€‚çš„Embeddingå’ŒRerankeræ¨¡å‹å¯¹æé«˜æŸ¥è¯¢è¡¨ç°ä¹Ÿè‡³å…³é‡è¦ã€‚

- **LLMé€‰å‹**ï¼š
  - æ¨èé€‰ç”¨å‚æ•°é‡è‡³å°‘ä¸º32Bçš„LLMã€‚
  - ä¸Šä¸‹æ–‡é•¿åº¦è‡³å°‘ä¸º32KBï¼Œæ¨èè¾¾åˆ°64KBã€‚
  - åœ¨æ–‡æ¡£ç´¢å¼•é˜¶æ®µä¸å»ºè®®é€‰æ‹©æ¨ç†æ¨¡å‹ã€‚
  - åœ¨æŸ¥è¯¢é˜¶æ®µå»ºè®®é€‰æ‹©æ¯”ç´¢å¼•é˜¶æ®µèƒ½åŠ›æ›´å¼ºçš„æ¨¡å‹ï¼Œä»¥è¾¾åˆ°æ›´é«˜çš„æŸ¥è¯¢æ•ˆæœã€‚
- **Embeddingæ¨¡å‹**ï¼š
  - é«˜æ€§èƒ½çš„Embeddingæ¨¡å‹å¯¹RAGè‡³å…³é‡è¦ã€‚
  - æ¨èä½¿ç”¨ä¸»æµçš„å¤šè¯­è¨€Embeddingæ¨¡å‹ï¼Œä¾‹å¦‚ï¼šBAAI/bge-m3 å’Œ text-embedding-3-largeã€‚
  - **é‡è¦æç¤º**ï¼šåœ¨æ–‡æ¡£ç´¢å¼•å‰å¿…é¡»ç¡®å®šä½¿ç”¨çš„Embeddingæ¨¡å‹ï¼Œä¸”åœ¨æ–‡æ¡£æŸ¥è¯¢é˜¶æ®µå¿…é¡»æ²¿ç”¨ä¸ç´¢å¼•é˜¶æ®µç›¸åŒçš„æ¨¡å‹ã€‚æœ‰äº›å­˜å‚¨ï¼ˆä¾‹å¦‚PostgreSQLï¼‰åœ¨é¦–æ¬¡å»ºç«‹æ•°è¡¨çš„æ—¶å€™éœ€è¦ç¡®å®šå‘é‡ç»´åº¦ï¼Œå› æ­¤æ›´æ¢Embeddingæ¨¡å‹åéœ€è¦åˆ é™¤å‘é‡ç›¸å…³åº“è¡¨ï¼Œä»¥ä¾¿è®©LightRAGé‡å»ºæ–°çš„åº“è¡¨ã€‚
- **Rerankeræ¨¡å‹é…ç½®**ï¼š
  - é…ç½®Rerankeræ¨¡å‹èƒ½å¤Ÿæ˜¾è‘—æå‡LightRAGçš„æ£€ç´¢æ•ˆæœã€‚
  - å¯ç”¨Rerankeræ¨¡å‹åï¼Œæ¨èå°†â€œmixæ¨¡å¼â€è®¾ä¸ºé»˜è®¤æŸ¥è¯¢æ¨¡å¼ã€‚
  - æ¨èé€‰ç”¨ä¸»æµçš„Rerankeræ¨¡å‹ï¼Œä¾‹å¦‚ï¼šBAAI/bge-reranker-v2-m3 æˆ– Jina ç­‰æœåŠ¡å•†æä¾›çš„æ¨¡å‹ã€‚

### ä½¿ç”¨LightRAGæœåŠ¡å™¨

**æœ‰å…³LightRAGæœåŠ¡å™¨çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[LightRAGæœåŠ¡å™¨](./lightrag/api/README.md)ã€‚**

### ä½¿ç”¨LightRAG Core

LightRAGæ ¸å¿ƒåŠŸèƒ½çš„ç¤ºä¾‹ä»£ç è¯·å‚è§`examples`ç›®å½•ã€‚æ‚¨è¿˜å¯å‚ç…§[è§†é¢‘](https://www.youtube.com/watch?v=g21royNJ4fw)è§†é¢‘å®Œæˆç¯å¢ƒé…ç½®ã€‚è‹¥å·²æŒæœ‰OpenAI APIå¯†é’¥ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤è¿è¡Œæ¼”ç¤ºä»£ç ï¼š

```bash
### you should run the demo code with project folder
cd LightRAG
### provide your API-KEY for OpenAI
export OPENAI_API_KEY="sk-...your_opeai_key..."
### download the demo document of "A Christmas Carol" by Charles Dickens
curl https://raw.githubusercontent.com/gusye1234/nano-graphrag/main/tests/mock_data.txt > ./book.txt
### run the demo code
python examples/lightrag_openai_demo.py
```

å¦‚éœ€æµå¼å“åº”ç¤ºä¾‹çš„å®ç°ä»£ç ï¼Œè¯·å‚é˜… `examples/lightrag_openai_compatible_demo.py`ã€‚è¿è¡Œå‰ï¼Œè¯·ç¡®ä¿æ ¹æ®éœ€æ±‚ä¿®æ”¹ç¤ºä¾‹ä»£ç ä¸­çš„LLMåŠåµŒå…¥æ¨¡å‹é…ç½®ã€‚

**æ³¨æ„1**ï¼šåœ¨è¿è¡Œdemoç¨‹åºçš„æ—¶å€™éœ€è¦æ³¨æ„ï¼Œä¸åŒçš„æµ‹è¯•ç¨‹åºå¯èƒ½ä½¿ç”¨çš„æ˜¯ä¸åŒçš„embeddingæ¨¡å‹ï¼Œæ›´æ¢ä¸åŒçš„embedingæ¨¡å‹çš„æ—¶å€™éœ€è¦æŠŠæ¸…ç©ºæ•°æ®ç›®å½•ï¼ˆ`./dickens`ï¼‰ï¼Œå¦åˆ™å±‚åºæ‰§è¡Œä¼šå‡ºé”™ã€‚å¦‚æœä½ æƒ³ä¿ç•™LLMç¼“å­˜ï¼Œå¯ä»¥åœ¨æ¸…é™¤æ•°æ®ç›®å½•æ—¶ä¿ç•™`kv_store_llm_response_cache.json`æ–‡ä»¶ã€‚

**æ³¨æ„2**ï¼šå®˜æ–¹æ”¯æŒçš„ç¤ºä¾‹ä»£ç ä»…ä¸º `lightrag_openai_demo.py` å’Œ `lightrag_openai_compatible_demo.py` ä¸¤ä¸ªæ–‡ä»¶ã€‚å…¶ä»–ç¤ºä¾‹æ–‡ä»¶å‡ä¸ºç¤¾åŒºè´¡çŒ®å†…å®¹ï¼Œå°šæœªç»è¿‡å®Œæ•´æµ‹è¯•ä¸ä¼˜åŒ–ã€‚

## ä½¿ç”¨LightRAG Coreè¿›è¡Œç¼–ç¨‹

> âš ï¸ **å¦‚æœæ‚¨å¸Œæœ›å°†LightRAGé›†æˆåˆ°æ‚¨çš„é¡¹ç›®ä¸­ï¼Œå»ºè®®æ‚¨ä½¿ç”¨LightRAG Serveræä¾›çš„REST API**ã€‚LightRAG Coreé€šå¸¸ç”¨äºåµŒå…¥å¼åº”ç”¨ï¼Œæˆ–ä¾›å¸Œæœ›è¿›è¡Œç ”ç©¶ä¸è¯„ä¼°çš„å­¦è€…ä½¿ç”¨ã€‚

### âš ï¸ é‡è¦ï¼šåˆå§‹åŒ–è¦æ±‚

LightRAG åœ¨ä½¿ç”¨å‰éœ€è¦æ˜¾å¼åˆå§‹åŒ–ã€‚ åˆ›å»º LightRAG å®ä¾‹åï¼Œæ‚¨å¿…é¡»è°ƒç”¨ await rag.initialize_storages()ï¼Œå¦åˆ™å°†å‡ºç°é”™è¯¯ã€‚

### ä¸€ä¸ªç®€å•ç¨‹åº

ä»¥ä¸‹Pythonä»£ç ç‰‡æ®µæ¼”ç¤ºäº†å¦‚ä½•åˆå§‹åŒ–LightRAGã€æ’å…¥æ–‡æœ¬å¹¶è¿›è¡ŒæŸ¥è¯¢ï¼š

```python
import os
import asyncio
from lightrag import LightRAG, QueryParam
from lightrag.llm.openai import gpt_4o_mini_complete, gpt_4o_complete, openai_embed
from lightrag.utils import setup_logger

setup_logger("lightrag", level="INFO")

WORKING_DIR = "./rag_storage"
if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

async def initialize_rag():
    rag = LightRAG(
        working_dir=WORKING_DIR,
        embedding_func=openai_embed,
        llm_model_func=gpt_4o_mini_complete,
    )
    await rag.initialize_storages()    return rag

async def main():
    try:
        # åˆå§‹åŒ–RAGå®ä¾‹
        rag = await initialize_rag()
        # æ’å…¥æ–‡æœ¬
        await rag.insert("Your text")

        # æ‰§è¡Œæ··åˆæ£€ç´¢
        mode = "hybrid"
        print(
            await rag.query(
                "è¿™ä¸ªæ•…äº‹çš„ä¸»è¦ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ",
                param=QueryParam(mode=mode)
            )
        )

    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        if rag:
            await rag.finalize_storages()

if __name__ == "__main__":
    asyncio.run(main())
```

é‡è¦è¯´æ˜ï¼š
- è¿è¡Œè„šæœ¬å‰è¯·å…ˆå¯¼å‡ºä½ çš„OPENAI_API_KEYç¯å¢ƒå˜é‡ã€‚
- è¯¥ç¨‹åºä½¿ç”¨LightRAGçš„é»˜è®¤å­˜å‚¨è®¾ç½®ï¼Œæ‰€æœ‰æ•°æ®å°†æŒä¹…åŒ–åœ¨WORKING_DIR/rag_storageç›®å½•ä¸‹ã€‚
- è¯¥ç¤ºä¾‹ä»…å±•ç¤ºäº†åˆå§‹åŒ–LightRAGå¯¹è±¡çš„æœ€ç®€å•æ–¹å¼ï¼šæ³¨å…¥embeddingå’ŒLLMå‡½æ•°ï¼Œå¹¶åœ¨åˆ›å»ºLightRAGå¯¹è±¡ååˆå§‹åŒ–å­˜å‚¨å’Œç®¡é“çŠ¶æ€ã€‚

### LightRAGåˆå§‹åŒ–å‚æ•°

ä»¥ä¸‹æ˜¯å®Œæ•´çš„LightRAGå¯¹è±¡åˆå§‹åŒ–å‚æ•°æ¸…å•ï¼š

<details>
<summary> å‚æ•° </summary>

| **å‚æ•°** | **ç±»å‹** | **è¯´æ˜** | **é»˜è®¤å€¼** |
|--------------|----------|-----------------|-------------|
| **working_dir** | `str` | å­˜å‚¨ç¼“å­˜çš„ç›®å½• | `lightrag_cache+timestamp` |
| **kv_storage** | `str` | Storage type for documents and text chunks. Supported types: `JsonKVStorage`,`PGKVStorage`,`RedisKVStorage`,`MongoKVStorage` | `JsonKVStorage` |
| **vector_storage** | `str` | Storage type for embedding vectors. Supported types: `NanoVectorDBStorage`,`PGVectorStorage`,`MilvusVectorDBStorage`,`ChromaVectorDBStorage`,`FaissVectorDBStorage`,`MongoVectorDBStorage`,`QdrantVectorDBStorage` | `NanoVectorDBStorage` |
| **graph_storage** | `str` | Storage type for graph edges and nodes. Supported types: `NetworkXStorage`,`Neo4JStorage`,`PGGraphStorage`,`AGEStorage` | `NetworkXStorage` |
| **doc_status_storage** | `str` | Storage type for documents process status. Supported types: `JsonDocStatusStorage`,`PGDocStatusStorage`,`MongoDocStatusStorage` | `JsonDocStatusStorage` |
| **chunk_token_size** | `int` | æ‹†åˆ†æ–‡æ¡£æ—¶æ¯ä¸ªå—çš„æœ€å¤§ä»¤ç‰Œå¤§å° | `1200` |
| **chunk_overlap_token_size** | `int` | æ‹†åˆ†æ–‡æ¡£æ—¶ä¸¤ä¸ªå—ä¹‹é—´çš„é‡å ä»¤ç‰Œå¤§å° | `100` |
| **tokenizer** | `Tokenizer` | ç”¨äºå°†æ–‡æœ¬è½¬æ¢ä¸º tokensï¼ˆæ•°å­—ï¼‰ä»¥åŠä½¿ç”¨éµå¾ª TokenizerInterface åè®®çš„ .encode() å’Œ .decode() å‡½æ•°å°† tokens è½¬æ¢å›æ–‡æœ¬çš„å‡½æ•°ã€‚ å¦‚æœæ‚¨ä¸æŒ‡å®šï¼Œå®ƒå°†ä½¿ç”¨é»˜è®¤çš„ Tiktoken tokenizerã€‚ | `TiktokenTokenizer` |
| **tiktoken_model_name** | `str` | å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯é»˜è®¤çš„ Tiktoken tokenizerï¼Œé‚£ä¹ˆè¿™æ˜¯è¦ä½¿ç”¨çš„ç‰¹å®š Tiktoken æ¨¡å‹çš„åç§°ã€‚å¦‚æœæ‚¨æä¾›è‡ªå·±çš„ tokenizerï¼Œåˆ™å¿½ç•¥æ­¤è®¾ç½®ã€‚ | `gpt-4o-mini` |
| **entity_extract_max_gleaning** | `int` | å®ä½“æå–è¿‡ç¨‹ä¸­çš„å¾ªç¯æ¬¡æ•°ï¼Œé™„åŠ å†å²æ¶ˆæ¯ | `1` |
| **node_embedding_algorithm** | `str` | èŠ‚ç‚¹åµŒå…¥ç®—æ³•ï¼ˆå½“å‰æœªä½¿ç”¨ï¼‰ | `node2vec` |
| **node2vec_params** | `dict` | èŠ‚ç‚¹åµŒå…¥çš„å‚æ•° | `{"dimensions": 1536,"num_walks": 10,"walk_length": 40,"window_size": 2,"iterations": 3,"random_seed": 3,}` |
| **embedding_func** | `EmbeddingFunc` | ä»æ–‡æœ¬ç”ŸæˆåµŒå…¥å‘é‡çš„å‡½æ•° | `openai_embed` |
| **embedding_batch_num** | `int` | åµŒå…¥è¿‡ç¨‹çš„æœ€å¤§æ‰¹é‡å¤§å°ï¼ˆæ¯æ‰¹å‘é€å¤šä¸ªæ–‡æœ¬ï¼‰ | `32` |
| **embedding_func_max_async** | `int` | æœ€å¤§å¹¶å‘å¼‚æ­¥åµŒå…¥è¿›ç¨‹æ•° | `16` |
| **llm_model_func** | `callable` | LLMç”Ÿæˆçš„å‡½æ•° | `gpt_4o_mini_complete` |
| **llm_model_name** | `str` | ç”¨äºç”Ÿæˆçš„LLMæ¨¡å‹åç§° | `meta-llama/Llama-3.2-1B-Instruct` |
| **summary_context_size** | `int` | åˆå¹¶å®ä½“å…³ç³»æ‘˜è¦æ—¶é€ç»™LLMçš„æœ€å¤§ä»¤ç‰Œæ•° | `10000`ï¼ˆç”±ç¯å¢ƒå˜é‡ SUMMARY_MAX_CONTEXT è®¾ç½®ï¼‰ |
| **summary_max_tokens** | `int` | åˆå¹¶å®ä½“å…³ç³»æè¿°çš„æœ€å¤§ä»¤ç‰Œæ•°é•¿åº¦ | `500`ï¼ˆç”±ç¯å¢ƒå˜é‡ SUMMARY_MAX_TOKENS è®¾ç½®ï¼‰ |
| **llm_model_max_async** | `int` | æœ€å¤§å¹¶å‘å¼‚æ­¥LLMè¿›ç¨‹æ•° | `4`ï¼ˆé»˜è®¤å€¼ç”±ç¯å¢ƒå˜é‡MAX_ASYNCæ›´æ”¹ï¼‰ |
| **llm_model_kwargs** | `dict` | LLMç”Ÿæˆçš„é™„åŠ å‚æ•° | |
| **vector_db_storage_cls_kwargs** | `dict` | å‘é‡æ•°æ®åº“çš„é™„åŠ å‚æ•°ï¼Œå¦‚è®¾ç½®èŠ‚ç‚¹å’Œå…³ç³»æ£€ç´¢çš„é˜ˆå€¼ | cosine_better_than_threshold: 0.2ï¼ˆé»˜è®¤å€¼ç”±ç¯å¢ƒå˜é‡COSINE_THRESHOLDæ›´æ”¹ï¼‰ |
| **enable_llm_cache** | `bool` | å¦‚æœä¸º`TRUE`ï¼Œå°†LLMç»“æœå­˜å‚¨åœ¨ç¼“å­˜ä¸­ï¼›é‡å¤çš„æç¤ºè¿”å›ç¼“å­˜çš„å“åº” | `TRUE` |
| **enable_llm_cache_for_entity_extract** | `bool` | å¦‚æœä¸º`TRUE`ï¼Œå°†å®ä½“æå–çš„LLMç»“æœå­˜å‚¨åœ¨ç¼“å­˜ä¸­ï¼›é€‚åˆåˆå­¦è€…è°ƒè¯•åº”ç”¨ç¨‹åº | `TRUE` |
| **addon_params** | `dict` | é™„åŠ å‚æ•°ï¼Œä¾‹å¦‚`{"language": "Simplified Chinese", "entity_types": ["organization", "person", "location", "event"]}`ï¼šè®¾ç½®ç¤ºä¾‹é™åˆ¶ã€è¾“å‡ºè¯­è¨€å’Œæ–‡æ¡£å¤„ç†çš„æ‰¹é‡å¤§å° | language: English` |
| **embedding_cache_config** | `dict` | é—®ç­”ç¼“å­˜çš„é…ç½®ã€‚åŒ…å«ä¸‰ä¸ªå‚æ•°ï¼š`enabled`ï¼šå¸ƒå°”å€¼ï¼Œå¯ç”¨/ç¦ç”¨ç¼“å­˜æŸ¥æ‰¾åŠŸèƒ½ã€‚å¯ç”¨æ—¶ï¼Œç³»ç»Ÿå°†åœ¨ç”Ÿæˆæ–°ç­”æ¡ˆä¹‹å‰æ£€æŸ¥ç¼“å­˜çš„å“åº”ã€‚`similarity_threshold`ï¼šæµ®ç‚¹å€¼ï¼ˆ0-1ï¼‰ï¼Œç›¸ä¼¼åº¦é˜ˆå€¼ã€‚å½“æ–°é—®é¢˜ä¸ç¼“å­˜é—®é¢˜çš„ç›¸ä¼¼åº¦è¶…è¿‡æ­¤é˜ˆå€¼æ—¶ï¼Œå°†ç›´æ¥è¿”å›ç¼“å­˜çš„ç­”æ¡ˆè€Œä¸è°ƒç”¨LLMã€‚`use_llm_check`ï¼šå¸ƒå°”å€¼ï¼Œå¯ç”¨/ç¦ç”¨LLMç›¸ä¼¼åº¦éªŒè¯ã€‚å¯ç”¨æ—¶ï¼Œåœ¨è¿”å›ç¼“å­˜ç­”æ¡ˆä¹‹å‰ï¼Œå°†ä½¿ç”¨LLMä½œä¸ºäºŒæ¬¡æ£€æŸ¥æ¥éªŒè¯é—®é¢˜ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚ | é»˜è®¤ï¼š`{"enabled": False, "similarity_threshold": 0.95, "use_llm_check": False}` |

</details>

### æŸ¥è¯¢å‚æ•°

ä½¿ç”¨QueryParamæ§åˆ¶ä½ çš„æŸ¥è¯¢è¡Œä¸ºï¼š

```python
class QueryParam:
    """Configuration parameters for query execution in LightRAG."""

    mode: Literal["local", "global", "hybrid", "naive", "mix", "bypass"] = "global"
    """Specifies the retrieval mode:
    - "local": Focuses on context-dependent information.
    - "global": Utilizes global knowledge.
    - "hybrid": Combines local and global retrieval methods.
    - "naive": Performs a basic search without advanced techniques.
    - "mix": Integrates knowledge graph and vector retrieval.
    """

    only_need_context: bool = False
    """If True, only returns the retrieved context without generating a response."""

    only_need_prompt: bool = False
    """If True, only returns the generated prompt without producing a response."""

    response_type: str = "Multiple Paragraphs"
    """Defines the response format. Examples: 'Multiple Paragraphs', 'Single Paragraph', 'Bullet Points'."""

    stream: bool = False
    """If True, enables streaming output for real-time responses."""

    top_k: int = int(os.getenv("TOP_K", "60"))
    """Number of top items to retrieve. Represents entities in 'local' mode and relationships in 'global' mode."""

    chunk_top_k: int = int(os.getenv("CHUNK_TOP_K", "20"))
    """Number of text chunks to retrieve initially from vector search and keep after reranking.
    If None, defaults to top_k value.
    """

    max_entity_tokens: int = int(os.getenv("MAX_ENTITY_TOKENS", "6000"))
    """Maximum number of tokens allocated for entity context in unified token control system."""

    max_relation_tokens: int = int(os.getenv("MAX_RELATION_TOKENS", "8000"))
    """Maximum number of tokens allocated for relationship context in unified token control system."""

    max_total_tokens: int = int(os.getenv("MAX_TOTAL_TOKENS", "30000"))
    """Maximum total tokens budget for the entire query context (entities + relations + chunks + system prompt)."""

    hl_keywords: list[str] = field(default_factory=list)
    """List of high-level keywords to prioritize in retrieval."""

    ll_keywords: list[str] = field(default_factory=list)
    """List of low-level keywords to refine retrieval focus."""

    # History mesages is only send to LLM for context, not used for retrieval
    conversation_history: list[dict[str, str]] = field(default_factory=list)
    """Stores past conversation history to maintain context.
    Format: [{"role": "user/assistant", "content": "message"}].
    """

    ids: list[str] | None = None
    """List of ids to filter the results."""

    model_func: Callable[..., object] | None = None
    """Optional override for the LLM model function to use for this specific query.
    If provided, this will be used instead of the global model function.
    This allows using different models for different query modes.
    """

    user_prompt: str | None = None
    """User-provided prompt for the query.
    Addition instructions for LLM. If provided, this will be inject into the prompt template.
    It's purpose is the let user customize the way LLM generate the response.
    """

    enable_rerank: bool = True
    """Enable reranking for retrieved text chunks. If True but no rerank model is configured, a warning will be issued.
    Default is True to enable reranking when rerank model is available.
    """
```

> top_kçš„é»˜è®¤å€¼å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡TOP_Kæ›´æ”¹ã€‚

### LLM and Embeddingæ³¨å…¥

LightRAG éœ€è¦åˆ©ç”¨LLMå’ŒEmbedingæ¨¡å‹æ¥å®Œæˆæ–‡æ¡£ç´¢å¼•å’ŒçŸ¥è¯†åº“æŸ¥è¯¢å·¥ä½œã€‚åœ¨åˆå§‹åŒ–LightRAGçš„æ—¶å€™éœ€è¦æŠŠé˜¶æ®µï¼Œéœ€è¦æŠŠLLMå’ŒEmbeddingçš„æ“ä½œå‡½æ•°æ³¨å…¥åˆ°å¯¹è±¡ä¸­ï¼š

<details>
<summary> <b>ä½¿ç”¨ç±»OpenAIçš„API</b> </summary>

* LightRAGè¿˜æ”¯æŒç±»OpenAIçš„èŠå¤©/åµŒå…¥APIï¼š

```python
import os
import numpy as np
from lightrag.utils import wrap_embedding_func_with_attrs
from lightrag.llm.openai import openai_complete_if_cache, openai_embed

async def llm_model_func(
    prompt, system_prompt=None, history_messages=[], keyword_extraction=False, **kwargs
) -> str:
    return await openai_complete_if_cache(
        "solar-mini",
        prompt,
        system_prompt=system_prompt,
        history_messages=history_messages,
        api_key=os.getenv("UPSTAGE_API_KEY"),
        base_url="https://api.upstage.ai/v1/solar",
        **kwargs
    )

@wrap_embedding_func_with_attrs(embedding_dim=4096, max_token_size=8192)
async def embedding_func(texts: list[str]) -> np.ndarray:
    return await openai_embed.func(
        texts,
        model="solar-embedding-1-large-query",
        api_key=os.getenv("UPSTAGE_API_KEY"),
        base_url="https://api.upstage.ai/v1/solar"
    )

async def initialize_rag():
    rag = LightRAG(
        working_dir=WORKING_DIR,
        llm_model_func=llm_model_func,
        embedding_func=embedding_func  # ç›´æ¥ä¼ å…¥è£…é¥°åçš„å‡½æ•°
    )

    await rag.initialize_storages()
    return rag
```

</details>

<details>
<summary> <b>ä½¿ç”¨Hugging Faceæ¨¡å‹</b> </summary>

* å¦‚æœæ‚¨æƒ³ä½¿ç”¨Hugging Faceæ¨¡å‹ï¼Œåªéœ€è¦æŒ‰å¦‚ä¸‹æ–¹å¼è®¾ç½®LightRAGï¼š

å‚è§`lightrag_hf_demo.py`

```python
# ä½¿ç”¨Hugging Faceæ¨¡å‹åˆå§‹åŒ–LightRAG
rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=hf_model_complete,  # ä½¿ç”¨Hugging Faceæ¨¡å‹è¿›è¡Œæ–‡æœ¬ç”Ÿæˆ
    llm_model_name='meta-llama/Llama-3.1-8B-Instruct',  # Hugging Faceçš„æ¨¡å‹åç§°
    # ä½¿ç”¨Hugging FaceåµŒå…¥å‡½æ•°
    embedding_func=EmbeddingFunc(
        embedding_dim=384,
        func=lambda texts: hf_embed(
            texts,
            tokenizer=AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2"),
            embed_model=AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
        )
    ),
)
```

</details>

<details>
<summary> <b>ä½¿ç”¨Ollamaæ¨¡å‹</b> </summary>
å¦‚æœæ‚¨æƒ³ä½¿ç”¨Ollamaæ¨¡å‹ï¼Œæ‚¨éœ€è¦æ‹‰å–è®¡åˆ’ä½¿ç”¨çš„æ¨¡å‹å’ŒåµŒå…¥æ¨¡å‹ï¼Œä¾‹å¦‚`nomic-embed-text`ã€‚

ç„¶åæ‚¨åªéœ€è¦æŒ‰å¦‚ä¸‹æ–¹å¼è®¾ç½®LightRAGï¼š

```python
import numpy as np
from lightrag.utils import wrap_embedding_func_with_attrs
from lightrag.llm.ollama import ollama_model_complete, ollama_embed

@wrap_embedding_func_with_attrs(embedding_dim=768, max_token_size=8192)
async def embedding_func(texts: list[str]) -> np.ndarray:
    return await ollama_embed.func(texts, embed_model="nomic-embed-text")

# ä½¿ç”¨Ollamaæ¨¡å‹åˆå§‹åŒ–LightRAG
rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete,  # ä½¿ç”¨Ollamaæ¨¡å‹è¿›è¡Œæ–‡æœ¬ç”Ÿæˆ
    llm_model_name='your_model_name', # æ‚¨çš„æ¨¡å‹åç§°
    embedding_func=embedding_func,  # ç›´æ¥ä¼ å…¥è£…é¥°åçš„å‡½æ•°
)
```

* **å¢åŠ ä¸Šä¸‹æ–‡å¤§å°**

ä¸ºäº†ä½¿LightRAGæ­£å¸¸å·¥ä½œï¼Œä¸Šä¸‹æ–‡åº”è‡³å°‘ä¸º32kä»¤ç‰Œã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒOllamaæ¨¡å‹çš„ä¸Šä¸‹æ–‡å¤§å°ä¸º8kã€‚æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹ä¸¤ç§æ–¹å¼ä¹‹ä¸€å®ç°è¿™ä¸€ç‚¹ï¼š

* **åœ¨Modelfileä¸­å¢åŠ `num_ctx`å‚æ•°**

1. æ‹‰å–æ¨¡å‹ï¼š

```bash
ollama pull qwen2
```

2. æ˜¾ç¤ºæ¨¡å‹æ–‡ä»¶ï¼š

```bash
ollama show --modelfile qwen2 > Modelfile
```

3. ç¼–è¾‘Modelfileï¼Œæ·»åŠ ä»¥ä¸‹è¡Œï¼š

```bash
PARAMETER num_ctx 32768
```

4. åˆ›å»ºä¿®æ”¹åçš„æ¨¡å‹ï¼š

```bash
ollama create -f Modelfile qwen2m
```

* **é€šè¿‡Ollama APIè®¾ç½®`num_ctx`**

æ‚¨å¯ä»¥ä½¿ç”¨`llm_model_kwargs`å‚æ•°é…ç½®ollamaï¼š

```python
import numpy as np
from lightrag.utils import wrap_embedding_func_with_attrs
from lightrag.llm.ollama import ollama_model_complete, ollama_embed

@wrap_embedding_func_with_attrs(embedding_dim=768, max_token_size=8192)
async def embedding_func(texts: list[str]) -> np.ndarray:
    return await ollama_embed.func(texts, embed_model="nomic-embed-text")

rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete,  # ä½¿ç”¨Ollamaæ¨¡å‹è¿›è¡Œæ–‡æœ¬ç”Ÿæˆ
    llm_model_name='your_model_name', # æ‚¨çš„æ¨¡å‹åç§°
    llm_model_kwargs={"options": {"num_ctx": 32768}},
    embedding_func=embedding_func,  # ç›´æ¥ä¼ å…¥è£…é¥°åçš„å‡½æ•°
)
```

* **ä½RAM GPU**

ä¸ºäº†åœ¨ä½RAM GPUä¸Šè¿è¡Œæ­¤å®éªŒï¼Œæ‚¨åº”è¯¥é€‰æ‹©å°å‹æ¨¡å‹å¹¶è°ƒæ•´ä¸Šä¸‹æ–‡çª—å£ï¼ˆå¢åŠ ä¸Šä¸‹æ–‡ä¼šå¢åŠ å†…å­˜æ¶ˆè€—ï¼‰ã€‚ä¾‹å¦‚ï¼Œåœ¨6Gb RAMçš„æ”¹è£…æŒ–çŸ¿GPUä¸Šè¿è¡Œè¿™ä¸ªollamaç¤ºä¾‹éœ€è¦å°†ä¸Šä¸‹æ–‡å¤§å°è®¾ç½®ä¸º26kï¼ŒåŒæ—¶ä½¿ç”¨`gemma2:2b`ã€‚å®ƒèƒ½å¤Ÿåœ¨`book.txt`ä¸­æ‰¾åˆ°197ä¸ªå®ä½“å’Œ19ä¸ªå…³ç³»ã€‚

</details>
<details>
<summary> <b>LlamaIndex</b> </summary>

LightRAGæ”¯æŒä¸LlamaIndexé›†æˆ (`llm/llama_index_impl.py`):

- é€šè¿‡LlamaIndexä¸OpenAIå’Œå…¶ä»–æä¾›å•†é›†æˆ
- è¯¦ç»†è®¾ç½®å’Œç¤ºä¾‹è¯·å‚è§[LlamaIndexæ–‡æ¡£](lightrag/llm/Readme.md)

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
# ä½¿ç”¨LlamaIndexç›´æ¥è®¿é—®OpenAI
import asyncio
from lightrag import LightRAG
from lightrag.llm.llama_index_impl import llama_index_complete_if_cache, llama_index_embed
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
from lightrag.utils import setup_logger

# ä¸ºLightRAGè®¾ç½®æ—¥å¿—å¤„ç†ç¨‹åº
setup_logger("lightrag", level="INFO")

async def initialize_rag():
    rag = LightRAG(
        working_dir="your/path",
        llm_model_func=llama_index_complete_if_cache,  # LlamaIndexå…¼å®¹çš„å®Œæˆå‡½æ•°
        embedding_func=EmbeddingFunc(    # LlamaIndexå…¼å®¹çš„åµŒå…¥å‡½æ•°
            embedding_dim=1536,
            func=lambda texts: llama_index_embed(texts, embed_model=embed_model)
        ),
    )

    await rag.initialize_storages()
    return rag

def main():
    # åˆå§‹åŒ–RAGå®ä¾‹
    rag = asyncio.run(initialize_rag())

    with open("./book.txt", "r", encoding="utf-8") as f:
        rag.insert(f.read())

    # æ‰§è¡Œæœ´ç´ æœç´¢
    print(
        rag.query("è¿™ä¸ªæ•…äº‹çš„ä¸»è¦ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ", param=QueryParam(mode="naive"))
    )

    # æ‰§è¡Œæœ¬åœ°æœç´¢
    print(
        rag.query("è¿™ä¸ªæ•…äº‹çš„ä¸»è¦ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ", param=QueryParam(mode="local"))
    )

    # æ‰§è¡Œå…¨å±€æœç´¢
    print(
        rag.query("è¿™ä¸ªæ•…äº‹çš„ä¸»è¦ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ", param=QueryParam(mode="global"))
    )

    # æ‰§è¡Œæ··åˆæœç´¢
    print(
        rag.query("è¿™ä¸ªæ•…äº‹çš„ä¸»è¦ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ", param=QueryParam(mode="hybrid"))
    )

if __name__ == "__main__":
    main()
```

**è¯¦ç»†æ–‡æ¡£å’Œç¤ºä¾‹ï¼Œè¯·å‚è§ï¼š**

- [LlamaIndexæ–‡æ¡£](lightrag/llm/Readme.md)
- [ç›´æ¥OpenAIç¤ºä¾‹](examples/lightrag_llamaindex_direct_demo.py)
- [LiteLLMä»£ç†ç¤ºä¾‹](examples/lightrag_llamaindex_litellm_demo.py)

</details>

### Rerankå‡½æ•°æ³¨å…¥

ä¸ºäº†æé«˜æ£€ç´¢è´¨é‡ï¼Œå¯ä»¥æ ¹æ®æ›´æœ‰æ•ˆçš„ç›¸å…³æ€§è¯„åˆ†æ¨¡å‹å¯¹æ–‡æ¡£è¿›è¡Œé‡æ’åºã€‚`rerank.py`æ–‡ä»¶æä¾›äº†ä¸‰ä¸ªRerankeræä¾›å•†çš„é©±åŠ¨å‡½æ•°ï¼š

* **Cohere / vLLM**: `cohere_rerank`
* **Jina AI**: `jina_rerank`
* **Aliyuné˜¿é‡Œäº‘**: `ali_rerank`

æ‚¨å¯ä»¥å°†è¿™äº›å‡½æ•°ä¹‹ä¸€æ³¨å…¥åˆ°LightRAGå¯¹è±¡çš„`rerank_model_func`å±æ€§ä¸­ã€‚è¿™å°†ä½¿LightRAGçš„æŸ¥è¯¢åŠŸèƒ½èƒ½å¤Ÿä½¿ç”¨æ³¨å…¥çš„å‡½æ•°å¯¹æ£€ç´¢åˆ°çš„æ–‡æœ¬å—è¿›è¡Œé‡æ–°æ’åºã€‚æœ‰å…³è¯¦ç»†ç”¨æ³•ï¼Œè¯·å‚é˜…`examples/rerank_example.py`æ–‡ä»¶ã€‚

### ç”¨æˆ·æç¤ºè¯ vs. æŸ¥è¯¢å†…å®¹

å½“ä½¿ç”¨LightRAGæŸ¥è¯¢å†…å®¹çš„æ—¶å€™ï¼Œä¸è¦æŠŠå†…å®¹æŸ¥è¯¢å’Œä¸æŸ¥è¯¢ç»“æœæ— å…³çš„è¾“å‡ºåŠ å·¥å†™åœ¨ä¸€èµ·ã€‚å› ä¸ºæŠŠä¸¤è€…æ··åœ¨ä¸€èµ·ä¼šä¸¥é‡å½±å“æŸ¥è¯¢çš„æ•ˆæœã€‚Query Paramä¸­çš„`user_prompt`å°±æ˜¯ä¸ºè§£å†³è¿™ä¸€é—®é¢˜è€Œè®¾è®¡çš„ã€‚`user_prompt`ä¸­çš„å†…å®¹ä¸å‚ä¸RAGä¸­çš„æŸ¥è¯¢è¿‡ç¨‹ï¼Œå®ƒä»…ä¼šåœ¨è·å¾—æŸ¥è¯¢ç»“æœä¹‹åï¼Œä¸æŸ¥è¯¢ç»“æœä¸€èµ·é€ç»™LLMï¼ŒæŒ‡å¯¼LLMå¦‚ä½•å¤„ç†æŸ¥è¯¢ç»“æœã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨æ–¹æ³•ï¼š

```python
# Create query parameters
query_param = QueryParam(
    mode = "hybrid",  # Other modesï¼šlocal, global, hybrid, mix, naive
    user_prompt = "å¦‚éœ€ç”»å›¾ä½¿ç”¨mermaidæ ¼å¼ï¼ŒèŠ‚ç‚¹åç§°ç”¨è‹±æ–‡æˆ–æ‹¼éŸ³ï¼Œæ˜¾ç¤ºåç§°ç”¨ä¸­æ–‡",
)

# Query and process
response_default = rag.query(
    "è¯·ç”»å‡º Scrooge çš„äººç‰©å…³ç³»å›¾è°±",
    param=query_param
)
print(response_default)
```

### æ’å…¥

<details>
  <summary> <b> åŸºæœ¬æ’å…¥ </b></summary>

```python
# åŸºæœ¬æ’å…¥
rag.insert("æ–‡æœ¬")
```

</details>

<details>
  <summary> <b> æ‰¹é‡æ’å…¥ </b></summary>

```python
# åŸºæœ¬æ‰¹é‡æ’å…¥ï¼šä¸€æ¬¡æ’å…¥å¤šä¸ªæ–‡æœ¬
rag.insert(["æ–‡æœ¬1", "æ–‡æœ¬2",...])

# å¸¦æœ‰è‡ªå®šä¹‰æ‰¹é‡å¤§å°é…ç½®çš„æ‰¹é‡æ’å…¥
rag = LightRAG(
    ...
    working_dir=WORKING_DIR,
    max_parallel_insert = 4
)

rag.insert(["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3", ...])  # æ–‡æ¡£å°†ä»¥4ä¸ªä¸ºä¸€æ‰¹è¿›è¡Œå¤„ç†
```

å‚æ•° `max_parallel_insert` ç”¨äºæ§åˆ¶æ–‡æ¡£ç´¢å¼•æµæ°´çº¿ä¸­å¹¶è¡Œå¤„ç†çš„æ–‡æ¡£æ•°é‡ã€‚è‹¥æœªæŒ‡å®šï¼Œé»˜è®¤å€¼ä¸º **2**ã€‚å»ºè®®å°†è¯¥å‚æ•°è®¾ç½®ä¸º **10 ä»¥ä¸‹**ï¼Œå› ä¸ºæ€§èƒ½ç“¶é¢ˆé€šå¸¸å‡ºç°åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤„ç†ç¯èŠ‚ã€‚

</details>

<details>
  <summary> <b> å¸¦IDæ’å…¥ </b></summary>

å¦‚æœæ‚¨æƒ³ä¸ºæ–‡æ¡£æä¾›è‡ªå·±çš„IDï¼Œæ–‡æ¡£æ•°é‡å’ŒIDæ•°é‡å¿…é¡»ç›¸åŒã€‚

```python
# æ’å…¥å•ä¸ªæ–‡æœ¬ï¼Œå¹¶ä¸ºå…¶æä¾›ID
rag.insert("æ–‡æœ¬1", ids=["æ–‡æœ¬1çš„ID"])

# æ’å…¥å¤šä¸ªæ–‡æœ¬ï¼Œå¹¶ä¸ºå®ƒä»¬æä¾›ID
rag.insert(["æ–‡æœ¬1", "æ–‡æœ¬2",...], ids=["æ–‡æœ¬1çš„ID", "æ–‡æœ¬2çš„ID"])
```

</details>

<details>
  <summary><b>ä½¿ç”¨æµæ°´çº¿æ’å…¥</b></summary>

`apipeline_enqueue_documents`å’Œ`apipeline_process_enqueue_documents`å‡½æ•°å…è®¸æ‚¨å¯¹æ–‡æ¡£è¿›è¡Œå¢é‡æ’å…¥åˆ°å›¾ä¸­ã€‚

è¿™å¯¹äºéœ€è¦åœ¨åå°å¤„ç†æ–‡æ¡£çš„åœºæ™¯å¾ˆæœ‰ç”¨ï¼ŒåŒæ—¶ä»å…è®¸ä¸»çº¿ç¨‹ç»§ç»­æ‰§è¡Œã€‚

å¹¶ä½¿ç”¨ä¾‹ç¨‹å¤„ç†æ–°æ–‡æ¡£ã€‚

```python
rag = LightRAG(..)

await rag.apipeline_enqueue_documents(input)
# æ‚¨çš„å¾ªç¯ä¾‹ç¨‹
await rag.apipeline_process_enqueue_documents(input)
```

</details>

<details>
  <summary><b>æ’å…¥å¤šæ–‡ä»¶ç±»å‹æ”¯æŒ</b></summary>

`textract`æ”¯æŒè¯»å–TXTã€DOCXã€PPTXã€CSVå’ŒPDFç­‰æ–‡ä»¶ç±»å‹ã€‚

```python
import textract

file_path = 'TEXT.pdf'
text_content = textract.process(file_path)

rag.insert(text_content.decode('utf-8'))
```

</details>

<details>
  <summary><b>å¼•æ–‡åŠŸèƒ½</b></summary>

é€šè¿‡æä¾›æ–‡ä»¶è·¯å¾„ï¼Œç³»ç»Ÿç¡®ä¿å¯ä»¥å°†æ¥æºè¿½æº¯åˆ°å…¶åŸå§‹æ–‡æ¡£ã€‚

```python
# å®šä¹‰æ–‡æ¡£åŠå…¶æ–‡ä»¶è·¯å¾„
documents = ["æ–‡æ¡£å†…å®¹1", "æ–‡æ¡£å†…å®¹2"]
file_paths = ["path/to/doc1.txt", "path/to/doc2.txt"]

# æ’å…¥å¸¦æœ‰æ–‡ä»¶è·¯å¾„çš„æ–‡æ¡£
rag.insert(documents, file_paths=file_paths)
```

</details>

### å­˜å‚¨

LightRAG ä½¿ç”¨ 4 ç§ç±»å‹çš„å­˜å‚¨ç”¨äºä¸åŒç›®çš„ï¼š

* KV_STORAGEï¼šllm å“åº”ç¼“å­˜ã€æ–‡æœ¬å—ã€æ–‡æ¡£ä¿¡æ¯
* VECTOR_STORAGEï¼šå®ä½“å‘é‡ã€å…³ç³»å‘é‡ã€å—å‘é‡
* GRAPH_STORAGEï¼šå®ä½“å…³ç³»å›¾
* DOC_STATUS_STORAGEï¼šæ–‡æ¡£ç´¢å¼•çŠ¶æ€

æ¯ç§å­˜å‚¨ç±»å‹éƒ½æœ‰å‡ ç§å®ç°ï¼š

* KV_STORAGE æ”¯æŒçš„å®ç°åç§°

```
JsonKVStorage    JsonFile(é»˜è®¤)
PGKVStorage      Postgres
RedisKVStorage   Redis
MongoKVStorage   MogonDB
```

* GRAPH_STORAGE æ”¯æŒçš„å®ç°åç§°

```
NetworkXStorage      NetworkX(é»˜è®¤)
Neo4JStorage         Neo4J
PGGraphStorage       PostgreSQL with AGE plugin
```

> åœ¨æµ‹è¯•ä¸­Neo4jå›¾å½¢æ•°æ®åº“ç›¸æ¯”PostgreSQL AGEæœ‰æ›´å¥½çš„æ€§èƒ½è¡¨ç°ã€‚

* VECTOR_STORAGE æ”¯æŒçš„å®ç°åç§°

```
NanoVectorDBStorage         NanoVector(é»˜è®¤)
PGVectorStorage             Postgres
MilvusVectorDBStorge        Milvus
FaissVectorDBStorage        Faiss
QdrantVectorDBStorage       Qdrant
MongoVectorDBStorage        MongoDB
```

* DOC_STATUS_STORAGE æ”¯æŒçš„å®ç°åç§°

```
JsonDocStatusStorage        JsonFile(é»˜è®¤)
PGDocStatusStorage          Postgres
MongoDocStatusStorage       MongoDB
```

æ¯ä¸€ç§å­˜å‚¨ç±»å‹çš„é“¾æ¥é…ç½®èŒƒä¾‹å¯ä»¥åœ¨ `env.example` æ–‡ä»¶ä¸­æ‰¾åˆ°ã€‚é“¾æ¥å­—ç¬¦ä¸²ä¸­çš„æ•°æ®åº“å®ä¾‹æ˜¯éœ€è¦ä½ é¢„å…ˆåœ¨æ•°æ®åº“æœåŠ¡å™¨ä¸Šåˆ›å»ºå¥½çš„ï¼ŒLightRAG ä»…è´Ÿè´£åœ¨æ•°æ®åº“å®ä¾‹ä¸­åˆ›å»ºæ•°æ®è¡¨ï¼Œä¸è´Ÿè´£åˆ›å»ºæ•°æ®åº“å®ä¾‹ã€‚å¦‚æœä½¿ç”¨ Redis ä½œä¸ºå­˜å‚¨ï¼Œè®°å¾—ç»™ Redis é…ç½®è‡ªåŠ¨æŒä¹…åŒ–æ•°æ®è§„åˆ™ï¼Œå¦åˆ™ Redis æœåŠ¡é‡å¯åæ•°æ®ä¼šä¸¢å¤±ã€‚å¦‚æœä½¿ç”¨PostgreSQLæ•°æ®åº“ï¼Œæ¨èä½¿ç”¨16.6ç‰ˆæœ¬æˆ–ä»¥ä¸Šã€‚

<details>
<summary> <b>ä½¿ç”¨Neo4Jå­˜å‚¨</b> </summary>

* å¯¹äºç”Ÿäº§çº§åœºæ™¯ï¼Œæ‚¨å¾ˆå¯èƒ½æƒ³è¦åˆ©ç”¨ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆ
* è¿›è¡ŒKGå­˜å‚¨ã€‚æ¨èåœ¨Dockerä¸­è¿è¡ŒNeo4Jä»¥è¿›è¡Œæ— ç¼æœ¬åœ°æµ‹è¯•ã€‚
* å‚è§ï¼šhttps://hub.docker.com/_/neo4j

```python
export NEO4J_URI="neo4j://localhost:7687"
export NEO4J_USERNAME="neo4j"
export NEO4J_PASSWORD="password"

# ä¸ºLightRAGè®¾ç½®æ—¥å¿—è®°å½•å™¨
setup_logger("lightrag", level="INFO")

# å½“æ‚¨å¯åŠ¨é¡¹ç›®æ—¶ï¼Œè¯·ç¡®ä¿é€šè¿‡æŒ‡å®škg="Neo4JStorage"æ¥è¦†ç›–é»˜è®¤çš„KGï¼šNetworkXã€‚

# æ³¨æ„ï¼šé»˜è®¤è®¾ç½®ä½¿ç”¨NetworkX
# ä½¿ç”¨Neo4Jå®ç°åˆå§‹åŒ–LightRAGã€‚
async def initialize_rag():
    rag = LightRAG(
        working_dir=WORKING_DIR,
        llm_model_func=gpt_4o_mini_complete,  # ä½¿ç”¨gpt_4o_mini_complete LLMæ¨¡å‹
        graph_storage="Neo4JStorage", #<-----------è¦†ç›–KGé»˜è®¤å€¼
    )

    # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
    await rag.initialize_storages()
    # åˆå§‹åŒ–æ–‡æ¡£å¤„ç†çš„ç®¡é“çŠ¶æ€
    return rag
```

å‚è§test_neo4j.pyè·å–å·¥ä½œç¤ºä¾‹ã€‚

</details>

<details>
<summary> <b>ä½¿ç”¨Faisså­˜å‚¨</b> </summary>
åœ¨ä½¿ç”¨Faisså‘é‡æ•°æ®åº“ä¹‹å‰å¿…é¡»æ‰‹å·¥å®‰è£…`faiss-cpu`æˆ–`faiss-gpu`ã€‚

- å®‰è£…æ‰€éœ€ä¾èµ–ï¼š

```
pip install faiss-cpu
```

å¦‚æœæ‚¨æœ‰GPUæ”¯æŒï¼Œä¹Ÿå¯ä»¥å®‰è£…`faiss-gpu`ã€‚

- è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨`sentence-transformers`ï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨ç»´åº¦ä¸º`3072`çš„`OpenAIEmbedding`æ¨¡å‹ã€‚

```python
async def embedding_func(texts: list[str]) -> np.ndarray:
    model = SentenceTransformer('all-MiniLM-L6-v2')
    embeddings = model.encode(texts, convert_to_numpy=True)
    return embeddings

# ä½¿ç”¨LLMæ¨¡å‹å‡½æ•°å’ŒåµŒå…¥å‡½æ•°åˆå§‹åŒ–LightRAG
rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=llm_model_func,
    embedding_func=EmbeddingFunc(
        embedding_dim=384,
        func=embedding_func,
    ),
    vector_storage="FaissVectorDBStorage",
    vector_db_storage_cls_kwargs={
        "cosine_better_than_threshold": 0.3  # æ‚¨æœŸæœ›çš„é˜ˆå€¼
    }
)
```

</details>

<details>
<summary> <b>ä½¿ç”¨PostgreSQLå­˜å‚¨</b> </summary>

å¯¹äºç”Ÿäº§çº§åœºæ™¯ï¼Œæ‚¨å¾ˆå¯èƒ½æƒ³è¦åˆ©ç”¨ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆã€‚PostgreSQLå¯ä»¥ä¸ºæ‚¨æä¾›ä¸€ç«™å¼å‚¨è§£è§£å†³æ–¹æ¡ˆï¼Œä½œä¸ºKVå­˜å‚¨ã€å‘é‡æ•°æ®åº“ï¼ˆpgvectorï¼‰å’Œå›¾æ•°æ®åº“ï¼ˆapache AGEï¼‰ã€‚æ”¯æŒ PostgreSQL ç‰ˆæœ¬ä¸º16.6æˆ–ä»¥ä¸Šã€‚

* å¦‚æœæ‚¨æ˜¯åˆå­¦è€…å¹¶æƒ³é¿å…éº»çƒ¦ï¼Œæ¨èä½¿ç”¨dockerï¼Œè¯·ä»è¿™ä¸ªé•œåƒå¼€å§‹ï¼ˆé»˜è®¤å¸å·å¯†ç :rag/ragï¼‰ï¼šhttps://hub.docker.com/r/gzdaniel/postgres-for-rag
* Apache AGEçš„æ€§èƒ½ä¸å¦‚Neo4jã€‚è¿½æ±‚é«˜æ€§èƒ½çš„å›¾æ•°æ®åº“è¯·ä½¿ç”¨Noe4jã€‚

</details>

<details>
<summary> <b>ä½¿ç”¨MogonDBå­˜å‚¨</b> </summary>

MongoDBä¸ºLightRAGæä¾›äº†ä¸€ç«™å¼çš„å­˜å‚¨è§£å†³æ–¹æ¡ˆã€‚MongoDBæä¾›åŸç”Ÿçš„KVå­˜å‚¨å’Œå‘é‡å­˜å‚¨ã€‚LightRAGä½¿ç”¨MogoDBçš„é›†åˆå®ç°äº†ä¸€ä¸ªç®€æ˜“çš„å›¾å­˜å‚¨ã€‚MongoDB å®˜æ–¹çš„å‘é‡æ£€ç´¢åŠŸèƒ½ï¼ˆ`$vectorSearch`ï¼‰ç›®å‰å¿…é¡»ä¾èµ–å…¶å®˜æ–¹çš„äº‘æœåŠ¡ MongoDB Atlasã€‚æ— æ³•åœ¨è‡ªæ‰˜ç®¡çš„ MongoDB Community/Enterprise ç‰ˆæœ¬ä¸Šä½¿ç”¨æ­¤åŠŸèƒ½ã€‚

</details>

<details>
<summary> <b>ä½¿ç”¨Rediså­˜å‚¨</b> </summary>

LightRAGæ”¯æŒä½¿ç”¨Reidisä½œä¸ºKVå­˜å‚¨ã€‚ä½¿ç”¨Rediså­˜å‚¨çš„æ—¶å€™éœ€è¦æ³¨æ„è¿›è¡ŒæŒä¹…åŒ–é…ç½®å’Œå†…å­˜ä½¿ç”¨é‡é…ç½®ã€‚ä»¥ä¸‹æ˜¯æ¨èçš„redisé…ç½®

```
save 900 1
save 300 10
save 60 1000
stop-writes-on-bgsave-error yes
maxmemory 4gb
maxmemory-policy noeviction
maxclients 500
```

</details>

### LightRAGå®ä¾‹é—´çš„æ•°æ®éš”ç¦»

é€šè¿‡ workspace å‚æ•°å¯ä»¥ä¸åŒå®ç°ä¸åŒLightRAGå®ä¾‹ä¹‹é—´çš„å­˜å‚¨æ•°æ®éš”ç¦»ã€‚LightRAGåœ¨åˆå§‹åŒ–åworkspaceå°±å·²ç»ç¡®å®šï¼Œä¹‹åä¿®æ”¹workspaceæ˜¯æ— æ•ˆçš„ã€‚ä¸‹é¢æ˜¯ä¸åŒç±»å‹çš„å­˜å‚¨å®ç°å·¥ä½œç©ºé—´çš„æ–¹å¼ï¼š

- **å¯¹äºæœ¬åœ°åŸºäºæ–‡ä»¶çš„æ•°æ®åº“ï¼Œæ•°æ®éš”ç¦»é€šè¿‡å·¥ä½œç©ºé—´å­ç›®å½•å®ç°ï¼š** JsonKVStorage, JsonDocStatusStorage, NetworkXStorage, NanoVectorDBStorage, FaissVectorDBStorageã€‚
- **å¯¹äºå°†æ•°æ®å­˜å‚¨åœ¨é›†åˆï¼ˆcollectionï¼‰ä¸­çš„æ•°æ®åº“ï¼Œé€šè¿‡åœ¨é›†åˆåç§°å‰æ·»åŠ å·¥ä½œç©ºé—´å‰ç¼€æ¥å®ç°ï¼š** RedisKVStorage, RedisDocStatusStorage, MilvusVectorDBStorage, QdrantVectorDBStorage, MongoKVStorage, MongoDocStatusStorage, MongoVectorDBStorage, MongoGraphStorage, PGGraphStorageã€‚
- **å¯¹äºå…³ç³»å‹æ•°æ®åº“ï¼Œæ•°æ®éš”ç¦»é€šè¿‡å‘è¡¨ä¸­æ·»åŠ  `workspace` å­—æ®µè¿›è¡Œæ•°æ®çš„é€»è¾‘éš”ç¦»ï¼š** PGKVStorage, PGVectorStorage, PGDocStatusStorageã€‚

* **å¯¹äºNeo4jå›¾æ•°æ®åº“ï¼Œé€šè¿‡labelæ¥å®ç°æ•°æ®çš„é€»è¾‘éš”ç¦»**ï¼šNeo4JStorage

ä¸ºäº†ä¿æŒå¯¹é—ç•™æ•°æ®çš„å…¼å®¹ï¼Œåœ¨æœªé…ç½®å·¥ä½œç©ºé—´æ—¶PostgreSQLéå›¾å­˜å‚¨çš„å·¥ä½œç©ºé—´ä¸º`default`ï¼ŒPostgreSQL AGEå›¾å­˜å‚¨çš„å·¥ä½œç©ºé—´ä¸ºç©ºï¼ŒNeo4jå›¾å­˜å‚¨çš„é»˜è®¤å·¥ä½œç©ºé—´ä¸º`base`ã€‚å¯¹äºæ‰€æœ‰çš„å¤–éƒ¨å­˜å‚¨ï¼Œç³»ç»Ÿéƒ½æä¾›äº†ä¸“ç”¨çš„å·¥ä½œç©ºé—´ç¯å¢ƒå˜é‡ï¼Œç”¨äºè¦†ç›–å…¬å…±çš„ `WORKSPACE`ç¯å¢ƒå˜é‡é…ç½®ã€‚è¿™äº›é€‚ç”¨äºæŒ‡å®šå­˜å‚¨ç±»å‹çš„å·¥ä½œç©ºé—´ç¯å¢ƒå˜é‡ä¸ºï¼š`REDIS_WORKSPACE`, `MILVUS_WORKSPACE`, `QDRANT_WORKSPACE`, `MONGODB_WORKSPACE`, `POSTGRES_WORKSPACE`, `NEO4J_WORKSPACE`ã€‚

### AGENTS.md â€“ è‡ªåŠ¨ç¼–ç¨‹å¼•å¯¼æ–‡ä»¶

AGENTS.md æ˜¯ä¸€ç§ç®€æ´ã€å¼€æ”¾çš„æ ¼å¼ï¼Œç”¨äºæŒ‡å¯¼è‡ªåŠ¨ç¼–ç¨‹ä»£ç†å®Œæˆå·¥ä½œï¼ˆhttps://agents.md/ï¼‰ã€‚å®ƒä¸º LightRAG é¡¹ç›®æä¾›äº†ä¸€ä¸ªä¸“å±ä¸”å¯é¢„æµ‹çš„ä¸Šä¸‹æ–‡ä¸æŒ‡ä»¤ä½ç½®ï¼Œå¸®åŠ© AI ä»£ç ä»£ç†æ›´å¥½åœ°å¼€å±•å·¥ä½œã€‚ä¸åŒçš„ AI ä»£ç ä»£ç†ä¸åº”å„è‡ªç»´æŠ¤ç‹¬ç«‹çš„å¼•å¯¼æ–‡ä»¶ã€‚å¦‚æœæŸä¸ª AI ä»£ç†æ— æ³•è‡ªåŠ¨è¯†åˆ« AGENTS.mdï¼Œå¯ä½¿ç”¨ç¬¦å·é“¾æ¥æ¥è§£å†³ã€‚å»ºç«‹ç¬¦å·é“¾æ¥åï¼Œå¯é€šè¿‡é…ç½®æœ¬åœ°çš„ `.gitignore_global` æ–‡ä»¶é˜²æ­¢å…¶è¢«æäº¤è‡³ Git ä»“åº“ã€‚

## ç¼–è¾‘å®ä½“å’Œå…³ç³»

LightRAGç°åœ¨æ”¯æŒå…¨é¢çš„çŸ¥è¯†å›¾è°±ç®¡ç†åŠŸèƒ½ï¼Œå…è®¸æ‚¨åœ¨çŸ¥è¯†å›¾è°±ä¸­åˆ›å»ºã€ç¼–è¾‘å’Œåˆ é™¤å®ä½“å’Œå…³ç³»ã€‚

<details>
<summary> <b>åˆ›å»ºå®ä½“å’Œå…³ç³»</b> </summary>

```python
# åˆ›å»ºæ–°å®ä½“
entity = rag.create_entity("Google", {
    "description": "Googleæ˜¯ä¸€å®¶ä¸“æ³¨äºäº’è”ç½‘ç›¸å…³æœåŠ¡å’Œäº§å“çš„è·¨å›½ç§‘æŠ€å…¬å¸ã€‚",
    "entity_type": "company"
})

# åˆ›å»ºå¦ä¸€ä¸ªå®ä½“
product = rag.create_entity("Gmail", {
    "description": "Gmailæ˜¯ç”±Googleå¼€å‘çš„ç”µå­é‚®ä»¶æœåŠ¡ã€‚",
    "entity_type": "product"
})

# åˆ›å»ºå®ä½“ä¹‹é—´çš„å…³ç³»
relation = rag.create_relation("Google", "Gmail", {
    "description": "Googleå¼€å‘å’Œè¿è¥Gmailã€‚",
    "keywords": "å¼€å‘ è¿è¥ æœåŠ¡",
    "weight": 2.0
})
```

</details>

<details>
<summary> <b>ç¼–è¾‘å®ä½“å’Œå…³ç³»</b> </summary>

```python
# ç¼–è¾‘ç°æœ‰å®ä½“
updated_entity = rag.edit_entity("Google", {
    "description": "Googleæ˜¯Alphabet Inc.çš„å­å…¬å¸ï¼Œæˆç«‹äº1998å¹´ã€‚",
    "entity_type": "tech_company"
})

# é‡å‘½åå®ä½“ï¼ˆæ‰€æœ‰å…³ç³»éƒ½ä¼šæ­£ç¡®è¿ç§»ï¼‰
renamed_entity = rag.edit_entity("Gmail", {
    "entity_name": "Google Mail",
    "description": "Google Mailï¼ˆå‰èº«ä¸ºGmailï¼‰æ˜¯ä¸€é¡¹ç”µå­é‚®ä»¶æœåŠ¡ã€‚"
})

# ç¼–è¾‘å®ä½“ä¹‹é—´çš„å…³ç³»
updated_relation = rag.edit_relation("Google", "Google Mail", {
    "description": "Googleåˆ›å»ºå¹¶ç»´æŠ¤Google MailæœåŠ¡ã€‚",
    "keywords": "åˆ›å»º ç»´æŠ¤ ç”µå­é‚®ä»¶æœåŠ¡",
    "weight": 3.0
})
```

æ‰€æœ‰æ“ä½œéƒ½æœ‰åŒæ­¥å’Œå¼‚æ­¥ç‰ˆæœ¬ã€‚å¼‚æ­¥ç‰ˆæœ¬å¸¦æœ‰å‰ç¼€"a"ï¼ˆä¾‹å¦‚ï¼Œ`acreate_entity`ï¼Œ`aedit_relation`ï¼‰ã€‚

</details>

<details>
<summary> <b>æ’å…¥è‡ªå®šä¹‰çŸ¥è¯†</b> </summary>

```python
custom_kg = {
    "chunks": [
        {
            "content": "Aliceå’ŒBobæ­£åœ¨åˆä½œè¿›è¡Œé‡å­è®¡ç®—ç ”ç©¶ã€‚",
            "source_id": "doc-1"
        }
    ],
    "entities": [
        {
            "entity_name": "Alice",
            "entity_type": "person",
            "description": "Aliceæ˜¯ä¸€ä½ä¸“é—¨ç ”ç©¶é‡å­ç‰©ç†çš„ç ”ç©¶å‘˜ã€‚",
            "source_id": "doc-1"
        },
        {
            "entity_name": "Bob",
            "entity_type": "person",
            "description": "Bobæ˜¯ä¸€ä½æ•°å­¦å®¶ã€‚",
            "source_id": "doc-1"
        },
        {
            "entity_name": "é‡å­è®¡ç®—",
            "entity_type": "technology",
            "description": "é‡å­è®¡ç®—åˆ©ç”¨é‡å­åŠ›å­¦ç°è±¡è¿›è¡Œè®¡ç®—ã€‚",
            "source_id": "doc-1"
        }
    ],
    "relationships": [
        {
            "src_id": "Alice",
            "tgt_id": "Bob",
            "description": "Aliceå’ŒBobæ˜¯ç ”ç©¶ä¼™ä¼´ã€‚",
            "keywords": "åˆä½œ ç ”ç©¶",
            "weight": 1.0,
            "source_id": "doc-1"
        },
        {
            "src_id": "Alice",
            "tgt_id": "é‡å­è®¡ç®—",
            "description": "Aliceè¿›è¡Œé‡å­è®¡ç®—ç ”ç©¶ã€‚",
            "keywords": "ç ”ç©¶ ä¸“ä¸š",
            "weight": 1.0,
            "source_id": "doc-1"
        },
        {
            "src_id": "Bob",
            "tgt_id": "é‡å­è®¡ç®—",
            "description": "Bobç ”ç©¶é‡å­è®¡ç®—ã€‚",
            "keywords": "ç ”ç©¶ åº”ç”¨",
            "weight": 1.0,
            "source_id": "doc-1"
        }
    ]
}

rag.insert_custom_kg(custom_kg)
```

</details>

<details>
<summary> <b>å…¶å®ƒå®ä½“ä¸å…³ç³»æ“ä½œ</b> </summary>

- **create_entity**ï¼šåˆ›å»ºå…·æœ‰æŒ‡å®šå±æ€§çš„æ–°å®ä½“
- **edit_entity**ï¼šæ›´æ–°ç°æœ‰å®ä½“çš„å±æ€§æˆ–é‡å‘½åå®ƒ

- **create_relation**ï¼šåœ¨ç°æœ‰å®ä½“ä¹‹é—´åˆ›å»ºæ–°å…³ç³»
- **edit_relation**ï¼šæ›´æ–°ç°æœ‰å…³ç³»çš„å±æ€§

è¿™äº›æ“ä½œåœ¨å›¾æ•°æ®åº“å’Œå‘é‡æ•°æ®åº“ç»„ä»¶ä¹‹é—´ä¿æŒæ•°æ®ä¸€è‡´æ€§ï¼Œç¡®ä¿æ‚¨çš„çŸ¥è¯†å›¾è°±ä¿æŒè¿è´¯ã€‚

</details>

## åˆ é™¤åŠŸèƒ½

LightRAGæä¾›äº†å…¨é¢çš„åˆ é™¤åŠŸèƒ½ï¼Œå…è®¸æ‚¨åˆ é™¤æ–‡æ¡£ã€å®ä½“å’Œå…³ç³»ã€‚

<details>
<summary> <b>åˆ é™¤å®ä½“</b> </summary>

æ‚¨å¯ä»¥é€šè¿‡å®ä½“åç§°åˆ é™¤å®ä½“åŠå…¶æ‰€æœ‰å…³è”å…³ç³»ï¼š

```python
# åˆ é™¤å®ä½“åŠå…¶æ‰€æœ‰å…³ç³»ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
rag.delete_by_entity("Google")

# å¼‚æ­¥ç‰ˆæœ¬
await rag.adelete_by_entity("Google")
```

åˆ é™¤å®ä½“æ—¶ä¼šï¼š
- ä»çŸ¥è¯†å›¾è°±ä¸­ç§»é™¤è¯¥å®ä½“èŠ‚ç‚¹
- åˆ é™¤è¯¥å®ä½“çš„æ‰€æœ‰å…³è”å…³ç³»
- ä»å‘é‡æ•°æ®åº“ä¸­ç§»é™¤ç›¸å…³çš„åµŒå…¥å‘é‡
- ä¿æŒçŸ¥è¯†å›¾è°±çš„å®Œæ•´æ€§

</details>

<details>
<summary> <b>åˆ é™¤å…³ç³»</b> </summary>

æ‚¨å¯ä»¥åˆ é™¤ä¸¤ä¸ªç‰¹å®šå®ä½“ä¹‹é—´çš„å…³ç³»ï¼š

```python
# åˆ é™¤ä¸¤ä¸ªå®ä½“ä¹‹é—´çš„å…³ç³»ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
rag.delete_by_relation("Google", "Gmail")

# å¼‚æ­¥ç‰ˆæœ¬
await rag.adelete_by_relation("Google", "Gmail")
```

åˆ é™¤å…³ç³»æ—¶ä¼šï¼š
- ç§»é™¤æŒ‡å®šçš„å…³ç³»è¾¹
- ä»å‘é‡æ•°æ®åº“ä¸­åˆ é™¤å…³ç³»çš„åµŒå…¥å‘é‡
- ä¿ç•™ä¸¤ä¸ªå®ä½“èŠ‚ç‚¹åŠå…¶ä»–å…³ç³»

</details>

<details>
<summary> <b>é€šè¿‡æ–‡æ¡£IDåˆ é™¤</b> </summary>

æ‚¨å¯ä»¥é€šè¿‡æ–‡æ¡£IDåˆ é™¤æ•´ä¸ªæ–‡æ¡£åŠå…¶ç›¸å…³çš„æ‰€æœ‰çŸ¥è¯†ï¼š

```python
# é€šè¿‡æ–‡æ¡£IDåˆ é™¤ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰
await rag.adelete_by_doc_id("doc-12345")
```

é€šè¿‡æ–‡æ¡£IDåˆ é™¤æ—¶çš„ä¼˜åŒ–å¤„ç†ï¼š
- **æ™ºèƒ½æ¸…ç†**ï¼šè‡ªåŠ¨è¯†åˆ«å¹¶åˆ é™¤ä»…å±äºè¯¥æ–‡æ¡£çš„å®ä½“å’Œå…³ç³»
- **ä¿ç•™å…±äº«çŸ¥è¯†**ï¼šå¦‚æœå®ä½“æˆ–å…³ç³»åœ¨å…¶ä»–æ–‡æ¡£ä¸­ä¹Ÿå­˜åœ¨ï¼Œåˆ™ä¼šä¿ç•™å¹¶é‡æ–°æ„å»ºæè¿°
- **ç¼“å­˜ä¼˜åŒ–**ï¼šæ¸…ç†ç›¸å…³çš„LLMç¼“å­˜ä»¥å‡å°‘å­˜å‚¨å¼€é”€
- **å¢é‡é‡å»º**ï¼šä»å‰©ä½™æ–‡æ¡£é‡æ–°æ„å»ºå—å½±å“çš„å®ä½“å’Œå…³ç³»æè¿°

åˆ é™¤è¿‡ç¨‹åŒ…æ‹¬ï¼š
1. åˆ é™¤æ–‡æ¡£ç›¸å…³çš„æ‰€æœ‰æ–‡æœ¬å—
2. è¯†åˆ«ä»…å±äºè¯¥æ–‡æ¡£çš„å®ä½“å’Œå…³ç³»å¹¶åˆ é™¤
3. é‡æ–°æ„å»ºåœ¨å…¶ä»–æ–‡æ¡£ä¸­ä»å­˜åœ¨çš„å®ä½“å’Œå…³ç³»
4. æ›´æ–°æ‰€æœ‰ç›¸å…³çš„å‘é‡ç´¢å¼•
5. æ¸…ç†æ–‡æ¡£çŠ¶æ€è®°å½•

æ³¨æ„ï¼šé€šè¿‡æ–‡æ¡£IDåˆ é™¤æ˜¯ä¸€ä¸ªå¼‚æ­¥æ“ä½œï¼Œå› ä¸ºå®ƒæ¶‰åŠå¤æ‚çš„çŸ¥è¯†å›¾è°±é‡æ„è¿‡ç¨‹ã€‚

</details>

<details>
<summary> <b>åˆ é™¤æ³¨æ„äº‹é¡¹</b> </summary>

**é‡è¦æé†’ï¼š**

1. **ä¸å¯é€†æ“ä½œ**ï¼šæ‰€æœ‰åˆ é™¤æ“ä½œéƒ½æ˜¯ä¸å¯é€†çš„ï¼Œè¯·è°¨æ…ä½¿ç”¨
2. **æ€§èƒ½è€ƒè™‘**ï¼šåˆ é™¤å¤§é‡æ•°æ®æ—¶å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡æ–‡æ¡£IDåˆ é™¤
3. **æ•°æ®ä¸€è‡´æ€§**ï¼šåˆ é™¤æ“ä½œä¼šè‡ªåŠ¨ç»´æŠ¤çŸ¥è¯†å›¾è°±å’Œå‘é‡æ•°æ®åº“ä¹‹é—´çš„ä¸€è‡´æ€§
4. **å¤‡ä»½å»ºè®®**ï¼šåœ¨æ‰§è¡Œé‡è¦åˆ é™¤æ“ä½œå‰å»ºè®®å¤‡ä»½æ•°æ®

**æ‰¹é‡åˆ é™¤å»ºè®®ï¼š**
- å¯¹äºæ‰¹é‡åˆ é™¤æ“ä½œï¼Œå»ºè®®ä½¿ç”¨å¼‚æ­¥æ–¹æ³•ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½
- å¤§è§„æ¨¡åˆ é™¤æ—¶ï¼Œè€ƒè™‘åˆ†æ‰¹è¿›è¡Œä»¥é¿å…ç³»ç»Ÿè´Ÿè½½è¿‡é«˜

</details>

## å®ä½“åˆå¹¶

<details>
<summary> <b>åˆå¹¶å®ä½“åŠå…¶å…³ç³»</b> </summary>

LightRAGç°åœ¨æ”¯æŒå°†å¤šä¸ªå®ä½“åˆå¹¶ä¸ºå•ä¸ªå®ä½“ï¼Œè‡ªåŠ¨å¤„ç†æ‰€æœ‰å…³ç³»ï¼š

```python
# åŸºæœ¬å®ä½“åˆå¹¶
rag.merge_entities(
    source_entities=["äººå·¥æ™ºèƒ½", "AI", "æœºå™¨æ™ºèƒ½"],
    target_entity="AIæŠ€æœ¯"
)
```

ä½¿ç”¨è‡ªå®šä¹‰åˆå¹¶ç­–ç•¥ï¼š

```python
# ä¸ºä¸åŒå­—æ®µå®šä¹‰è‡ªå®šä¹‰åˆå¹¶ç­–ç•¥
rag.merge_entities(
    source_entities=["çº¦ç¿°Â·å²å¯†æ–¯", "å²å¯†æ–¯åšå£«", "JÂ·å²å¯†æ–¯"],
    target_entity="çº¦ç¿°Â·å²å¯†æ–¯",
    merge_strategy={
        "description": "concatenate",  # ç»„åˆæ‰€æœ‰æè¿°
        "entity_type": "keep_first",   # ä¿ç•™ç¬¬ä¸€ä¸ªå®ä½“çš„ç±»å‹
        "source_id": "join_unique"     # ç»„åˆæ‰€æœ‰å”¯ä¸€çš„æºID
    }
)
```

ä½¿ç”¨è‡ªå®šä¹‰ç›®æ ‡å®ä½“æ•°æ®ï¼š

```python
# ä¸ºåˆå¹¶åçš„å®ä½“æŒ‡å®šç¡®åˆ‡å€¼
rag.merge_entities(
    source_entities=["çº½çº¦", "NYC", "å¤§è‹¹æœ"],
    target_entity="çº½çº¦å¸‚",
    target_entity_data={
        "entity_type": "LOCATION",
        "description": "çº½çº¦å¸‚æ˜¯ç¾å›½äººå£æœ€å¤šçš„åŸå¸‚ã€‚",
    }
)
```

ç»“åˆä¸¤ç§æ–¹æ³•çš„é«˜çº§ç”¨æ³•ï¼š

```python
# ä½¿ç”¨ç­–ç•¥å’Œè‡ªå®šä¹‰æ•°æ®åˆå¹¶å…¬å¸å®ä½“
rag.merge_entities(
    source_entities=["å¾®è½¯å…¬å¸", "Microsoft Corporation", "MSFT"],
    target_entity="å¾®è½¯",
    merge_strategy={
        "description": "concatenate",  # ç»„åˆæ‰€æœ‰æè¿°
        "source_id": "join_unique"     # ç»„åˆæºID
    },
    target_entity_data={
        "entity_type": "ORGANIZATION",
    }
)
```

åˆå¹¶å®ä½“æ—¶ï¼š

* æ‰€æœ‰æ¥è‡ªæºå®ä½“çš„å…³ç³»éƒ½ä¼šé‡å®šå‘åˆ°ç›®æ ‡å®ä½“
* é‡å¤çš„å…³ç³»ä¼šè¢«æ™ºèƒ½åˆå¹¶
* é˜²æ­¢è‡ªæˆ‘å…³ç³»ï¼ˆå¾ªç¯ï¼‰
* åˆå¹¶ååˆ é™¤æºå®ä½“
* ä¿ç•™å…³ç³»æƒé‡å’Œå±æ€§

</details>

## å¤šæ¨¡æ€æ–‡æ¡£å¤„ç†ï¼ˆRAG-Anythingé›†æˆï¼‰

LightRAG ç°å·²ä¸ [RAG-Anything](https://github.com/HKUDS/RAG-Anything) å®ç°æ— ç¼é›†æˆï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸º LightRAG æ„å»ºçš„**å…¨èƒ½å¤šæ¨¡æ€æ–‡æ¡£å¤„ç†RAGç³»ç»Ÿ**ã€‚RAG-Anything æä¾›å…ˆè¿›çš„è§£æå’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰èƒ½åŠ›ï¼Œè®©æ‚¨èƒ½å¤Ÿæ— ç¼å¤„ç†å¤šæ¨¡æ€æ–‡æ¡£ï¼Œå¹¶ä»å„ç§æ–‡æ¡£æ ¼å¼ä¸­æå–ç»“æ„åŒ–å†…å®¹â€”â€”åŒ…æ‹¬æ–‡æœ¬ã€å›¾ç‰‡ã€è¡¨æ ¼å’Œå…¬å¼â€”â€”ä»¥é›†æˆåˆ°æ‚¨çš„RAGæµç¨‹ä¸­ã€‚

**ä¸»è¦ç‰¹æ€§ï¼š**
- **ç«¯åˆ°ç«¯å¤šæ¨¡æ€æµç¨‹**ï¼šä»æ–‡æ¡£æ‘„å–è§£æåˆ°æ™ºèƒ½å¤šæ¨¡æ€é—®ç­”çš„å®Œæ•´å·¥ä½œæµç¨‹
- **é€šç”¨æ–‡æ¡£æ”¯æŒ**ï¼šæ— ç¼å¤„ç†PDFã€Officeæ–‡æ¡£ï¼ˆDOC/DOCX/PPT/PPTX/XLS/XLSXï¼‰ã€å›¾ç‰‡å’Œå„ç§æ–‡ä»¶æ ¼å¼
- **ä¸“ä¸šå†…å®¹åˆ†æ**ï¼šé’ˆå¯¹å›¾ç‰‡ã€è¡¨æ ¼ã€æ•°å­¦å…¬å¼å’Œå¼‚æ„å†…å®¹ç±»å‹çš„ä¸“ç”¨å¤„ç†å™¨
- **å¤šæ¨¡æ€çŸ¥è¯†å›¾è°±**ï¼šè‡ªåŠ¨å®ä½“æå–å’Œè·¨æ¨¡æ€å…³ç³»å‘ç°ä»¥å¢å¼ºç†è§£
- **æ··åˆæ™ºèƒ½æ£€ç´¢**ï¼šè¦†ç›–æ–‡æœ¬å’Œå¤šæ¨¡æ€å†…å®¹çš„é«˜çº§æœç´¢èƒ½åŠ›ï¼Œå…·å¤‡ä¸Šä¸‹æ–‡ç†è§£

**å¿«é€Ÿå¼€å§‹ï¼š**
1. å®‰è£…RAG-Anythingï¼š
   ```bash
   pip install raganything
   ```
2. å¤„ç†å¤šæ¨¡æ€æ–‡æ¡£ï¼š
    <details>
    <summary> <b> RAGAnything ä½¿ç”¨ç¤ºä¾‹ </b></summary>

    ```python
        import asyncio
        from raganything import RAGAnything
        from lightrag import LightRAG
        from lightrag.llm.openai import openai_complete_if_cache, openai_embed
        from lightrag.utils import EmbeddingFunc
        import os

        async def load_existing_lightrag():
            # é¦–å…ˆï¼Œåˆ›å»ºæˆ–åŠ è½½ç°æœ‰çš„ LightRAG å®ä¾‹
            lightrag_working_dir = "./existing_lightrag_storage"

            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¹‹å‰çš„ LightRAG å®ä¾‹
            if os.path.exists(lightrag_working_dir) and os.listdir(lightrag_working_dir):
                print("âœ… Found existing LightRAG instance, loading...")
            else:
                print("âŒ No existing LightRAG instance found, will create new one")

            # ä½¿ç”¨æ‚¨çš„é…ç½®åˆ›å»º/åŠ è½½ LightRAG å®ä¾‹
            lightrag_instance = LightRAG(
                working_dir=lightrag_working_dir,
                llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
                    "gpt-4o-mini",
                    prompt,
                    system_prompt=system_prompt,
                    history_messages=history_messages,
                    api_key="your-api-key",
                    **kwargs,
                ),
                embedding_func=EmbeddingFunc(
                    embedding_dim=3072,
                    func=lambda texts: openai_embed(
                        texts,
                        model="text-embedding-3-large",
                        api_key=api_key,
                        base_url=base_url,
                    ),
                )
            )

            # åˆå§‹åŒ–å­˜å‚¨ï¼ˆå¦‚æœæœ‰ç°æœ‰æ•°æ®ï¼Œè¿™å°†åŠ è½½ç°æœ‰æ•°æ®ï¼‰
            await lightrag_instance.initialize_storages()

            # ç°åœ¨ä½¿ç”¨ç°æœ‰çš„ LightRAG å®ä¾‹åˆå§‹åŒ– RAGAnything
            rag = RAGAnything(
                lightrag=lightrag_instance,  # ä¼ é€’ç°æœ‰çš„ LightRAG å®ä¾‹
                # ä»…éœ€è¦è§†è§‰æ¨¡å‹ç”¨äºå¤šæ¨¡æ€å¤„ç†
                vision_model_func=lambda prompt, system_prompt=None, history_messages=[], image_data=None, **kwargs: openai_complete_if_cache(
                    "gpt-4o",
                    "",
                    system_prompt=None,
                    history_messages=[],
                    messages=[
                        {"role": "system", "content": system_prompt} if system_prompt else None,
                        {"role": "user", "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                        ]} if image_data else {"role": "user", "content": prompt}
                    ],
                    api_key="your-api-key",
                    **kwargs,
                ) if image_data else openai_complete_if_cache(
                    "gpt-4o-mini",
                    prompt,
                    system_prompt=system_prompt,
                    history_messages=history_messages,
                    api_key="your-api-key",
                    **kwargs,
                )
                # æ³¨æ„ï¼šworking_dirã€llm_model_funcã€embedding_func ç­‰éƒ½ä» lightrag_instance ç»§æ‰¿
            )

            # æŸ¥è¯¢ç°æœ‰çš„çŸ¥è¯†åº“
            result = await rag.query_with_multimodal(
                "What data has been processed in this LightRAG instance?",
                mode="hybrid"
            )
            print("Query result:", result)

            # å‘ç°æœ‰çš„ LightRAG å®ä¾‹æ·»åŠ æ–°çš„å¤šæ¨¡æ€æ–‡æ¡£
            await rag.process_document_complete(
                file_path="path/to/new/multimodal_document.pdf",
                output_dir="./output"
            )

        if __name__ == "__main__":
            asyncio.run(load_existing_lightrag())
    ```

    </details>

å¦‚éœ€è¯¦ç»†æ–‡æ¡£å’Œé«˜çº§ç”¨æ³•ï¼Œè¯·å‚é˜… [RAG-Anything ä»“åº“](https://github.com/HKUDS/RAG-Anything)ã€‚

## Tokenç»Ÿè®¡åŠŸèƒ½

<details>
<summary> <b>æ¦‚è¿°å’Œä½¿ç”¨</b> </summary>

LightRAGæä¾›äº†TokenTrackerå·¥å…·æ¥è·Ÿè¸ªå’Œç®¡ç†å¤§æ¨¡å‹çš„tokenæ¶ˆè€—ã€‚è¿™ä¸ªåŠŸèƒ½å¯¹äºæ§åˆ¶APIæˆæœ¬å’Œä¼˜åŒ–æ€§èƒ½ç‰¹åˆ«æœ‰ç”¨ã€‚

### ä½¿ç”¨æ–¹æ³•

```python
from lightrag.utils import TokenTracker

# åˆ›å»ºTokenTrackerå®ä¾‹
token_tracker = TokenTracker()

# æ–¹æ³•1ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆæ¨èï¼‰
# é€‚ç”¨äºéœ€è¦è‡ªåŠ¨è·Ÿè¸ªtokenä½¿ç”¨çš„åœºæ™¯
with token_tracker:
    result1 = await llm_model_func("ä½ çš„é—®é¢˜1")
    result2 = await llm_model_func("ä½ çš„é—®é¢˜2")

# æ–¹æ³•2ï¼šæ‰‹åŠ¨æ·»åŠ tokenä½¿ç”¨è®°å½•
# é€‚ç”¨äºéœ€è¦æ›´ç²¾ç»†æ§åˆ¶tokenç»Ÿè®¡çš„åœºæ™¯
token_tracker.reset()

rag.insert()

rag.query("ä½ çš„é—®é¢˜1", param=QueryParam(mode="naive"))
rag.query("ä½ çš„é—®é¢˜2", param=QueryParam(mode="mix"))

# æ˜¾ç¤ºæ€»tokenä½¿ç”¨é‡ï¼ˆåŒ…å«æ’å…¥å’ŒæŸ¥è¯¢æ“ä½œï¼‰
print("Token usage:", token_tracker.get_usage())
```

### ä½¿ç”¨å»ºè®®
- åœ¨é•¿ä¼šè¯æˆ–æ‰¹é‡æ“ä½œä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œå¯ä»¥è‡ªåŠ¨è·Ÿè¸ªæ‰€æœ‰tokenæ¶ˆè€—
- å¯¹äºéœ€è¦åˆ†æ®µç»Ÿè®¡çš„åœºæ™¯ï¼Œä½¿ç”¨æ‰‹åŠ¨æ¨¡å¼å¹¶é€‚æ—¶è°ƒç”¨reset()
- å®šæœŸæ£€æŸ¥tokenä½¿ç”¨æƒ…å†µï¼Œæœ‰åŠ©äºåŠæ—¶å‘ç°å¼‚å¸¸æ¶ˆè€—
- åœ¨å¼€å‘æµ‹è¯•é˜¶æ®µç§¯æä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œä»¥ä¾¿ä¼˜åŒ–ç”Ÿäº§ç¯å¢ƒçš„æˆæœ¬

### å®é™…åº”ç”¨ç¤ºä¾‹
æ‚¨å¯ä»¥å‚è€ƒä»¥ä¸‹ç¤ºä¾‹æ¥å®ç°tokenç»Ÿè®¡ï¼š
- `examples/lightrag_gemini_track_token_demo.py`ï¼šä½¿ç”¨Google Geminiæ¨¡å‹çš„tokenç»Ÿè®¡ç¤ºä¾‹
- `examples/lightrag_siliconcloud_track_token_demo.py`ï¼šä½¿ç”¨SiliconCloudæ¨¡å‹çš„tokenç»Ÿè®¡ç¤ºä¾‹

è¿™äº›ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•åœ¨ä¸åŒæ¨¡å‹å’Œåœºæ™¯ä¸‹æœ‰æ•ˆåœ°ä½¿ç”¨TokenTrackeråŠŸèƒ½ã€‚

</details>

## æ•°æ®å¯¼å‡ºåŠŸèƒ½

### æ¦‚è¿°

LightRAGå…è®¸æ‚¨ä»¥å„ç§æ ¼å¼å¯¼å‡ºçŸ¥è¯†å›¾è°±æ•°æ®ï¼Œç”¨äºåˆ†æã€å…±äº«å’Œå¤‡ä»½ç›®çš„ã€‚ç³»ç»Ÿæ”¯æŒå¯¼å‡ºå®ä½“ã€å…³ç³»å’Œå…³ç³»æ•°æ®ã€‚

### å¯¼å‡ºåŠŸèƒ½

#### åŸºæœ¬ç”¨æ³•

```python
# åŸºæœ¬CSVå¯¼å‡ºï¼ˆé»˜è®¤æ ¼å¼ï¼‰
rag.export_data("knowledge_graph.csv")

# æŒ‡å®šä»»æ„æ ¼å¼
rag.export_data("output.xlsx", file_format="excel")
```

#### æ”¯æŒçš„ä¸åŒæ–‡ä»¶æ ¼å¼

```python
# ä»¥CSVæ ¼å¼å¯¼å‡ºæ•°æ®
rag.export_data("graph_data.csv", file_format="csv")

# å¯¼å‡ºæ•°æ®åˆ°Excelè¡¨æ ¼
rag.export_data("graph_data.xlsx", file_format="excel")

# ä»¥markdownæ ¼å¼å¯¼å‡ºæ•°æ®
rag.export_data("graph_data.md", file_format="md")

# å¯¼å‡ºæ•°æ®ä¸ºæ–‡æœ¬
rag.export_data("graph_data.txt", file_format="txt")
```

#### é™„åŠ é€‰é¡¹

åœ¨å¯¼å‡ºä¸­åŒ…å«å‘é‡åµŒå…¥ï¼ˆå¯é€‰ï¼‰ï¼š

```python
rag.export_data("complete_data.csv", include_vector_data=True)
```

### å¯¼å‡ºæ•°æ®åŒ…æ‹¬

æ‰€æœ‰å¯¼å‡ºåŒ…æ‹¬ï¼š

* å®ä½“ä¿¡æ¯ï¼ˆåç§°ã€IDã€å…ƒæ•°æ®ï¼‰
* å…³ç³»æ•°æ®ï¼ˆå®ä½“ä¹‹é—´çš„è¿æ¥ï¼‰
* æ¥è‡ªå‘é‡æ•°æ®åº“çš„å…³ç³»ä¿¡æ¯

## ç¼“å­˜

<details>
  <summary> <b>æ¸…é™¤ç¼“å­˜</b> </summary>

æ‚¨å¯ä»¥ä½¿ç”¨ä¸åŒæ¨¡å¼æ¸…é™¤LLMå“åº”ç¼“å­˜ï¼š

```python
# æ¸…é™¤æ‰€æœ‰ç¼“å­˜
await rag.aclear_cache()

# æ¸…é™¤æœ¬åœ°æ¨¡å¼ç¼“å­˜
await rag.aclear_cache(modes=["local"])

# æ¸…é™¤æå–ç¼“å­˜
await rag.aclear_cache(modes=["default"])

# æ¸…é™¤å¤šä¸ªæ¨¡å¼
await rag.aclear_cache(modes=["local", "global", "hybrid"])

# åŒæ­¥ç‰ˆæœ¬
rag.clear_cache(modes=["local"])
```

æœ‰æ•ˆçš„æ¨¡å¼åŒ…æ‹¬ï¼š

- `"default"`ï¼šæå–ç¼“å­˜
- `"naive"`ï¼šæœ´ç´ æœç´¢ç¼“å­˜
- `"local"`ï¼šæœ¬åœ°æœç´¢ç¼“å­˜
- `"global"`ï¼šå…¨å±€æœç´¢ç¼“å­˜
- `"hybrid"`ï¼šæ··åˆæœç´¢ç¼“å­˜
- `"mix"`ï¼šæ··åˆæœç´¢ç¼“å­˜

</details>

## LightRAG API

LightRAGæœåŠ¡å™¨æ—¨åœ¨æä¾›Web UIå’ŒAPIæ”¯æŒã€‚**æœ‰å…³LightRAGæœåŠ¡å™¨çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[LightRAGæœåŠ¡å™¨](./lightrag/api/README.md)ã€‚**

## çŸ¥è¯†å›¾è°±å¯è§†åŒ–

LightRAGæœåŠ¡å™¨æä¾›å…¨é¢çš„çŸ¥è¯†å›¾è°±å¯è§†åŒ–åŠŸèƒ½ã€‚å®ƒæ”¯æŒå„ç§é‡åŠ›å¸ƒå±€ã€èŠ‚ç‚¹æŸ¥è¯¢ã€å­å›¾è¿‡æ»¤ç­‰ã€‚**æœ‰å…³LightRAGæœåŠ¡å™¨çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[LightRAGæœåŠ¡å™¨](./lightrag/api/README.md)ã€‚**

![iShot_2025-03-23_12.40.08](./README.assets/iShot_2025-03-23_12.40.08.png)

## Langfuse å¯è§‚æµ‹æ€§é›†æˆ

Langfuse ä¸º OpenAI å®¢æˆ·ç«¯æä¾›äº†ç›´æ¥æ›¿ä»£æ–¹æ¡ˆï¼Œå¯è‡ªåŠ¨è·Ÿè¸ªæ‰€æœ‰ LLM äº¤äº’ï¼Œä½¿å¼€å‘è€…èƒ½å¤Ÿåœ¨æ— éœ€ä¿®æ”¹ä»£ç çš„æƒ…å†µä¸‹ç›‘æ§ã€è°ƒè¯•å’Œä¼˜åŒ–å…¶ RAG ç³»ç»Ÿã€‚

### å®‰è£… Langfuse å¯é€‰ä¾èµ–

```
pip install lightrag-hku
pip install lightrag-hku[observability]

# æˆ–ä»æºä»£ç å®‰è£…å¹¶å¯ç”¨è°ƒè¯•æ¨¡å¼
pip install -e .
pip install -e ".[observability]"
```

### é…ç½® Langfuse ç¯å¢ƒå˜é‡

ä¿®æ”¹ .env æ–‡ä»¶ï¼š

```
## Langfuse å¯è§‚æµ‹æ€§ï¼ˆå¯é€‰ï¼‰
# LLM å¯è§‚æµ‹æ€§å’Œè¿½è¸ªå¹³å°
# å®‰è£…å‘½ä»¤: pip install lightrag-hku[observability]
# æ³¨å†Œåœ°å€: https://cloud.langfuse.com æˆ–è‡ªæ‰˜ç®¡éƒ¨ç½²
LANGFUSE_SECRET_KEY=""
LANGFUSE_PUBLIC_KEY=""
LANGFUSE_HOST="https://cloud.langfuse.com"  # æˆ–æ‚¨çš„è‡ªæ‰˜ç®¡å®ä¾‹åœ°å€
LANGFUSE_ENABLE_TRACE=true
```

### Langfuse ä½¿ç”¨è¯´æ˜

å®‰è£…å¹¶é…ç½®å®Œæˆåï¼ŒLangfuse ä¼šè‡ªåŠ¨è¿½è¸ªæ‰€æœ‰ OpenAI LLM è°ƒç”¨ã€‚Langfuse ä»ªè¡¨æ¿åŠŸèƒ½åŒ…æ‹¬ï¼š

- **è¿½è¸ª**ï¼šæŸ¥çœ‹å®Œæ•´çš„ LLM è°ƒç”¨é“¾
- **åˆ†æ**ï¼šToken ä½¿ç”¨é‡ã€å»¶è¿Ÿã€æˆæœ¬æŒ‡æ ‡
- **è°ƒè¯•**ï¼šæ£€æŸ¥æç¤ºè¯å’Œå“åº”å†…å®¹
- **è¯„ä¼°**ï¼šæ¯”è¾ƒæ¨¡å‹è¾“å‡ºç»“æœ
- **ç›‘æ§**ï¼šå®æ—¶å‘Šè­¦åŠŸèƒ½

### é‡è¦æç¤º

**æ³¨æ„**ï¼šLightRAG ç›®å‰ä»…æŠŠ OpenAI å…¼å®¹çš„ API è°ƒç”¨æ¥å…¥äº† Langfuseã€‚Ollamaã€Azure å’Œ AWS Bedrock ç­‰ API è¿˜æ— æ³•ä½¿ç”¨ Langfuse çš„å¯è§‚æµ‹æ€§åŠŸèƒ½ã€‚

## RAGASè¯„ä¼°

**RAGAS**ï¼ˆRetrieval Augmented Generation Assessmentï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆè¯„ä¼°ï¼‰æ˜¯ä¸€ä¸ªä½¿ç”¨LLMå¯¹RAGç³»ç»Ÿè¿›è¡Œæ— å‚è€ƒè¯„ä¼°çš„æ¡†æ¶ã€‚æˆ‘ä»¬æä¾›äº†åŸºäºRAGASçš„è¯„ä¼°è„šæœ¬ã€‚è¯¦ç»†ä¿¡æ¯è¯·å‚é˜…[åŸºäºRAGASçš„è¯„ä¼°æ¡†æ¶](lightrag/evaluation/README.md)ã€‚

## è¯„ä¼°

### æ•°æ®é›†

LightRAGä½¿ç”¨çš„æ•°æ®é›†å¯ä»¥ä»[TommyChien/UltraDomain](https://huggingface.co/datasets/TommyChien/UltraDomain)ä¸‹è½½ã€‚

### ç”ŸæˆæŸ¥è¯¢

LightRAGä½¿ç”¨ä»¥ä¸‹æç¤ºç”Ÿæˆé«˜çº§æŸ¥è¯¢ï¼Œç›¸åº”çš„ä»£ç åœ¨`example/generate_query.py`ä¸­ã€‚

<details>
<summary> æç¤º </summary>

```python
ç»™å®šä»¥ä¸‹æ•°æ®é›†æè¿°ï¼š

{description}

è¯·è¯†åˆ«5ä¸ªå¯èƒ½ä¼šä½¿ç”¨æ­¤æ•°æ®é›†çš„æ½œåœ¨ç”¨æˆ·ã€‚å¯¹äºæ¯ä¸ªç”¨æˆ·ï¼Œåˆ—å‡ºä»–ä»¬ä¼šä½¿ç”¨æ­¤æ•°æ®é›†æ‰§è¡Œçš„5ä¸ªä»»åŠ¡ã€‚ç„¶åï¼Œå¯¹äºæ¯ä¸ªï¼ˆç”¨æˆ·ï¼Œä»»åŠ¡ï¼‰ç»„åˆï¼Œç”Ÿæˆ5ä¸ªéœ€è¦å¯¹æ•´ä¸ªæ•°æ®é›†æœ‰é«˜çº§ç†è§£çš„é—®é¢˜ã€‚

æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºç»“æœï¼š
- ç”¨æˆ·1ï¼š[ç”¨æˆ·æè¿°]
    - ä»»åŠ¡1ï¼š[ä»»åŠ¡æè¿°]
        - é—®é¢˜1ï¼š
        - é—®é¢˜2ï¼š
        - é—®é¢˜3ï¼š
        - é—®é¢˜4ï¼š
        - é—®é¢˜5ï¼š
    - ä»»åŠ¡2ï¼š[ä»»åŠ¡æè¿°]
        ...
    - ä»»åŠ¡5ï¼š[ä»»åŠ¡æè¿°]
- ç”¨æˆ·2ï¼š[ç”¨æˆ·æè¿°]
    ...
- ç”¨æˆ·5ï¼š[ç”¨æˆ·æè¿°]
    ...
```

</details>

### æ‰¹é‡è¯„ä¼°

ä¸ºäº†è¯„ä¼°ä¸¤ä¸ªRAGç³»ç»Ÿåœ¨é«˜çº§æŸ¥è¯¢ä¸Šçš„æ€§èƒ½ï¼ŒLightRAGä½¿ç”¨ä»¥ä¸‹æç¤ºï¼Œå…·ä½“ä»£ç å¯åœ¨`example/batch_eval.py`ä¸­æ‰¾åˆ°ã€‚

<details>
<summary> æç¤º </summary>

```python
---è§’è‰²---
æ‚¨æ˜¯ä¸€ä½ä¸“å®¶ï¼Œè´Ÿè´£æ ¹æ®ä¸‰ä¸ªæ ‡å‡†è¯„ä¼°åŒä¸€é—®é¢˜çš„ä¸¤ä¸ªç­”æ¡ˆï¼š**å…¨é¢æ€§**ã€**å¤šæ ·æ€§**å’Œ**èµ‹èƒ½æ€§**ã€‚
---ç›®æ ‡---
æ‚¨å°†æ ¹æ®ä¸‰ä¸ªæ ‡å‡†è¯„ä¼°åŒä¸€é—®é¢˜çš„ä¸¤ä¸ªç­”æ¡ˆï¼š**å…¨é¢æ€§**ã€**å¤šæ ·æ€§**å’Œ**èµ‹èƒ½æ€§**ã€‚

- **å…¨é¢æ€§**ï¼šç­”æ¡ˆæä¾›äº†å¤šå°‘ç»†èŠ‚æ¥æ¶µç›–é—®é¢˜çš„æ‰€æœ‰æ–¹é¢å’Œç»†èŠ‚ï¼Ÿ
- **å¤šæ ·æ€§**ï¼šç­”æ¡ˆåœ¨æä¾›å…³äºé—®é¢˜çš„ä¸åŒè§†è§’å’Œè§è§£æ–¹é¢æœ‰å¤šä¸°å¯Œå¤šæ ·ï¼Ÿ
- **èµ‹èƒ½æ€§**ï¼šç­”æ¡ˆåœ¨å¤šå¤§ç¨‹åº¦ä¸Šå¸®åŠ©è¯»è€…ç†è§£å¹¶å¯¹ä¸»é¢˜åšå‡ºæ˜æ™ºåˆ¤æ–­ï¼Ÿ

å¯¹äºæ¯ä¸ªæ ‡å‡†ï¼Œé€‰æ‹©æ›´å¥½çš„ç­”æ¡ˆï¼ˆç­”æ¡ˆ1æˆ–ç­”æ¡ˆ2ï¼‰å¹¶è§£é‡ŠåŸå› ã€‚ç„¶åï¼Œæ ¹æ®è¿™ä¸‰ä¸ªç±»åˆ«é€‰æ‹©æ€»ä½“èµ¢å®¶ã€‚

è¿™æ˜¯é—®é¢˜ï¼š
{query}

è¿™æ˜¯ä¸¤ä¸ªç­”æ¡ˆï¼š

**ç­”æ¡ˆ1ï¼š**
{answer1}

**ç­”æ¡ˆ2ï¼š**
{answer2}

ä½¿ç”¨ä¸Šè¿°ä¸‰ä¸ªæ ‡å‡†è¯„ä¼°ä¸¤ä¸ªç­”æ¡ˆï¼Œå¹¶ä¸ºæ¯ä¸ªæ ‡å‡†æä¾›è¯¦ç»†è§£é‡Šã€‚

ä»¥ä¸‹åˆ—JSONæ ¼å¼è¾“å‡ºæ‚¨çš„è¯„ä¼°ï¼š

{{
    "å…¨é¢æ€§": {{
        "è·èƒœè€…": "[ç­”æ¡ˆ1æˆ–ç­”æ¡ˆ2]",
        "è§£é‡Š": "[åœ¨æ­¤æä¾›è§£é‡Š]"
    }},
    "èµ‹èƒ½æ€§": {{
        "è·èƒœè€…": "[ç­”æ¡ˆ1æˆ–ç­”æ¡ˆ2]",
        "è§£é‡Š": "[åœ¨æ­¤æä¾›è§£é‡Š]"
    }},
    "æ€»ä½“è·èƒœè€…": {{
        "è·èƒœè€…": "[ç­”æ¡ˆ1æˆ–ç­”æ¡ˆ2]",
        "è§£é‡Š": "[æ ¹æ®ä¸‰ä¸ªæ ‡å‡†æ€»ç»“ä¸ºä»€ä¹ˆè¿™ä¸ªç­”æ¡ˆæ˜¯æ€»ä½“è·èƒœè€…]"
    }}
}}
```

</details>

### æ€»ä½“æ€§èƒ½è¡¨

|                      |**å†œä¸š**|            |**è®¡ç®—æœºç§‘å­¦**|            |**æ³•å¾‹**|            |**æ··åˆ**|            |
|----------------------|---------------|------------|------|------------|---------|------------|-------|------------|
|                      |NaiveRAG|**LightRAG**|NaiveRAG|**LightRAG**|NaiveRAG|**LightRAG**|NaiveRAG|**LightRAG**|
|**å…¨é¢æ€§**|32.4%|**67.6%**|38.4%|**61.6%**|16.4%|**83.6%**|38.8%|**61.2%**|
|**å¤šæ ·æ€§**|23.6%|**76.4%**|38.0%|**62.0%**|13.6%|**86.4%**|32.4%|**67.6%**|
|**èµ‹èƒ½æ€§**|32.4%|**67.6%**|38.8%|**61.2%**|16.4%|**83.6%**|42.8%|**57.2%**|
|**æ€»ä½“**|32.4%|**67.6%**|38.8%|**61.2%**|15.2%|**84.8%**|40.0%|**60.0%**|
|                      |RQ-RAG|**LightRAG**|RQ-RAG|**LightRAG**|RQ-RAG|**LightRAG**|RQ-RAG|**LightRAG**|
|**å…¨é¢æ€§**|31.6%|**68.4%**|38.8%|**61.2%**|15.2%|**84.8%**|39.2%|**60.8%**|
|**å¤šæ ·æ€§**|29.2%|**70.8%**|39.2%|**60.8%**|11.6%|**88.4%**|30.8%|**69.2%**|
|**èµ‹èƒ½æ€§**|31.6%|**68.4%**|36.4%|**63.6%**|15.2%|**84.8%**|42.4%|**57.6%**|
|**æ€»ä½“**|32.4%|**67.6%**|38.0%|**62.0%**|14.4%|**85.6%**|40.0%|**60.0%**|
|                      |HyDE|**LightRAG**|HyDE|**LightRAG**|HyDE|**LightRAG**|HyDE|**LightRAG**|
|**å…¨é¢æ€§**|26.0%|**74.0%**|41.6%|**58.4%**|26.8%|**73.2%**|40.4%|**59.6%**|
|**å¤šæ ·æ€§**|24.0%|**76.0%**|38.8%|**61.2%**|20.0%|**80.0%**|32.4%|**67.6%**|
|**èµ‹èƒ½æ€§**|25.2%|**74.8%**|40.8%|**59.2%**|26.0%|**74.0%**|46.0%|**54.0%**|
|**æ€»ä½“**|24.8%|**75.2%**|41.6%|**58.4%**|26.4%|**73.6%**|42.4%|**57.6%**|
|                      |GraphRAG|**LightRAG**|GraphRAG|**LightRAG**|GraphRAG|**LightRAG**|GraphRAG|**LightRAG**|
|**å…¨é¢æ€§**|45.6%|**54.4%**|48.4%|**51.6%**|48.4%|**51.6%**|**50.4%**|49.6%|
|**å¤šæ ·æ€§**|22.8%|**77.2%**|40.8%|**59.2%**|26.4%|**73.6%**|36.0%|**64.0%**|
|**èµ‹èƒ½æ€§**|41.2%|**58.8%**|45.2%|**54.8%**|43.6%|**56.4%**|**50.8%**|49.2%|
|**æ€»ä½“**|45.2%|**54.8%**|48.0%|**52.0%**|47.2%|**52.8%**|**50.4%**|49.6%|

## å¤ç°

æ‰€æœ‰ä»£ç éƒ½å¯ä»¥åœ¨`./reproduce`ç›®å½•ä¸­æ‰¾åˆ°ã€‚

### æ­¥éª¤0 æå–å”¯ä¸€ä¸Šä¸‹æ–‡

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æå–æ•°æ®é›†ä¸­çš„å”¯ä¸€ä¸Šä¸‹æ–‡ã€‚

<details>
<summary> ä»£ç  </summary>

```python
def extract_unique_contexts(input_directory, output_directory):

    os.makedirs(output_directory, exist_ok=True)

    jsonl_files = glob.glob(os.path.join(input_directory, '*.jsonl'))
    print(f"æ‰¾åˆ°{len(jsonl_files)}ä¸ªJSONLæ–‡ä»¶ã€‚")

    for file_path in jsonl_files:
        filename = os.path.basename(file_path)
        name, ext = os.path.splitext(filename)
        output_filename = f"{name}_unique_contexts.json"
        output_path = os.path.join(output_directory, output_filename)

        unique_contexts_dict = {}

        print(f"å¤„ç†æ–‡ä»¶ï¼š{filename}")

        try:
            with open(file_path, 'r', encoding='utf-8') as infile:
                for line_number, line in enumerate(infile, start=1):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        json_obj = json.loads(line)
                        context = json_obj.get('context')
                        if context and context not in unique_contexts_dict:
                            unique_contexts_dict[context] = None
                    except json.JSONDecodeError as e:
                        print(f"æ–‡ä»¶{filename}ç¬¬{line_number}è¡ŒJSONè§£ç é”™è¯¯ï¼š{e}")
        except FileNotFoundError:
            print(f"æœªæ‰¾åˆ°æ–‡ä»¶ï¼š{filename}")
            continue
        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶{filename}æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
            continue

        unique_contexts_list = list(unique_contexts_dict.keys())
        print(f"æ–‡ä»¶{filename}ä¸­æœ‰{len(unique_contexts_list)}ä¸ªå”¯ä¸€çš„`context`æ¡ç›®ã€‚")

        try:
            with open(output_path, 'w', encoding='utf-8') as outfile:
                json.dump(unique_contexts_list, outfile, ensure_ascii=False, indent=4)
            print(f"å”¯ä¸€çš„`context`æ¡ç›®å·²ä¿å­˜åˆ°ï¼š{output_filename}")
        except Exception as e:
            print(f"ä¿å­˜åˆ°æ–‡ä»¶{output_filename}æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")

    print("æ‰€æœ‰æ–‡ä»¶å·²å¤„ç†å®Œæˆã€‚")

```

</details>

### æ­¥éª¤1 æ’å…¥ä¸Šä¸‹æ–‡

å¯¹äºæå–çš„ä¸Šä¸‹æ–‡ï¼Œæˆ‘ä»¬å°†å®ƒä»¬æ’å…¥åˆ°LightRAGç³»ç»Ÿä¸­ã€‚

<details>
<summary> ä»£ç  </summary>

```python
def insert_text(rag, file_path):
    with open(file_path, mode='r') as f:
        unique_contexts = json.load(f)

    retries = 0
    max_retries = 3
    while retries < max_retries:
        try:
            rag.insert(unique_contexts)
            break
        except Exception as e:
            retries += 1
            print(f"æ’å…¥å¤±è´¥ï¼Œé‡è¯•ï¼ˆ{retries}/{max_retries}ï¼‰ï¼Œé”™è¯¯ï¼š{e}")
            time.sleep(10)
    if retries == max_retries:
        print("è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°åæ’å…¥å¤±è´¥")
```

</details>

### æ­¥éª¤2 ç”ŸæˆæŸ¥è¯¢

æˆ‘ä»¬ä»æ•°æ®é›†ä¸­æ¯ä¸ªä¸Šä¸‹æ–‡çš„å‰åŠéƒ¨åˆ†å’ŒååŠéƒ¨åˆ†æå–ä»¤ç‰Œï¼Œç„¶åå°†å®ƒä»¬ç»„åˆä¸ºæ•°æ®é›†æè¿°ä»¥ç”ŸæˆæŸ¥è¯¢ã€‚

<details>
<summary> ä»£ç  </summary>

```python
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')

def get_summary(context, tot_tokens=2000):
    tokens = tokenizer.tokenize(context)
    half_tokens = tot_tokens // 2

    start_tokens = tokens[1000:1000 + half_tokens]
    end_tokens = tokens[-(1000 + half_tokens):1000]

    summary_tokens = start_tokens + end_tokens
    summary = tokenizer.convert_tokens_to_string(summary_tokens)

    return summary
```

</details>

### æ­¥éª¤3 æŸ¥è¯¢

å¯¹äºæ­¥éª¤2ä¸­ç”Ÿæˆçš„æŸ¥è¯¢ï¼Œæˆ‘ä»¬å°†æå–å®ƒä»¬å¹¶æŸ¥è¯¢LightRAGã€‚

<details>
<summary> ä»£ç  </summary>

```python
def extract_queries(file_path):
    with open(file_path, 'r') as f:
        data = f.read()

    data = data.replace('**', '')

    queries = re.findall(r'- Question \d+: (.+)', data)

    return queries
```

</details>

## Starå†å²

<a href="https://star-history.com/#HKUDS/LightRAG&Date">
 <picture>
   <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/LightRAG&type=Date&theme=dark" />
   <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/LightRAG&type=Date" />
   <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/LightRAG&type=Date" />
 </picture>
</a>

## è´¡çŒ®

æ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…ï¼

<a href="https://github.com/HKUDS/LightRAG/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=HKUDS/LightRAG" />
</a>

## ğŸŒŸå¼•ç”¨

```python
@article{guo2024lightrag,
title={LightRAG: Simple and Fast Retrieval-Augmented Generation},
author={Zirui Guo and Lianghao Xia and Yanhua Yu and Tu Ao and Chao Huang},
year={2024},
eprint={2410.05779},
archivePrefix={arXiv},
primaryClass={cs.IR}
}
```

**æ„Ÿè°¢æ‚¨å¯¹æˆ‘ä»¬å·¥ä½œçš„å…³æ³¨ï¼**
